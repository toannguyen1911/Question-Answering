{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "LAP6Y877eGiV",
        "nJkoYfLK7wco",
        "zWJeRCn4dYkv"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "e235044d929646aa96181c4b01b17a0b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1f0ac4a69c5543a4be2d6f186456ffee",
              "IPY_MODEL_be9b3de3c2184c1985e3e789b59eb4ae",
              "IPY_MODEL_214b3c646ee142c391eaaf6314c6b343"
            ],
            "layout": "IPY_MODEL_8e8bc95b520944c38779488d730c8fdd"
          }
        },
        "1f0ac4a69c5543a4be2d6f186456ffee": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fc3ca89029cf42648120358a315d9246",
            "placeholder": "​",
            "style": "IPY_MODEL_5ca4939078ce444193d7bb82ebb258f0",
            "value": "Downloading (…)okenizer_config.json: 100%"
          }
        },
        "be9b3de3c2184c1985e3e789b59eb4ae": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6331bc664e9044209bbe8914e0bb1470",
            "max": 79,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c270ecd5ab79403e874a0015f21b5488",
            "value": 79
          }
        },
        "214b3c646ee142c391eaaf6314c6b343": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1239f89dcff047448a2d58cf9f8887ea",
            "placeholder": "​",
            "style": "IPY_MODEL_e38b3db1f9fe4ea1a904f56ceb646d24",
            "value": " 79.0/79.0 [00:00&lt;00:00, 2.70kB/s]"
          }
        },
        "8e8bc95b520944c38779488d730c8fdd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fc3ca89029cf42648120358a315d9246": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5ca4939078ce444193d7bb82ebb258f0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6331bc664e9044209bbe8914e0bb1470": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c270ecd5ab79403e874a0015f21b5488": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "1239f89dcff047448a2d58cf9f8887ea": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e38b3db1f9fe4ea1a904f56ceb646d24": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7850c34fdd9f455f938d0da67928da81": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a1ec886fb32749a28a1659dfa20ac0e6",
              "IPY_MODEL_80ac668e009d466196e455c6c4226d56",
              "IPY_MODEL_28eb1c21d2f04f978ad6ca60d7bc9ecc"
            ],
            "layout": "IPY_MODEL_905def2096924bf4ba8bd36d96dad027"
          }
        },
        "a1ec886fb32749a28a1659dfa20ac0e6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a4d38655efd8419bad8e432fd912e867",
            "placeholder": "​",
            "style": "IPY_MODEL_f2e4828454a447cfb437aeb73d61d98a",
            "value": "Downloading (…)lve/main/config.json: 100%"
          }
        },
        "80ac668e009d466196e455c6c4226d56": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2df0ab7d75ab453a92985bea67e5ca89",
            "max": 605,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_65ffcaa1b8294c5da4c9201e83b5b372",
            "value": 605
          }
        },
        "28eb1c21d2f04f978ad6ca60d7bc9ecc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_71956ecdfdf2439ba096b4d77223cbaf",
            "placeholder": "​",
            "style": "IPY_MODEL_2ee5a32527ee4ae0b5a6b116e04a1f3a",
            "value": " 605/605 [00:00&lt;00:00, 21.0kB/s]"
          }
        },
        "905def2096924bf4ba8bd36d96dad027": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a4d38655efd8419bad8e432fd912e867": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f2e4828454a447cfb437aeb73d61d98a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2df0ab7d75ab453a92985bea67e5ca89": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "65ffcaa1b8294c5da4c9201e83b5b372": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "71956ecdfdf2439ba096b4d77223cbaf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2ee5a32527ee4ae0b5a6b116e04a1f3a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ba49e082d1ae4a4fb37eddf508e11034": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_315f6709f28b4b65987df33aefd41ac5",
              "IPY_MODEL_7373002f6d3b4c299b932fa5bd28e8d7",
              "IPY_MODEL_dac293982f1e4da1a10d084a94dc72f5"
            ],
            "layout": "IPY_MODEL_684a1167db954b2e9f9e93592edca41d"
          }
        },
        "315f6709f28b4b65987df33aefd41ac5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8e7db3c3721f4dcc90811e2950891317",
            "placeholder": "​",
            "style": "IPY_MODEL_f04b507ff5f24e129052f23e071df84e",
            "value": "Downloading (…)ncepiece.bpe.model&quot;;: 100%"
          }
        },
        "7373002f6d3b4c299b932fa5bd28e8d7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9901d0333de0464ba27de958a493c88f",
            "max": 5069051,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e5f6cb8559014f7ea1559dbded493f0a",
            "value": 5069051
          }
        },
        "dac293982f1e4da1a10d084a94dc72f5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dc0c079f448047b58db85b79251118ab",
            "placeholder": "​",
            "style": "IPY_MODEL_057ac860470e4f439d27b3b7168f4860",
            "value": " 5.07M/5.07M [00:00&lt;00:00, 27.7MB/s]"
          }
        },
        "684a1167db954b2e9f9e93592edca41d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8e7db3c3721f4dcc90811e2950891317": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f04b507ff5f24e129052f23e071df84e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9901d0333de0464ba27de958a493c88f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e5f6cb8559014f7ea1559dbded493f0a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "dc0c079f448047b58db85b79251118ab": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "057ac860470e4f439d27b3b7168f4860": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "066a1c8f4f7047dcbbd1072f86e54b16": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c7e18ab00a604e46bfcb0866fdcacdc8",
              "IPY_MODEL_532db5fdc242448fb2895db2b891eae5",
              "IPY_MODEL_175fa442b6064e018a56a3777c33a495"
            ],
            "layout": "IPY_MODEL_1f99f0556d8d40b9a526b6455bcdb75f"
          }
        },
        "c7e18ab00a604e46bfcb0866fdcacdc8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_32e28a580ca4485fad18f95af79f7eb6",
            "placeholder": "​",
            "style": "IPY_MODEL_c1fc5c13da6d4159b0668c9b7cc9ae4b",
            "value": "Downloading (…)cial_tokens_map.json: 100%"
          }
        },
        "532db5fdc242448fb2895db2b891eae5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_546c215be44844a69fcdbc94f0e51793",
            "max": 150,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_632ab52af0844eb4b00cf0da8196e555",
            "value": 150
          }
        },
        "175fa442b6064e018a56a3777c33a495": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_facb7f545d454408a7ab38322fc393ae",
            "placeholder": "​",
            "style": "IPY_MODEL_bb485fafeed446c59a9e1eb6337f8b19",
            "value": " 150/150 [00:00&lt;00:00, 7.89kB/s]"
          }
        },
        "1f99f0556d8d40b9a526b6455bcdb75f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "32e28a580ca4485fad18f95af79f7eb6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c1fc5c13da6d4159b0668c9b7cc9ae4b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "546c215be44844a69fcdbc94f0e51793": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "632ab52af0844eb4b00cf0da8196e555": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "facb7f545d454408a7ab38322fc393ae": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bb485fafeed446c59a9e1eb6337f8b19": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "44ab16a227e1432c86e6760ed40a4e7a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_543a36800a4d4bb796f54ba5a93fd31f",
              "IPY_MODEL_3caad7d2beed47d5a9348b7fe6b52dde",
              "IPY_MODEL_4ccd8f8e6fe54e22aafe159134e84032"
            ],
            "layout": "IPY_MODEL_d467a202d6dc4f5285e3f18cc352eaeb"
          }
        },
        "543a36800a4d4bb796f54ba5a93fd31f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4d4c0914c8ff4ba3b077485a0697dbe9",
            "placeholder": "​",
            "style": "IPY_MODEL_79be81bb18284fa89f9643367cbef890",
            "value": "Downloading (…)&quot;pytorch_model.bin&quot;;: 100%"
          }
        },
        "3caad7d2beed47d5a9348b7fe6b52dde": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_de2d3c3bb522416b847adc9588ec74e1",
            "max": 1109905791,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4019c0b00fad4d8983ad9276d9b5bc1a",
            "value": 1109905791
          }
        },
        "4ccd8f8e6fe54e22aafe159134e84032": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d724c3442b664fd4a631bc234ceec137",
            "placeholder": "​",
            "style": "IPY_MODEL_2c44dc77f2674a029f4c224eb980f751",
            "value": " 1.11G/1.11G [00:34&lt;00:00, 31.9MB/s]"
          }
        },
        "d467a202d6dc4f5285e3f18cc352eaeb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4d4c0914c8ff4ba3b077485a0697dbe9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "79be81bb18284fa89f9643367cbef890": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "de2d3c3bb522416b847adc9588ec74e1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4019c0b00fad4d8983ad9276d9b5bc1a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d724c3442b664fd4a631bc234ceec137": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2c44dc77f2674a029f4c224eb980f751": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Install lib"
      ],
      "metadata": {
        "id": "LAP6Y877eGiV"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "ShbRR5_AIN9-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "978e0d7a-c94e-4567-a05c-8538d1498552"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting datasets\n",
            "  Downloading datasets-2.9.0-py3-none-any.whl (462 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m462.8/462.8 KB\u001b[0m \u001b[31m20.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting transformers\n",
            "  Downloading transformers-4.26.0-py3-none-any.whl (6.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m95.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: aiohttp in /usr/local/lib/python3.8/dist-packages (from datasets) (3.8.3)\n",
            "Requirement already satisfied: fsspec[http]>=2021.11.1 in /usr/local/lib/python3.8/dist-packages (from datasets) (2023.1.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/dist-packages (from datasets) (6.0)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.8/dist-packages (from datasets) (4.64.1)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.8/dist-packages (from datasets) (2.25.1)\n",
            "Collecting responses<0.19\n",
            "  Downloading responses-0.18.0-py3-none-any.whl (38 kB)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from datasets) (23.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.8/dist-packages (from datasets) (1.21.6)\n",
            "Requirement already satisfied: dill<0.3.7 in /usr/local/lib/python3.8/dist-packages (from datasets) (0.3.6)\n",
            "Requirement already satisfied: pyarrow>=6.0.0 in /usr/local/lib/python3.8/dist-packages (from datasets) (9.0.0)\n",
            "Collecting multiprocess\n",
            "  Downloading multiprocess-0.70.14-py38-none-any.whl (132 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m132.0/132.0 KB\u001b[0m \u001b[31m20.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting huggingface-hub<1.0.0,>=0.2.0\n",
            "  Downloading huggingface_hub-0.12.0-py3-none-any.whl (190 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m190.3/190.3 KB\u001b[0m \u001b[31m25.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.8/dist-packages (from datasets) (1.3.5)\n",
            "Collecting xxhash\n",
            "  Downloading xxhash-3.2.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (213 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m213.0/213.0 KB\u001b[0m \u001b[31m29.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tokenizers!=0.11.3,<0.14,>=0.11.1\n",
            "  Downloading tokenizers-0.13.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.6/7.6 MB\u001b[0m \u001b[31m113.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from transformers) (3.9.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (2022.6.2)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (6.0.4)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (1.8.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (22.2.0)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (4.0.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (1.3.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (2.1.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.8/dist-packages (from huggingface-hub<1.0.0,>=0.2.0->datasets) (4.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->datasets) (2022.12.7)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->datasets) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->datasets) (2.10)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->datasets) (4.0.0)\n",
            "Collecting urllib3<1.27,>=1.21.1\n",
            "  Downloading urllib3-1.26.14-py2.py3-none-any.whl (140 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m140.6/140.6 KB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.8/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.8/dist-packages (from pandas->datasets) (2022.7.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.8/dist-packages (from python-dateutil>=2.7.3->pandas->datasets) (1.15.0)\n",
            "Installing collected packages: tokenizers, xxhash, urllib3, multiprocess, responses, huggingface-hub, transformers, datasets\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 1.24.3\n",
            "    Uninstalling urllib3-1.24.3:\n",
            "      Successfully uninstalled urllib3-1.24.3\n",
            "Successfully installed datasets-2.9.0 huggingface-hub-0.12.0 multiprocess-0.70.14 responses-0.18.0 tokenizers-0.13.2 transformers-4.26.0 urllib3-1.26.14 xxhash-3.2.0\n"
          ]
        }
      ],
      "source": [
        "!pip install datasets transformers"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers[sentencepiece]"
      ],
      "metadata": {
        "id": "vJ7O0QdtvKh7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c4639faf-e873-4991-cfe5-9c78f8a498c7"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: transformers[sentencepiece] in /usr/local/lib/python3.8/dist-packages (4.26.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.8/dist-packages (from transformers[sentencepiece]) (1.21.6)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.8/dist-packages (from transformers[sentencepiece]) (2022.6.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from transformers[sentencepiece]) (3.9.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.11.0 in /usr/local/lib/python3.8/dist-packages (from transformers[sentencepiece]) (0.12.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from transformers[sentencepiece]) (23.0)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.8/dist-packages (from transformers[sentencepiece]) (0.13.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/dist-packages (from transformers[sentencepiece]) (6.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.8/dist-packages (from transformers[sentencepiece]) (4.64.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from transformers[sentencepiece]) (2.25.1)\n",
            "Collecting sentencepiece!=0.1.92,>=0.1.91\n",
            "  Downloading sentencepiece-0.1.97-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m33.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: protobuf<=3.20.2 in /usr/local/lib/python3.8/dist-packages (from transformers[sentencepiece]) (3.19.6)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.8/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers[sentencepiece]) (4.4.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->transformers[sentencepiece]) (1.26.14)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->transformers[sentencepiece]) (2022.12.7)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->transformers[sentencepiece]) (2.10)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->transformers[sentencepiece]) (4.0.0)\n",
            "Installing collected packages: sentencepiece\n",
            "Successfully installed sentencepiece-0.1.97\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#!apt install git-lfs"
      ],
      "metadata": {
        "id": "1Koh8yXlITLC"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Enviroment"
      ],
      "metadata": {
        "id": "nlrl0qCj7t8P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2TbYPNbz7yHO",
        "outputId": "c01c1cf1-cddd-4257-a208-57f0edfbbaa8"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# This flag is the difference between SQUAD v1 or 2 (if you're using another dataset, it indicates if impossible answers are allowed or not).\n",
        "squad_v2 = True\n",
        "#model_checkpoint = \"xlm-roberta-base\"\n",
        "model_checkpoint = \"deepset/xlm-roberta-base-squad2\"\n",
        "batch_size = 16"
      ],
      "metadata": {
        "id": "0A7s9p2BIgTT"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Preprocessing the training data"
      ],
      "metadata": {
        "id": "zWJeRCn4dYkv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "from pathlib import Path\n",
        "import torch"
      ],
      "metadata": {
        "id": "2pXKNpVo6XzJ"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer\n",
        "    \n",
        "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 145,
          "referenced_widgets": [
            "e235044d929646aa96181c4b01b17a0b",
            "1f0ac4a69c5543a4be2d6f186456ffee",
            "be9b3de3c2184c1985e3e789b59eb4ae",
            "214b3c646ee142c391eaaf6314c6b343",
            "8e8bc95b520944c38779488d730c8fdd",
            "fc3ca89029cf42648120358a315d9246",
            "5ca4939078ce444193d7bb82ebb258f0",
            "6331bc664e9044209bbe8914e0bb1470",
            "c270ecd5ab79403e874a0015f21b5488",
            "1239f89dcff047448a2d58cf9f8887ea",
            "e38b3db1f9fe4ea1a904f56ceb646d24",
            "7850c34fdd9f455f938d0da67928da81",
            "a1ec886fb32749a28a1659dfa20ac0e6",
            "80ac668e009d466196e455c6c4226d56",
            "28eb1c21d2f04f978ad6ca60d7bc9ecc",
            "905def2096924bf4ba8bd36d96dad027",
            "a4d38655efd8419bad8e432fd912e867",
            "f2e4828454a447cfb437aeb73d61d98a",
            "2df0ab7d75ab453a92985bea67e5ca89",
            "65ffcaa1b8294c5da4c9201e83b5b372",
            "71956ecdfdf2439ba096b4d77223cbaf",
            "2ee5a32527ee4ae0b5a6b116e04a1f3a",
            "ba49e082d1ae4a4fb37eddf508e11034",
            "315f6709f28b4b65987df33aefd41ac5",
            "7373002f6d3b4c299b932fa5bd28e8d7",
            "dac293982f1e4da1a10d084a94dc72f5",
            "684a1167db954b2e9f9e93592edca41d",
            "8e7db3c3721f4dcc90811e2950891317",
            "f04b507ff5f24e129052f23e071df84e",
            "9901d0333de0464ba27de958a493c88f",
            "e5f6cb8559014f7ea1559dbded493f0a",
            "dc0c079f448047b58db85b79251118ab",
            "057ac860470e4f439d27b3b7168f4860",
            "066a1c8f4f7047dcbbd1072f86e54b16",
            "c7e18ab00a604e46bfcb0866fdcacdc8",
            "532db5fdc242448fb2895db2b891eae5",
            "175fa442b6064e018a56a3777c33a495",
            "1f99f0556d8d40b9a526b6455bcdb75f",
            "32e28a580ca4485fad18f95af79f7eb6",
            "c1fc5c13da6d4159b0668c9b7cc9ae4b",
            "546c215be44844a69fcdbc94f0e51793",
            "632ab52af0844eb4b00cf0da8196e555",
            "facb7f545d454408a7ab38322fc393ae",
            "bb485fafeed446c59a9e1eb6337f8b19"
          ]
        },
        "id": "-IZTRVm8JA25",
        "outputId": "70bcd8f7-05f8-422e-8867-c1e72885c0ea"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)okenizer_config.json:   0%|          | 0.00/79.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e235044d929646aa96181c4b01b17a0b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)lve/main/config.json:   0%|          | 0.00/605 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7850c34fdd9f455f938d0da67928da81"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)ncepiece.bpe.model\";:   0%|          | 0.00/5.07M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ba49e082d1ae4a4fb37eddf508e11034"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)cial_tokens_map.json:   0%|          | 0.00/150 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "066a1c8f4f7047dcbbd1072f86e54b16"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def read_squad_train(path,data_index,context_size):\n",
        "  \"\"\"\n",
        "  Read data format squad \n",
        "  -> return contexts, questions, answers of sentenses\n",
        "  \"\"\"\n",
        "  path = Path(path)\n",
        "  with open(path, 'rb') as f:\n",
        "      squad_dict = json.load(f)\n",
        "\n",
        "  contexts = []\n",
        "  questions = []\n",
        "  answers = []\n",
        "  size=0\n",
        "  for group in squad_dict['data'][data_index-1:data_index]:\n",
        "      for passage in group['paragraphs']:\n",
        "        if size <= context_size:\n",
        "          context = passage['context']\n",
        "          for qa in passage['qas']:\n",
        "              question = qa['question']\n",
        "              for answer in qa['answers']:\n",
        "                if answer['answer_start']>=0:\n",
        "                  contexts.append(context)\n",
        "                  questions.append(question)\n",
        "                  answers.append(answer)\n",
        "          size+=1\n",
        "        else: break\n",
        "\n",
        "  return contexts, questions, answers\n",
        "def read_squad_val(path):\n",
        "  \"\"\"\n",
        "  Read data format squad \n",
        "  -> return contexts, questions, answers of sentenses\n",
        "  \"\"\"\n",
        "  path = Path(path)\n",
        "  with open(path, 'rb') as f:\n",
        "      squad_dict = json.load(f)\n",
        "\n",
        "  contexts = []\n",
        "  questions = []\n",
        "  answers = []\n",
        "  for group in squad_dict['data']:\n",
        "      for passage in group['paragraphs']:\n",
        "          context = passage['context']\n",
        "          for qa in passage['qas']:\n",
        "              question = qa['question']\n",
        "              for answer in qa['answers']:\n",
        "                  contexts.append(context)\n",
        "                  questions.append(question)\n",
        "                  answers.append(answer)\n",
        "\n",
        "  return contexts, questions, answers\n",
        "def add_token_positions(encodings, answers):\n",
        "  \"\"\"\n",
        "  Convert answer start- end from string to token\n",
        "  \"\"\"\n",
        "  start_positions = []\n",
        "  end_positions = []\n",
        "  for i in range(len(answers)):\n",
        "    start_positions.append(encodings.char_to_token(i, answers[i]['answer_start']))\n",
        "    end_positions.append(encodings.char_to_token(i, answers[i]['answer_end'] - 1))\n",
        "    # if None, the answer passage has been truncated\n",
        "    if start_positions[-1] is None:\n",
        "        start_positions[-1] = tokenizer.model_max_length\n",
        "    if end_positions[-1] is None:\n",
        "        end_positions[-1] = tokenizer.model_max_length\n",
        "  encodings.update({'start_positions': start_positions, 'end_positions': end_positions})\n",
        "def add_end_idx(answers, contexts):\n",
        "  \"\"\"\n",
        "  Squad format chỉ có id start của câu trả lời\n",
        "  -> Hàm này dùng để tạo id end của câu trả lời\n",
        "  \"\"\"\n",
        "  for answer, context in zip(answers, contexts):\n",
        "    gold_text = answer['text']\n",
        "    start_idx = answer['answer_start']\n",
        "    end_idx = start_idx + len(gold_text)\n",
        "\n",
        "    # sometimes squad answers are off by a character or two – fix this\n",
        "    if context[start_idx:end_idx] == gold_text:\n",
        "        answer['answer_end'] = end_idx\n",
        "    elif context[start_idx-1:end_idx-1] == gold_text:\n",
        "        answer['answer_start'] = start_idx - 1\n",
        "        answer['answer_end'] = end_idx - 1     # When the gold label is off by one character\n",
        "    elif context[start_idx-2:end_idx-2] == gold_text:\n",
        "        answer['answer_start'] = start_idx - 2\n",
        "        answer['answer_end'] = end_idx - 2     # When the gold label is off by two characters"
      ],
      "metadata": {
        "id": "DON7PU5kgZHM"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class SquadDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, encodings):\n",
        "        self.encodings = encodings\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.encodings.input_ids)"
      ],
      "metadata": {
        "id": "juoHW4ZpJn7V"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_contexts, train_questions, train_answers = read_squad_train('/content/drive/MyDrive/CS221/DoAnCK/Dataset/squad_vi.json', 1,3500)\n",
        "#val_contexts, val_questions, val_answers = read_squad_train('/content/drive/MyDrive/CS221/DoAnCK/Dataset/squad_vi.json', 3000, 3500)\n",
        "add_end_idx(train_answers, train_contexts)\n",
        "#add_end_idx(val_answers, val_contexts) \n",
        "\n",
        "#train\n",
        "new_train_contexts=[]\n",
        "new_train_questions=[]\n",
        "new_train_answers=[]\n",
        "for i in range(len(train_answers)):\n",
        "  if train_answers[i]['answer_start']!=train_answers[i]['answer_end']:\n",
        "    new_train_contexts.append(train_contexts[i])\n",
        "    new_train_questions.append(train_questions[i])\n",
        "    new_train_answers.append(train_answers[i])\n",
        "(train_contexts, train_questions, train_answers)=(new_train_contexts, new_train_questions, new_train_answers)\n",
        "(new_train_contexts, new_train_questions, new_train_answers)=(0,0,0)\n",
        "\n",
        "#chia train val\n",
        "val_contexts, val_questions, val_answers = train_contexts[12000:], train_questions[12000:], train_answers[12000:]\n",
        "train_contexts, train_questions, train_answers = train_contexts[:12000], train_questions[:12000], train_answers[:12000]\n",
        "\n",
        "\n",
        "train_encodings = tokenizer(train_contexts, train_questions, truncation=True, padding=True)\n",
        "val_encodings = tokenizer(val_contexts, val_questions, truncation=True, padding=True)\n",
        "\n",
        "add_token_positions(train_encodings, train_answers)\n",
        "add_token_positions(val_encodings, val_answers)\n"
      ],
      "metadata": {
        "id": "KABrDBg5j4q_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = SquadDataset(train_encodings)\n",
        "val_dataset = SquadDataset(val_encodings)"
      ],
      "metadata": {
        "id": "3wGUVFH-24U8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Load pretrain"
      ],
      "metadata": {
        "id": "XcSlcJmuKoip"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModelForQuestionAnswering, TrainingArguments, Trainer\n",
        "\n",
        "model = AutoModelForQuestionAnswering.from_pretrained(model_checkpoint)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "referenced_widgets": [
            "44ab16a227e1432c86e6760ed40a4e7a",
            "543a36800a4d4bb796f54ba5a93fd31f",
            "3caad7d2beed47d5a9348b7fe6b52dde",
            "4ccd8f8e6fe54e22aafe159134e84032",
            "d467a202d6dc4f5285e3f18cc352eaeb",
            "4d4c0914c8ff4ba3b077485a0697dbe9",
            "79be81bb18284fa89f9643367cbef890",
            "de2d3c3bb522416b847adc9588ec74e1",
            "4019c0b00fad4d8983ad9276d9b5bc1a",
            "d724c3442b664fd4a631bc234ceec137",
            "2c44dc77f2674a029f4c224eb980f751"
          ],
          "height": 0
        },
        "id": "OzIv0rIXKpxm",
        "outputId": "c7f305fd-f578-4f7c-b814-8869590874f2"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)\"pytorch_model.bin\";:   0%|          | 0.00/1.11G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "44ab16a227e1432c86e6760ed40a4e7a"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RLgu-uEd5cm0",
        "outputId": "fafe639c-6692-4d7e-c3e8-f28e61d00ee7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "XLMRobertaForQuestionAnswering(\n",
              "  (roberta): XLMRobertaModel(\n",
              "    (embeddings): XLMRobertaEmbeddings(\n",
              "      (word_embeddings): Embedding(250002, 768, padding_idx=1)\n",
              "      (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
              "      (token_type_embeddings): Embedding(1, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): XLMRobertaEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): XLMRobertaLayer(\n",
              "          (attention): XLMRobertaAttention(\n",
              "            (self): XLMRobertaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): XLMRobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): XLMRobertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): XLMRobertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): XLMRobertaLayer(\n",
              "          (attention): XLMRobertaAttention(\n",
              "            (self): XLMRobertaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): XLMRobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): XLMRobertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): XLMRobertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): XLMRobertaLayer(\n",
              "          (attention): XLMRobertaAttention(\n",
              "            (self): XLMRobertaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): XLMRobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): XLMRobertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): XLMRobertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): XLMRobertaLayer(\n",
              "          (attention): XLMRobertaAttention(\n",
              "            (self): XLMRobertaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): XLMRobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): XLMRobertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): XLMRobertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): XLMRobertaLayer(\n",
              "          (attention): XLMRobertaAttention(\n",
              "            (self): XLMRobertaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): XLMRobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): XLMRobertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): XLMRobertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): XLMRobertaLayer(\n",
              "          (attention): XLMRobertaAttention(\n",
              "            (self): XLMRobertaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): XLMRobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): XLMRobertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): XLMRobertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): XLMRobertaLayer(\n",
              "          (attention): XLMRobertaAttention(\n",
              "            (self): XLMRobertaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): XLMRobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): XLMRobertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): XLMRobertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): XLMRobertaLayer(\n",
              "          (attention): XLMRobertaAttention(\n",
              "            (self): XLMRobertaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): XLMRobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): XLMRobertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): XLMRobertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): XLMRobertaLayer(\n",
              "          (attention): XLMRobertaAttention(\n",
              "            (self): XLMRobertaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): XLMRobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): XLMRobertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): XLMRobertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): XLMRobertaLayer(\n",
              "          (attention): XLMRobertaAttention(\n",
              "            (self): XLMRobertaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): XLMRobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): XLMRobertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): XLMRobertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): XLMRobertaLayer(\n",
              "          (attention): XLMRobertaAttention(\n",
              "            (self): XLMRobertaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): XLMRobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): XLMRobertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): XLMRobertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): XLMRobertaLayer(\n",
              "          (attention): XLMRobertaAttention(\n",
              "            (self): XLMRobertaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): XLMRobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): XLMRobertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): XLMRobertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (qa_outputs): Linear(in_features=768, out_features=2, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Train"
      ],
      "metadata": {
        "id": "vMlPE-C7l1kQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader\n",
        "from transformers import AdamW\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "DGxpf8C53jYT"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 10\n",
        "batch_size=8\n",
        "train_count = len(train_dataset)\n",
        "val_count = len(val_dataset)\n",
        "PATH = \"/content/drive/MyDrive/CS221/DoAnCK/Model/best_model.model\""
      ],
      "metadata": {
        "id": "ZSkUTlj23qUH",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "outputId": "38029a72-1ee9-4348-a5b5-c90a3a925ef6"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-c8477a9b85f2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mtrain_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mval_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_dataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mPATH\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"/content/drive/MyDrive/CS221/DoAnCK/Model/best_model.model\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'train_dataset' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Train with pytorch (Train thử với data mẫu gồm 1000 bộ câu hỏi)"
      ],
      "metadata": {
        "id": "IKcswr6P3hdJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
        "model.to(device)\n",
        "train_loader = DataLoader(train_dataset, batch_size = batch_size, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size = batch_size, shuffle=True)\n",
        "\n",
        "optim = AdamW(model.parameters(), lr=5e-5)\n",
        "\n",
        "for epoch in range(epochs):\n",
        "  print(\"Epoch \" + str(epoch) + \":\")\n",
        "  train_loss, val_loss = 0.0, 0.0\n",
        "  train_correct, val_correct = 0, 0\n",
        "\n",
        "  #train\n",
        "  model.train()\n",
        "  for batch in train_loader:\n",
        "    optim.zero_grad()\n",
        "    input_ids = batch['input_ids'].to(device)\n",
        "    attention_mask = batch['attention_mask'].to(device)\n",
        "    start_positions = batch['start_positions'].to(device)\n",
        "    end_positions = batch['end_positions'].to(device)\n",
        "    outputs = model(input_ids, attention_mask=attention_mask, start_positions=start_positions, end_positions=end_positions)\n",
        "    loss = outputs[0]\n",
        "    loss.backward()\n",
        "    optim.step()\n",
        "    train_loss += loss\n",
        "    start, end = outputs.start_logits.argmax(dim=-1), outputs.end_logits.argmax(dim=-1)\n",
        "\n",
        "    #print(f'start: {start_positions}, end: {end_positions} \\nstart_pre: {start}, end_pre: {end}')\n",
        "    for i in range(len(start)):\n",
        "      if (start_positions[i] == start[i] and end_positions[i] == end[i]):\n",
        "        train_correct += 1\n",
        "\n",
        "  #Val\n",
        "  #torch.cuda.empty_cache()\n",
        "  # del outputs\n",
        "  # model.eval()\n",
        "  # for batch in val_loader:\n",
        "  #   input_ids = batch['input_ids'].to(device)\n",
        "  #   attention_mask = batch['attention_mask'].to(device)\n",
        "  #   start_positions = batch['start_positions'].to(device)\n",
        "  #   end_positions = batch['end_positions'].to(device)\n",
        "  #   outputs = model(input_ids, attention_mask=attention_mask, start_positions=start_positions, end_positions=end_positions)\n",
        "  #   loss = outputs[0]\n",
        "  #   val_loss += loss\n",
        "\n",
        "  #   start, end = outputs.start_logits.argmax(dim=-1), outputs.end_logits.argmax(dim=-1)\n",
        "  #   for i in range(len(start)):\n",
        "  #     if (start_positions[i] == start[i] and end_positions[i] == end[i]):\n",
        "  #       val_correct += 1\n",
        "\n",
        "  print(f'\\ttrain_loss: {train_loss/train_count}, train_EM: {round(train_correct/train_count, 3)}')#\\n\\tval_loss: {val_loss/val_count}, val_EM: {round(val_correct/val_count, 3)}')\n",
        "  torch.save(model.state_dict(), PATH)\n",
        "\n",
        "model.eval()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ka2LlbO_3fV6",
        "outputId": "a68f136c-2d37-4cd7-d16e-f756f86fc74b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0:\n",
            "\ttrain_loss: 0.06970500946044922, train_EM: 0.782\n",
            "Epoch 1:\n",
            "\ttrain_loss: 0.025197690352797508, train_EM: 0.91\n",
            "Epoch 2:\n",
            "\ttrain_loss: 0.010780108161270618, train_EM: 0.951\n",
            "Epoch 3:\n",
            "\ttrain_loss: 0.010792060755193233, train_EM: 0.961\n",
            "Epoch 4:\n",
            "\ttrain_loss: 0.004178685136139393, train_EM: 0.988\n",
            "Epoch 5:\n",
            "\ttrain_loss: 0.012848387472331524, train_EM: 0.956\n",
            "Epoch 6:\n",
            "\ttrain_loss: 0.008505364879965782, train_EM: 0.961\n",
            "Epoch 7:\n",
            "\ttrain_loss: 0.011643161065876484, train_EM: 0.956\n",
            "Epoch 8:\n",
            "\ttrain_loss: 0.00583803141489625, train_EM: 0.975\n",
            "Epoch 9:\n",
            "\ttrain_loss: 0.012150724418461323, train_EM: 0.962\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "XLMRobertaForQuestionAnswering(\n",
              "  (roberta): XLMRobertaModel(\n",
              "    (embeddings): XLMRobertaEmbeddings(\n",
              "      (word_embeddings): Embedding(250002, 768, padding_idx=1)\n",
              "      (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
              "      (token_type_embeddings): Embedding(1, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): XLMRobertaEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): XLMRobertaLayer(\n",
              "          (attention): XLMRobertaAttention(\n",
              "            (self): XLMRobertaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): XLMRobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): XLMRobertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): XLMRobertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): XLMRobertaLayer(\n",
              "          (attention): XLMRobertaAttention(\n",
              "            (self): XLMRobertaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): XLMRobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): XLMRobertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): XLMRobertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): XLMRobertaLayer(\n",
              "          (attention): XLMRobertaAttention(\n",
              "            (self): XLMRobertaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): XLMRobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): XLMRobertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): XLMRobertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): XLMRobertaLayer(\n",
              "          (attention): XLMRobertaAttention(\n",
              "            (self): XLMRobertaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): XLMRobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): XLMRobertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): XLMRobertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): XLMRobertaLayer(\n",
              "          (attention): XLMRobertaAttention(\n",
              "            (self): XLMRobertaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): XLMRobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): XLMRobertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): XLMRobertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): XLMRobertaLayer(\n",
              "          (attention): XLMRobertaAttention(\n",
              "            (self): XLMRobertaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): XLMRobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): XLMRobertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): XLMRobertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): XLMRobertaLayer(\n",
              "          (attention): XLMRobertaAttention(\n",
              "            (self): XLMRobertaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): XLMRobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): XLMRobertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): XLMRobertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): XLMRobertaLayer(\n",
              "          (attention): XLMRobertaAttention(\n",
              "            (self): XLMRobertaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): XLMRobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): XLMRobertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): XLMRobertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): XLMRobertaLayer(\n",
              "          (attention): XLMRobertaAttention(\n",
              "            (self): XLMRobertaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): XLMRobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): XLMRobertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): XLMRobertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): XLMRobertaLayer(\n",
              "          (attention): XLMRobertaAttention(\n",
              "            (self): XLMRobertaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): XLMRobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): XLMRobertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): XLMRobertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): XLMRobertaLayer(\n",
              "          (attention): XLMRobertaAttention(\n",
              "            (self): XLMRobertaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): XLMRobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): XLMRobertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): XLMRobertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): XLMRobertaLayer(\n",
              "          (attention): XLMRobertaAttention(\n",
              "            (self): XLMRobertaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): XLMRobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): XLMRobertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): XLMRobertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (qa_outputs): Linear(in_features=768, out_features=2, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Train with trainer (Chính thức)"
      ],
      "metadata": {
        "id": "fN-QiKEf5ngP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "args = TrainingArguments(\n",
        "    f\"/content/drive/MyDrive/CS221/DoAnCK/Logs/Roberta-ViSquad\",#Tên folder chứa log\n",
        "    evaluation_strategy = \"epoch\",#Đánh giá sau mỗi epoch\n",
        "    learning_rate=2e-5,\n",
        "    per_device_train_batch_size=batch_size,\n",
        "    per_device_eval_batch_size=16,\n",
        "    num_train_epochs=10,\n",
        "    weight_decay=0.01,\n",
        "    #push_to_hub=True,\n",
        ")"
      ],
      "metadata": {
        "id": "Qh5bWNzHKYOL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def f1_score(start_pred,end_pred,start_true,end_true):\n",
        "  a=np.arange(int(start_pred),int(end_pred+1), step=1)\n",
        "  b=np.arange(int(start_true),int(end_true+1), step=1)\n",
        "  true_count = len(np.intersect1d(a,b))\n",
        "  if ((int(end_true)-int(start_true)) == 0):\n",
        "    recall = 0\n",
        "  else:\n",
        "    recall = true_count/(int(end_true)-int(start_true))\n",
        "  if ((int(end_pred)-int(start_pred)) == 0):\n",
        "    precision = 0\n",
        "  else:\n",
        "    precision= true_count/(int(end_pred)-int(start_pred))\n",
        "  if (precision + recall == 0):\n",
        "    return 0\n",
        "  f1=2*(precision*recall)/(precision+recall)\n",
        "  return f1"
      ],
      "metadata": {
        "id": "VSGbLruKKYOL"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_metrics(eval_pred):    \n",
        "    logits, labels = eval_pred\n",
        "    predictions = np.argmax(logits, axis=-1)\n",
        "    count = 0\n",
        "    for i in range(len(predictions[0])):\n",
        "      if (predictions[0][i] == labels[0][i] and predictions[1][i] == labels[1][i]):\n",
        "        count += 1\n",
        "    f1 = 0\n",
        "    for i in range(len(predictions[0])):\n",
        "      f1 += f1_score(predictions[0][i], predictions[1][i], labels[0][i], labels[1][i])\n",
        "\n",
        "    return {'exact_match': round(count/len(predictions[0]), 3), 'f1_score': round(f1/len(predictions[0]),3)} #metric.compute(predictions=predictions, references=labels)"
      ],
      "metadata": {
        "id": "NnKZcCABKYOL"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer = Trainer(\n",
        "    model,\n",
        "    args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=val_dataset,\n",
        "    #data_collator=data_collator,\n",
        "    tokenizer=tokenizer,\n",
        "    compute_metrics=compute_metrics\n",
        ")"
      ],
      "metadata": {
        "id": "FUNMR9oVKYOL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.train()\n",
        "trainer.save_model(\"/content/drive/MyDrive/CS221/DoAnCK/Model/Roberta-ViSquad\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "e7c5b211-27dc-4943-b9a4-65d0300f9383",
        "id": "jWnUln7dKYOM"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n",
            "***** Running training *****\n",
            "  Num examples = 12000\n",
            "  Num Epochs = 10\n",
            "  Instantaneous batch size per device = 8\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
            "  Gradient Accumulation steps = 1\n",
            "  Total optimization steps = 15000\n",
            "  Number of trainable parameters = 277454594\n",
            "You're using a XLMRobertaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='15000' max='15000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [15000/15000 3:55:11, Epoch 10/10]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Exact Match</th>\n",
              "      <th>F1 Score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>1.479900</td>\n",
              "      <td>1.359919</td>\n",
              "      <td>52.696000</td>\n",
              "      <td>0.800000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>1.099000</td>\n",
              "      <td>1.337566</td>\n",
              "      <td>54.340000</td>\n",
              "      <td>0.834000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.805500</td>\n",
              "      <td>1.565913</td>\n",
              "      <td>54.751000</td>\n",
              "      <td>0.822000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.606600</td>\n",
              "      <td>1.708217</td>\n",
              "      <td>54.545000</td>\n",
              "      <td>0.815000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.461000</td>\n",
              "      <td>1.777834</td>\n",
              "      <td>54.751000</td>\n",
              "      <td>0.833000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.361900</td>\n",
              "      <td>2.020115</td>\n",
              "      <td>54.340000</td>\n",
              "      <td>0.822000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>0.284300</td>\n",
              "      <td>2.531387</td>\n",
              "      <td>55.932000</td>\n",
              "      <td>0.838000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>0.220700</td>\n",
              "      <td>2.673394</td>\n",
              "      <td>55.829000</td>\n",
              "      <td>0.837000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>0.163000</td>\n",
              "      <td>3.208999</td>\n",
              "      <td>55.419000</td>\n",
              "      <td>0.830000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>0.149000</td>\n",
              "      <td>3.267859</td>\n",
              "      <td>55.470000</td>\n",
              "      <td>0.831000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Saving model checkpoint to /content/drive/MyDrive/CS221/DoAnCK/Logs/Roberta-ViSquad/checkpoint-500\n",
            "Configuration saved in /content/drive/MyDrive/CS221/DoAnCK/Logs/Roberta-ViSquad/checkpoint-500/config.json\n",
            "Model weights saved in /content/drive/MyDrive/CS221/DoAnCK/Logs/Roberta-ViSquad/checkpoint-500/pytorch_model.bin\n",
            "tokenizer config file saved in /content/drive/MyDrive/CS221/DoAnCK/Logs/Roberta-ViSquad/checkpoint-500/tokenizer_config.json\n",
            "Special tokens file saved in /content/drive/MyDrive/CS221/DoAnCK/Logs/Roberta-ViSquad/checkpoint-500/special_tokens_map.json\n",
            "Saving model checkpoint to /content/drive/MyDrive/CS221/DoAnCK/Logs/Roberta-ViSquad/checkpoint-1000\n",
            "Configuration saved in /content/drive/MyDrive/CS221/DoAnCK/Logs/Roberta-ViSquad/checkpoint-1000/config.json\n",
            "Model weights saved in /content/drive/MyDrive/CS221/DoAnCK/Logs/Roberta-ViSquad/checkpoint-1000/pytorch_model.bin\n",
            "tokenizer config file saved in /content/drive/MyDrive/CS221/DoAnCK/Logs/Roberta-ViSquad/checkpoint-1000/tokenizer_config.json\n",
            "Special tokens file saved in /content/drive/MyDrive/CS221/DoAnCK/Logs/Roberta-ViSquad/checkpoint-1000/special_tokens_map.json\n",
            "Saving model checkpoint to /content/drive/MyDrive/CS221/DoAnCK/Logs/Roberta-ViSquad/checkpoint-1500\n",
            "Configuration saved in /content/drive/MyDrive/CS221/DoAnCK/Logs/Roberta-ViSquad/checkpoint-1500/config.json\n",
            "Model weights saved in /content/drive/MyDrive/CS221/DoAnCK/Logs/Roberta-ViSquad/checkpoint-1500/pytorch_model.bin\n",
            "tokenizer config file saved in /content/drive/MyDrive/CS221/DoAnCK/Logs/Roberta-ViSquad/checkpoint-1500/tokenizer_config.json\n",
            "Special tokens file saved in /content/drive/MyDrive/CS221/DoAnCK/Logs/Roberta-ViSquad/checkpoint-1500/special_tokens_map.json\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1947\n",
            "  Batch size = 16\n",
            "Saving model checkpoint to /content/drive/MyDrive/CS221/DoAnCK/Logs/Roberta-ViSquad/checkpoint-2000\n",
            "Configuration saved in /content/drive/MyDrive/CS221/DoAnCK/Logs/Roberta-ViSquad/checkpoint-2000/config.json\n",
            "Model weights saved in /content/drive/MyDrive/CS221/DoAnCK/Logs/Roberta-ViSquad/checkpoint-2000/pytorch_model.bin\n",
            "tokenizer config file saved in /content/drive/MyDrive/CS221/DoAnCK/Logs/Roberta-ViSquad/checkpoint-2000/tokenizer_config.json\n",
            "Special tokens file saved in /content/drive/MyDrive/CS221/DoAnCK/Logs/Roberta-ViSquad/checkpoint-2000/special_tokens_map.json\n",
            "Saving model checkpoint to /content/drive/MyDrive/CS221/DoAnCK/Logs/Roberta-ViSquad/checkpoint-2500\n",
            "Configuration saved in /content/drive/MyDrive/CS221/DoAnCK/Logs/Roberta-ViSquad/checkpoint-2500/config.json\n",
            "Model weights saved in /content/drive/MyDrive/CS221/DoAnCK/Logs/Roberta-ViSquad/checkpoint-2500/pytorch_model.bin\n",
            "tokenizer config file saved in /content/drive/MyDrive/CS221/DoAnCK/Logs/Roberta-ViSquad/checkpoint-2500/tokenizer_config.json\n",
            "Special tokens file saved in /content/drive/MyDrive/CS221/DoAnCK/Logs/Roberta-ViSquad/checkpoint-2500/special_tokens_map.json\n",
            "Saving model checkpoint to /content/drive/MyDrive/CS221/DoAnCK/Logs/Roberta-ViSquad/checkpoint-3000\n",
            "Configuration saved in /content/drive/MyDrive/CS221/DoAnCK/Logs/Roberta-ViSquad/checkpoint-3000/config.json\n",
            "Model weights saved in /content/drive/MyDrive/CS221/DoAnCK/Logs/Roberta-ViSquad/checkpoint-3000/pytorch_model.bin\n",
            "tokenizer config file saved in /content/drive/MyDrive/CS221/DoAnCK/Logs/Roberta-ViSquad/checkpoint-3000/tokenizer_config.json\n",
            "Special tokens file saved in /content/drive/MyDrive/CS221/DoAnCK/Logs/Roberta-ViSquad/checkpoint-3000/special_tokens_map.json\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1947\n",
            "  Batch size = 16\n",
            "Saving model checkpoint to /content/drive/MyDrive/CS221/DoAnCK/Logs/Roberta-ViSquad/checkpoint-3500\n",
            "Configuration saved in /content/drive/MyDrive/CS221/DoAnCK/Logs/Roberta-ViSquad/checkpoint-3500/config.json\n",
            "Model weights saved in /content/drive/MyDrive/CS221/DoAnCK/Logs/Roberta-ViSquad/checkpoint-3500/pytorch_model.bin\n",
            "tokenizer config file saved in /content/drive/MyDrive/CS221/DoAnCK/Logs/Roberta-ViSquad/checkpoint-3500/tokenizer_config.json\n",
            "Special tokens file saved in /content/drive/MyDrive/CS221/DoAnCK/Logs/Roberta-ViSquad/checkpoint-3500/special_tokens_map.json\n",
            "Saving model checkpoint to /content/drive/MyDrive/CS221/DoAnCK/Logs/Roberta-ViSquad/checkpoint-4000\n",
            "Configuration saved in /content/drive/MyDrive/CS221/DoAnCK/Logs/Roberta-ViSquad/checkpoint-4000/config.json\n",
            "Model weights saved in /content/drive/MyDrive/CS221/DoAnCK/Logs/Roberta-ViSquad/checkpoint-4000/pytorch_model.bin\n",
            "tokenizer config file saved in /content/drive/MyDrive/CS221/DoAnCK/Logs/Roberta-ViSquad/checkpoint-4000/tokenizer_config.json\n",
            "Special tokens file saved in /content/drive/MyDrive/CS221/DoAnCK/Logs/Roberta-ViSquad/checkpoint-4000/special_tokens_map.json\n",
            "Saving model checkpoint to /content/drive/MyDrive/CS221/DoAnCK/Logs/Roberta-ViSquad/checkpoint-4500\n",
            "Configuration saved in /content/drive/MyDrive/CS221/DoAnCK/Logs/Roberta-ViSquad/checkpoint-4500/config.json\n",
            "Model weights saved in /content/drive/MyDrive/CS221/DoAnCK/Logs/Roberta-ViSquad/checkpoint-4500/pytorch_model.bin\n",
            "tokenizer config file saved in /content/drive/MyDrive/CS221/DoAnCK/Logs/Roberta-ViSquad/checkpoint-4500/tokenizer_config.json\n",
            "Special tokens file saved in /content/drive/MyDrive/CS221/DoAnCK/Logs/Roberta-ViSquad/checkpoint-4500/special_tokens_map.json\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1947\n",
            "  Batch size = 16\n",
            "Saving model checkpoint to /content/drive/MyDrive/CS221/DoAnCK/Logs/Roberta-ViSquad/checkpoint-5000\n",
            "Configuration saved in /content/drive/MyDrive/CS221/DoAnCK/Logs/Roberta-ViSquad/checkpoint-5000/config.json\n",
            "Model weights saved in /content/drive/MyDrive/CS221/DoAnCK/Logs/Roberta-ViSquad/checkpoint-5000/pytorch_model.bin\n",
            "tokenizer config file saved in /content/drive/MyDrive/CS221/DoAnCK/Logs/Roberta-ViSquad/checkpoint-5000/tokenizer_config.json\n",
            "Special tokens file saved in /content/drive/MyDrive/CS221/DoAnCK/Logs/Roberta-ViSquad/checkpoint-5000/special_tokens_map.json\n",
            "Saving model checkpoint to /content/drive/MyDrive/CS221/DoAnCK/Logs/Roberta-ViSquad/checkpoint-5500\n",
            "Configuration saved in /content/drive/MyDrive/CS221/DoAnCK/Logs/Roberta-ViSquad/checkpoint-5500/config.json\n",
            "Model weights saved in /content/drive/MyDrive/CS221/DoAnCK/Logs/Roberta-ViSquad/checkpoint-5500/pytorch_model.bin\n",
            "tokenizer config file saved in /content/drive/MyDrive/CS221/DoAnCK/Logs/Roberta-ViSquad/checkpoint-5500/tokenizer_config.json\n",
            "Special tokens file saved in /content/drive/MyDrive/CS221/DoAnCK/Logs/Roberta-ViSquad/checkpoint-5500/special_tokens_map.json\n",
            "Saving model checkpoint to /content/drive/MyDrive/CS221/DoAnCK/Logs/Roberta-ViSquad/checkpoint-6000\n",
            "Configuration saved in /content/drive/MyDrive/CS221/DoAnCK/Logs/Roberta-ViSquad/checkpoint-6000/config.json\n",
            "Model weights saved in /content/drive/MyDrive/CS221/DoAnCK/Logs/Roberta-ViSquad/checkpoint-6000/pytorch_model.bin\n",
            "tokenizer config file saved in /content/drive/MyDrive/CS221/DoAnCK/Logs/Roberta-ViSquad/checkpoint-6000/tokenizer_config.json\n",
            "Special tokens file saved in /content/drive/MyDrive/CS221/DoAnCK/Logs/Roberta-ViSquad/checkpoint-6000/special_tokens_map.json\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1947\n",
            "  Batch size = 16\n",
            "Saving model checkpoint to /content/drive/MyDrive/CS221/DoAnCK/Logs/Roberta-ViSquad/checkpoint-6500\n",
            "Configuration saved in /content/drive/MyDrive/CS221/DoAnCK/Logs/Roberta-ViSquad/checkpoint-6500/config.json\n",
            "Model weights saved in /content/drive/MyDrive/CS221/DoAnCK/Logs/Roberta-ViSquad/checkpoint-6500/pytorch_model.bin\n",
            "tokenizer config file saved in /content/drive/MyDrive/CS221/DoAnCK/Logs/Roberta-ViSquad/checkpoint-6500/tokenizer_config.json\n",
            "Special tokens file saved in /content/drive/MyDrive/CS221/DoAnCK/Logs/Roberta-ViSquad/checkpoint-6500/special_tokens_map.json\n",
            "Saving model checkpoint to /content/drive/MyDrive/CS221/DoAnCK/Logs/Roberta-ViSquad/checkpoint-7000\n",
            "Configuration saved in /content/drive/MyDrive/CS221/DoAnCK/Logs/Roberta-ViSquad/checkpoint-7000/config.json\n",
            "Model weights saved in /content/drive/MyDrive/CS221/DoAnCK/Logs/Roberta-ViSquad/checkpoint-7000/pytorch_model.bin\n",
            "tokenizer config file saved in /content/drive/MyDrive/CS221/DoAnCK/Logs/Roberta-ViSquad/checkpoint-7000/tokenizer_config.json\n",
            "Special tokens file saved in /content/drive/MyDrive/CS221/DoAnCK/Logs/Roberta-ViSquad/checkpoint-7000/special_tokens_map.json\n",
            "Saving model checkpoint to /content/drive/MyDrive/CS221/DoAnCK/Logs/Roberta-ViSquad/checkpoint-7500\n",
            "Configuration saved in /content/drive/MyDrive/CS221/DoAnCK/Logs/Roberta-ViSquad/checkpoint-7500/config.json\n",
            "Model weights saved in /content/drive/MyDrive/CS221/DoAnCK/Logs/Roberta-ViSquad/checkpoint-7500/pytorch_model.bin\n",
            "tokenizer config file saved in /content/drive/MyDrive/CS221/DoAnCK/Logs/Roberta-ViSquad/checkpoint-7500/tokenizer_config.json\n",
            "Special tokens file saved in /content/drive/MyDrive/CS221/DoAnCK/Logs/Roberta-ViSquad/checkpoint-7500/special_tokens_map.json\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1947\n",
            "  Batch size = 16\n",
            "Saving model checkpoint to /content/drive/MyDrive/CS221/DoAnCK/Logs/Roberta-ViSquad/checkpoint-8000\n",
            "Configuration saved in /content/drive/MyDrive/CS221/DoAnCK/Logs/Roberta-ViSquad/checkpoint-8000/config.json\n",
            "Model weights saved in /content/drive/MyDrive/CS221/DoAnCK/Logs/Roberta-ViSquad/checkpoint-8000/pytorch_model.bin\n",
            "tokenizer config file saved in /content/drive/MyDrive/CS221/DoAnCK/Logs/Roberta-ViSquad/checkpoint-8000/tokenizer_config.json\n",
            "Special tokens file saved in /content/drive/MyDrive/CS221/DoAnCK/Logs/Roberta-ViSquad/checkpoint-8000/special_tokens_map.json\n",
            "Saving model checkpoint to /content/drive/MyDrive/CS221/DoAnCK/Logs/Roberta-ViSquad/checkpoint-8500\n",
            "Configuration saved in /content/drive/MyDrive/CS221/DoAnCK/Logs/Roberta-ViSquad/checkpoint-8500/config.json\n",
            "Model weights saved in /content/drive/MyDrive/CS221/DoAnCK/Logs/Roberta-ViSquad/checkpoint-8500/pytorch_model.bin\n",
            "tokenizer config file saved in /content/drive/MyDrive/CS221/DoAnCK/Logs/Roberta-ViSquad/checkpoint-8500/tokenizer_config.json\n",
            "Special tokens file saved in /content/drive/MyDrive/CS221/DoAnCK/Logs/Roberta-ViSquad/checkpoint-8500/special_tokens_map.json\n",
            "Saving model checkpoint to /content/drive/MyDrive/CS221/DoAnCK/Logs/Roberta-ViSquad/checkpoint-9000\n",
            "Configuration saved in /content/drive/MyDrive/CS221/DoAnCK/Logs/Roberta-ViSquad/checkpoint-9000/config.json\n",
            "Model weights saved in /content/drive/MyDrive/CS221/DoAnCK/Logs/Roberta-ViSquad/checkpoint-9000/pytorch_model.bin\n",
            "tokenizer config file saved in /content/drive/MyDrive/CS221/DoAnCK/Logs/Roberta-ViSquad/checkpoint-9000/tokenizer_config.json\n",
            "Special tokens file saved in /content/drive/MyDrive/CS221/DoAnCK/Logs/Roberta-ViSquad/checkpoint-9000/special_tokens_map.json\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1947\n",
            "  Batch size = 16\n",
            "Saving model checkpoint to /content/drive/MyDrive/CS221/DoAnCK/Logs/Roberta-ViSquad/checkpoint-9500\n",
            "Configuration saved in /content/drive/MyDrive/CS221/DoAnCK/Logs/Roberta-ViSquad/checkpoint-9500/config.json\n",
            "Model weights saved in /content/drive/MyDrive/CS221/DoAnCK/Logs/Roberta-ViSquad/checkpoint-9500/pytorch_model.bin\n",
            "tokenizer config file saved in /content/drive/MyDrive/CS221/DoAnCK/Logs/Roberta-ViSquad/checkpoint-9500/tokenizer_config.json\n",
            "Special tokens file saved in /content/drive/MyDrive/CS221/DoAnCK/Logs/Roberta-ViSquad/checkpoint-9500/special_tokens_map.json\n",
            "Saving model checkpoint to /content/drive/MyDrive/CS221/DoAnCK/Logs/Roberta-ViSquad/checkpoint-10000\n",
            "Configuration saved in /content/drive/MyDrive/CS221/DoAnCK/Logs/Roberta-ViSquad/checkpoint-10000/config.json\n",
            "Model weights saved in /content/drive/MyDrive/CS221/DoAnCK/Logs/Roberta-ViSquad/checkpoint-10000/pytorch_model.bin\n",
            "tokenizer config file saved in /content/drive/MyDrive/CS221/DoAnCK/Logs/Roberta-ViSquad/checkpoint-10000/tokenizer_config.json\n",
            "Special tokens file saved in /content/drive/MyDrive/CS221/DoAnCK/Logs/Roberta-ViSquad/checkpoint-10000/special_tokens_map.json\n",
            "Saving model checkpoint to /content/drive/MyDrive/CS221/DoAnCK/Logs/Roberta-ViSquad/checkpoint-10500\n",
            "Configuration saved in /content/drive/MyDrive/CS221/DoAnCK/Logs/Roberta-ViSquad/checkpoint-10500/config.json\n",
            "Model weights saved in /content/drive/MyDrive/CS221/DoAnCK/Logs/Roberta-ViSquad/checkpoint-10500/pytorch_model.bin\n",
            "tokenizer config file saved in /content/drive/MyDrive/CS221/DoAnCK/Logs/Roberta-ViSquad/checkpoint-10500/tokenizer_config.json\n",
            "Special tokens file saved in /content/drive/MyDrive/CS221/DoAnCK/Logs/Roberta-ViSquad/checkpoint-10500/special_tokens_map.json\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1947\n",
            "  Batch size = 16\n",
            "Saving model checkpoint to /content/drive/MyDrive/CS221/DoAnCK/Logs/Roberta-ViSquad/checkpoint-11000\n",
            "Configuration saved in /content/drive/MyDrive/CS221/DoAnCK/Logs/Roberta-ViSquad/checkpoint-11000/config.json\n",
            "Model weights saved in /content/drive/MyDrive/CS221/DoAnCK/Logs/Roberta-ViSquad/checkpoint-11000/pytorch_model.bin\n",
            "tokenizer config file saved in /content/drive/MyDrive/CS221/DoAnCK/Logs/Roberta-ViSquad/checkpoint-11000/tokenizer_config.json\n",
            "Special tokens file saved in /content/drive/MyDrive/CS221/DoAnCK/Logs/Roberta-ViSquad/checkpoint-11000/special_tokens_map.json\n",
            "Saving model checkpoint to /content/drive/MyDrive/CS221/DoAnCK/Logs/Roberta-ViSquad/checkpoint-11500\n",
            "Configuration saved in /content/drive/MyDrive/CS221/DoAnCK/Logs/Roberta-ViSquad/checkpoint-11500/config.json\n",
            "Model weights saved in /content/drive/MyDrive/CS221/DoAnCK/Logs/Roberta-ViSquad/checkpoint-11500/pytorch_model.bin\n",
            "tokenizer config file saved in /content/drive/MyDrive/CS221/DoAnCK/Logs/Roberta-ViSquad/checkpoint-11500/tokenizer_config.json\n",
            "Special tokens file saved in /content/drive/MyDrive/CS221/DoAnCK/Logs/Roberta-ViSquad/checkpoint-11500/special_tokens_map.json\n",
            "Saving model checkpoint to /content/drive/MyDrive/CS221/DoAnCK/Logs/Roberta-ViSquad/checkpoint-12000\n",
            "Configuration saved in /content/drive/MyDrive/CS221/DoAnCK/Logs/Roberta-ViSquad/checkpoint-12000/config.json\n",
            "Model weights saved in /content/drive/MyDrive/CS221/DoAnCK/Logs/Roberta-ViSquad/checkpoint-12000/pytorch_model.bin\n",
            "tokenizer config file saved in /content/drive/MyDrive/CS221/DoAnCK/Logs/Roberta-ViSquad/checkpoint-12000/tokenizer_config.json\n",
            "Special tokens file saved in /content/drive/MyDrive/CS221/DoAnCK/Logs/Roberta-ViSquad/checkpoint-12000/special_tokens_map.json\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1947\n",
            "  Batch size = 16\n",
            "Saving model checkpoint to /content/drive/MyDrive/CS221/DoAnCK/Logs/Roberta-ViSquad/checkpoint-12500\n",
            "Configuration saved in /content/drive/MyDrive/CS221/DoAnCK/Logs/Roberta-ViSquad/checkpoint-12500/config.json\n",
            "Model weights saved in /content/drive/MyDrive/CS221/DoAnCK/Logs/Roberta-ViSquad/checkpoint-12500/pytorch_model.bin\n",
            "tokenizer config file saved in /content/drive/MyDrive/CS221/DoAnCK/Logs/Roberta-ViSquad/checkpoint-12500/tokenizer_config.json\n",
            "Special tokens file saved in /content/drive/MyDrive/CS221/DoAnCK/Logs/Roberta-ViSquad/checkpoint-12500/special_tokens_map.json\n",
            "Saving model checkpoint to /content/drive/MyDrive/CS221/DoAnCK/Logs/Roberta-ViSquad/checkpoint-13000\n",
            "Configuration saved in /content/drive/MyDrive/CS221/DoAnCK/Logs/Roberta-ViSquad/checkpoint-13000/config.json\n",
            "Model weights saved in /content/drive/MyDrive/CS221/DoAnCK/Logs/Roberta-ViSquad/checkpoint-13000/pytorch_model.bin\n",
            "tokenizer config file saved in /content/drive/MyDrive/CS221/DoAnCK/Logs/Roberta-ViSquad/checkpoint-13000/tokenizer_config.json\n",
            "Special tokens file saved in /content/drive/MyDrive/CS221/DoAnCK/Logs/Roberta-ViSquad/checkpoint-13000/special_tokens_map.json\n",
            "Saving model checkpoint to /content/drive/MyDrive/CS221/DoAnCK/Logs/Roberta-ViSquad/checkpoint-13500\n",
            "Configuration saved in /content/drive/MyDrive/CS221/DoAnCK/Logs/Roberta-ViSquad/checkpoint-13500/config.json\n",
            "Model weights saved in /content/drive/MyDrive/CS221/DoAnCK/Logs/Roberta-ViSquad/checkpoint-13500/pytorch_model.bin\n",
            "tokenizer config file saved in /content/drive/MyDrive/CS221/DoAnCK/Logs/Roberta-ViSquad/checkpoint-13500/tokenizer_config.json\n",
            "Special tokens file saved in /content/drive/MyDrive/CS221/DoAnCK/Logs/Roberta-ViSquad/checkpoint-13500/special_tokens_map.json\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1947\n",
            "  Batch size = 16\n",
            "Saving model checkpoint to /content/drive/MyDrive/CS221/DoAnCK/Logs/Roberta-ViSquad/checkpoint-14000\n",
            "Configuration saved in /content/drive/MyDrive/CS221/DoAnCK/Logs/Roberta-ViSquad/checkpoint-14000/config.json\n",
            "Model weights saved in /content/drive/MyDrive/CS221/DoAnCK/Logs/Roberta-ViSquad/checkpoint-14000/pytorch_model.bin\n",
            "tokenizer config file saved in /content/drive/MyDrive/CS221/DoAnCK/Logs/Roberta-ViSquad/checkpoint-14000/tokenizer_config.json\n",
            "Special tokens file saved in /content/drive/MyDrive/CS221/DoAnCK/Logs/Roberta-ViSquad/checkpoint-14000/special_tokens_map.json\n",
            "Saving model checkpoint to /content/drive/MyDrive/CS221/DoAnCK/Logs/Roberta-ViSquad/checkpoint-14500\n",
            "Configuration saved in /content/drive/MyDrive/CS221/DoAnCK/Logs/Roberta-ViSquad/checkpoint-14500/config.json\n",
            "Model weights saved in /content/drive/MyDrive/CS221/DoAnCK/Logs/Roberta-ViSquad/checkpoint-14500/pytorch_model.bin\n",
            "tokenizer config file saved in /content/drive/MyDrive/CS221/DoAnCK/Logs/Roberta-ViSquad/checkpoint-14500/tokenizer_config.json\n",
            "Special tokens file saved in /content/drive/MyDrive/CS221/DoAnCK/Logs/Roberta-ViSquad/checkpoint-14500/special_tokens_map.json\n",
            "Saving model checkpoint to /content/drive/MyDrive/CS221/DoAnCK/Logs/Roberta-ViSquad/checkpoint-15000\n",
            "Configuration saved in /content/drive/MyDrive/CS221/DoAnCK/Logs/Roberta-ViSquad/checkpoint-15000/config.json\n",
            "Model weights saved in /content/drive/MyDrive/CS221/DoAnCK/Logs/Roberta-ViSquad/checkpoint-15000/pytorch_model.bin\n",
            "tokenizer config file saved in /content/drive/MyDrive/CS221/DoAnCK/Logs/Roberta-ViSquad/checkpoint-15000/tokenizer_config.json\n",
            "Special tokens file saved in /content/drive/MyDrive/CS221/DoAnCK/Logs/Roberta-ViSquad/checkpoint-15000/special_tokens_map.json\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1947\n",
            "  Batch size = 16\n",
            "\n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n",
            "Saving model checkpoint to /content/drive/MyDrive/CS221/DoAnCK/Model/Roberta-ViSquad\n",
            "Configuration saved in /content/drive/MyDrive/CS221/DoAnCK/Model/Roberta-ViSquad/config.json\n",
            "Model weights saved in /content/drive/MyDrive/CS221/DoAnCK/Model/Roberta-ViSquad/pytorch_model.bin\n",
            "tokenizer config file saved in /content/drive/MyDrive/CS221/DoAnCK/Model/Roberta-ViSquad/tokenizer_config.json\n",
            "Special tokens file saved in /content/drive/MyDrive/CS221/DoAnCK/Model/Roberta-ViSquad/special_tokens_map.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "DLrpnVO9KYOM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Evaluation"
      ],
      "metadata": {
        "id": "RLHW604nx1HN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Test"
      ],
      "metadata": {
        "id": "i1CcM3ZOJaf-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModelForQuestionAnswering, TrainingArguments, Trainer\n",
        "from transformers import AutoTokenizer\n",
        "\n",
        "model = AutoModelForQuestionAnswering.from_pretrained(\"/content/drive/MyDrive/CS221/DoAnCK/Logs/MiniBert-ViSquad/checkpoint-15000\") \n",
        "tokenizer = AutoTokenizer.from_pretrained(\"/content/drive/MyDrive/CS221/DoAnCK/Logs/MiniBert-ViSquad/checkpoint-15000\")"
      ],
      "metadata": {
        "id": "lOMW8Fi-JZs1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_contexts, test_questions, test_answers = read_squad_val('/content/drive/MyDrive/CS221/DoAnCK/Dataset/Mailong25/train-v2.0.json')\n",
        "add_end_idx(test_answers, test_contexts)\n",
        "new_test_contexts=[]\n",
        "new_test_questions=[]\n",
        "new_test_answers=[]\n",
        "for i in range(len(test_answers)):\n",
        "  if test_answers[i]['answer_start']!=test_answers[i]['answer_end']:\n",
        "    new_test_contexts.append(test_contexts[i])\n",
        "    new_test_questions.append(test_questions[i])\n",
        "    new_test_answers.append(test_answers[i])\n",
        "(test_contexts, test_questions, test_answers)=(new_test_contexts, new_test_questions, new_test_answers)\n",
        "test_encodings = tokenizer(test_contexts, test_questions, truncation=True, padding=True, return_offsets_mapping=True,)\n",
        "add_token_positions(test_encodings, test_answers)\n",
        "test_dataset = SquadDataset(test_encodings)"
      ],
      "metadata": {
        "id": "pc0lAnaygxIv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "args = TrainingArguments(\n",
        "    f\"/content/drive/MyDrive/CS221/DoAnCK/Logs/Roberta-ViSquad-test\",#Tên folder chứa log\n",
        "    evaluation_strategy = \"epoch\",#Đánh giá sau mỗi epoch\n",
        "    save_strategy = \"epoch\",\n",
        "    learning_rate=2e-5,\n",
        "    per_device_train_batch_size=batch_size,\n",
        "    per_device_eval_batch_size=16,\n",
        "    num_train_epochs=10,\n",
        "    weight_decay=0.01\n",
        "    #push_to_hub=True,\n",
        ")"
      ],
      "metadata": {
        "id": "vn0BOog3KyDU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer = Trainer(\n",
        "    model,\n",
        "    args,\n",
        "    #train_dataset=train_dataset,\n",
        "    eval_dataset=test_dataset,\n",
        "    #data_collator=data_collator,\n",
        "    tokenizer=tokenizer,\n",
        "    compute_metrics=compute_metrics\n",
        ")\n",
        "trainer.evaluate()"
      ],
      "metadata": {
        "id": "5nUbH5LPcDjk",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 248
        },
        "outputId": "d82cff61-e477-4a84-b6c1-fed0e00d884c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "***** Running Evaluation *****\n",
            "  Num examples = 985\n",
            "  Batch size = 16\n",
            "The following columns in the evaluation set don't have a corresponding argument in `RobertaForQuestionAnswering.forward` and have been ignored: offset_mapping. If offset_mapping are not expected by `RobertaForQuestionAnswering.forward`,  you can safely ignore this message.\n",
            "You're using a RobertaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='62' max='62' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [62/62 16:57]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'eval_loss': 3.7535665035247803,\n",
              " 'eval_exact_match': 0.241,\n",
              " 'eval_f1_score': 0.527,\n",
              " 'eval_runtime': 1037.9302,\n",
              " 'eval_samples_per_second': 0.949,\n",
              " 'eval_steps_per_second': 0.06}"
            ]
          },
          "metadata": {},
          "execution_count": 115
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Predict"
      ],
      "metadata": {
        "id": "gVjsbfooPe6i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def Predict(contexts, questions, trainer):\n",
        "  test_encodings = trainer.tokenizer(contexts, questions, truncation=True, padding=True, return_overflowing_tokens=True, return_offsets_mapping=True,)\n",
        "  test_dataset = SquadDataset(test_encodings)\n",
        "  \n",
        "  result = trainer.predict(test_dataset, )\n",
        "  predictions = np.argmax(result.predictions, axis =-1)\n",
        "  metrics = result.metrics\n",
        "  \n",
        "  answers = []\n",
        "  for i in range(len(contexts)):\n",
        "    start = test_encodings['offset_mapping'][0][predictions[0][0]][0]\n",
        "    end = test_encodings['offset_mapping'][0][predictions[1][0]][1]\n",
        "    answers.append(contexts[i][start: end])\n",
        "  return answers[0]"
      ],
      "metadata": {
        "id": "yAHmD-40TmJj"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "a = Predict(['Nam sinh ra và lớn lên ở Thủ Đức. Nam học công nghệ thông tin'], [\"Nam học gì\"], trainer)\n",
        "a"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        },
        "id": "G2JfahLWTbVM",
        "outputId": "b087a44e-c5e0-4278-8f1e-1c4e094fee10"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "***** Running Prediction *****\n",
            "  Num examples = 1\n",
            "  Batch size = 16\n",
            "The following columns in the test set don't have a corresponding argument in `XLMRobertaForQuestionAnswering.forward` and have been ignored: overflow_to_sample_mapping, offset_mapping. If overflow_to_sample_mapping, offset_mapping are not expected by `XLMRobertaForQuestionAnswering.forward`,  you can safely ignore this message.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' công nghệ thông tin'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(0, 100, 10):\n",
        "  print(\"Context:\", test_contexts[i])\n",
        "  print(\"Question:\", test_questions[i])\n",
        "  print(\"Trả lời:\", Predict([test_contexts[i]], [test_questions[i]], trainer))\n",
        "  print(\"\\n==========\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "JcwJHQjiVQuZ",
        "outputId": "e51d150b-e22d-4b77-9e02-3978ff1cc38c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "***** Running Prediction *****\n",
            "  Num examples = 1\n",
            "  Batch size = 16\n",
            "The following columns in the test set don't have a corresponding argument in `XLMRobertaForQuestionAnswering.forward` and have been ignored: overflow_to_sample_mapping, offset_mapping. If overflow_to_sample_mapping, offset_mapping are not expected by `XLMRobertaForQuestionAnswering.forward`,  you can safely ignore this message.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Context: Narendra Damodardas Modi ( tiếng Gujarat : નરેન્દ્ર દામોદરદાસ મોદી , [ nəreːnd̪rə d̪ɑːmoːd̪ərəd̪ɑːsə moːd̪iː ] ( nghe ) , tiếng Hindi : नरेन्द्र दामोदरदास मोदी , sinh ngày 17 tháng 9 năm 1950 ) là Thủ tướng Ấn Độ thứ 15 . Ông là thủ lĩnh của đảng Bharatiya Janata ( đảng Nhân dân ) , từng giữ chức Thủ tịch bộ trưởng Gujarat từ năm 2001 đến năm 2014 . Ông đại diện cho Varanasi tại Lok Sabha .\n",
            "Question: Ai là thủ tướng Ấn Độ hiện tại\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "***** Running Prediction *****\n",
            "  Num examples = 1\n",
            "  Batch size = 16\n",
            "The following columns in the test set don't have a corresponding argument in `XLMRobertaForQuestionAnswering.forward` and have been ignored: overflow_to_sample_mapping, offset_mapping. If overflow_to_sample_mapping, offset_mapping are not expected by `XLMRobertaForQuestionAnswering.forward`,  you can safely ignore this message.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trả lời: Narendra Damodardas Modi\n",
            "\n",
            "==========\n",
            "Context: Chia sẻ với VnExpress sau khi được Forbes công nhận là tỷ phú USD với 1,3 tỷ USD tài sản , ông Trần Đình Long - Chủ tịch HĐQT Tập đoàn Hoà Phát , thú nhận đã lâu không làm việc để vì mục tiêu kiếm một con số cụ thể bao nhiêu tiền trong ngày .\n",
            "Question: Ai là chủ tịch tập đoàn Hòa Phát\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "***** Running Prediction *****\n",
            "  Num examples = 1\n",
            "  Batch size = 16\n",
            "The following columns in the test set don't have a corresponding argument in `XLMRobertaForQuestionAnswering.forward` and have been ignored: overflow_to_sample_mapping, offset_mapping. If overflow_to_sample_mapping, offset_mapping are not expected by `XLMRobertaForQuestionAnswering.forward`,  you can safely ignore this message.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trả lời:  ông Trần Đình Long\n",
            "\n",
            "==========\n",
            "Context: Nhà Trắng ngày 29/4 cho biết , Tổng thống Mỹ Donald Trump đã mời Tổng thống Philippines Rodrigo Duterte tới thăm Mỹ .\n",
            "Question: Ai là tổng thống Philippines\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "***** Running Prediction *****\n",
            "  Num examples = 1\n",
            "  Batch size = 16\n",
            "The following columns in the test set don't have a corresponding argument in `XLMRobertaForQuestionAnswering.forward` and have been ignored: overflow_to_sample_mapping, offset_mapping. If overflow_to_sample_mapping, offset_mapping are not expected by `XLMRobertaForQuestionAnswering.forward`,  you can safely ignore this message.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trả lời:  Rodrigo Duterte\n",
            "\n",
            "==========\n",
            "Context: Sáng ngày 25-2 , Bộ trưởng Bộ TT-TT Nguyễn Mạnh Hùng , Chủ tịch UBND TP Hà Nội Nguyễn Đức Chung , Thứ trưởng Bộ Ngoại giao Lê Hoài Trung sáng 25-2 đã chủ trì cuộc họp báo tại Trung tâm ...\n",
            "Question: Bộ trưởng bộ ngoại giao Việt Nam là ai\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "***** Running Prediction *****\n",
            "  Num examples = 1\n",
            "  Batch size = 16\n",
            "The following columns in the test set don't have a corresponding argument in `XLMRobertaForQuestionAnswering.forward` and have been ignored: overflow_to_sample_mapping, offset_mapping. If overflow_to_sample_mapping, offset_mapping are not expected by `XLMRobertaForQuestionAnswering.forward`,  you can safely ignore this message.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trả lời:  Lê Hoài Trung\n",
            "\n",
            "==========\n",
            "Context: Khi ra mắt lần đầu vào năm 1993 , bộ phim Jurassic Park ( Công viên kỷ Jura ) của đạo diễn kỳ tài Steven Spielberg đã trở thành một trong những bom tấn kinh điển về công nghệ CGI ( công nghệ mô phỏng hình ảnh ) cũng như thổi bay mọi phòng vé thời bấy giờ . Tiếp theo là các phần phim The Lost World : Jurassic Park ( 1997 ) và Jurassic Park III ( 2001 ) .\n",
            "Question: Bộ phim Jurassic Park do ai làm đạo diễn?\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "***** Running Prediction *****\n",
            "  Num examples = 1\n",
            "  Batch size = 16\n",
            "The following columns in the test set don't have a corresponding argument in `XLMRobertaForQuestionAnswering.forward` and have been ignored: overflow_to_sample_mapping, offset_mapping. If overflow_to_sample_mapping, offset_mapping are not expected by `XLMRobertaForQuestionAnswering.forward`,  you can safely ignore this message.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trả lời:  Steven Spielberg\n",
            "\n",
            "==========\n",
            "Context: ( VNF ) - Công ty Cổ phần Vinhomes ( HoSE : VHM ) vừa thông báo bà Nguyễn Diệu Linh , thành viên HĐQT kiêm Tổng giám đốc đã được bầu vào vị trí Phó Chủ tịch HĐQT của công ty .\n",
            "Question: tổng giám đốc công ty cổ phần Vinhomes\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "***** Running Prediction *****\n",
            "  Num examples = 1\n",
            "  Batch size = 16\n",
            "The following columns in the test set don't have a corresponding argument in `XLMRobertaForQuestionAnswering.forward` and have been ignored: overflow_to_sample_mapping, offset_mapping. If overflow_to_sample_mapping, offset_mapping are not expected by `XLMRobertaForQuestionAnswering.forward`,  you can safely ignore this message.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trả lời: ,\n",
            "\n",
            "==========\n",
            "Context: Một đoạn clip ghi lại câu trả lời của phi hành gia Buzz Aldrin , người thứ 2 đặt chân lên Mặt trăng thừa nhận ông chưa từng đặt chân lên Mặt trăng , đã được đăng tải lên mạng .\n",
            "Question: Ai là người thứ hai đặt chân lên Mặt trăng?\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "***** Running Prediction *****\n",
            "  Num examples = 1\n",
            "  Batch size = 16\n",
            "The following columns in the test set don't have a corresponding argument in `XLMRobertaForQuestionAnswering.forward` and have been ignored: overflow_to_sample_mapping, offset_mapping. If overflow_to_sample_mapping, offset_mapping are not expected by `XLMRobertaForQuestionAnswering.forward`,  you can safely ignore this message.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trả lời:  Buzz Aldrin ,\n",
            "\n",
            "==========\n",
            "Context: Ông Putin lần đầu tiên nắm quyền tổng thống Nga vào ngày 31/12/1999 , sau khi tổng thống đầu tiên của Nga , ông Boris Yeltsin bất ngờ tuyên bố thoái vị và trao quyền lại cho thủ tướng Vladimir Putin , khi đó vẫn là cái tên ít người biết đến . Ba tháng sau , ông đắc cử tổng thống lần đầu tiên .\n",
            "Question: Tổng thống Nga hiện tại là ai\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "***** Running Prediction *****\n",
            "  Num examples = 1\n",
            "  Batch size = 16\n",
            "The following columns in the test set don't have a corresponding argument in `XLMRobertaForQuestionAnswering.forward` and have been ignored: overflow_to_sample_mapping, offset_mapping. If overflow_to_sample_mapping, offset_mapping are not expected by `XLMRobertaForQuestionAnswering.forward`,  you can safely ignore this message.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trả lời: Ông Putin lần đầu tiên nắm quyền tổng thống Nga vào ngày 31/12/1999 , sau khi tổng thống đầu tiên của Nga , ông Boris Yeltsin\n",
            "\n",
            "==========\n",
            "Context: Cùng với đó , Hội đồng quản trị FECON cũng đã bổ nhiệm ông Nguyễn Văn Thanh , Tổng giám đốc điều hành FECON chính thức đảm nhận vị trí Tổng giám đốc FECON từ ngày 8/11/2018 .\n",
            "Question: tổng giám đốc công ty Fecon\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "***** Running Prediction *****\n",
            "  Num examples = 1\n",
            "  Batch size = 16\n",
            "The following columns in the test set don't have a corresponding argument in `XLMRobertaForQuestionAnswering.forward` and have been ignored: overflow_to_sample_mapping, offset_mapping. If overflow_to_sample_mapping, offset_mapping are not expected by `XLMRobertaForQuestionAnswering.forward`,  you can safely ignore this message.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trả lời: ,\n",
            "\n",
            "==========\n",
            "Context: “ Vài năm nay , mọi người nhìn thép rất xấu , nhưng thép vẫn được coi là bánh mì của công nghiệp và tại những nước công nghiệp hoá mới như chúng ta , nhu cầu thép vẫn còn tăng ” , đó là chia sẻ chân tình của ông Trần Đình Long , Chủ tịch HĐQT Tập đoàn Hoà Phát khi nói về những mối quan tâm của dư luận thời gian gần đây trước những biến động lớn trong ngành thép lẫn tương lai của ngành này tại Việt Nam .\n",
            "Question: chủ tịch tập đoàn Hòa Phát\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trả lời: ,\n",
            "\n",
            "==========\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Demo"
      ],
      "metadata": {
        "id": "wxgiIBWXDS25"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Context: My name is Sylvain.\\nQuestion: What is your name?\\nAnswer: Sylvain\\nAnswer_start: 11\")#\\nAnswer_end: 18\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e9f6cWkv0hga",
        "outputId": "d74fb9c7-73ef-4866-8b0c-c2c70f8677e0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Context: My name is Sylvain.\n",
            "Question: What is your name?\n",
            "Answer: Sylvain\n",
            "Answer_start: 11\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "decode = tokenizer(\"My name is Sylvain.\", \"What is your name?\", return_offsets_mapping=True)\n",
        "for i in decode:\n",
        "  print(f\"{i}: {decode[i]}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vpy4ql5Azbxc",
        "outputId": "ddaa870e-fd81-4e4c-aa10-819b41995b9c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "input_ids: [0, 2646, 9351, 83, 100973, 21845, 5, 2, 2, 4865, 83, 935, 9351, 32, 2]\n",
            "attention_mask: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
            "offset_mapping: [(0, 0), (0, 2), (2, 7), (7, 10), (10, 15), (15, 18), (18, 19), (0, 0), (0, 0), (0, 4), (4, 7), (7, 12), (12, 17), (17, 18), (0, 0)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "add_token_positions(decode, [{'answer_start': 11, 'text': 'Sylvain', 'answer_end': 18}])\n",
        "tokenizer.decode(decode[\"input_ids\"])"
      ],
      "metadata": {
        "id": "rEa2dSCK2KYT",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "4b72b9c9-cc12-4df4-fa95-98283371d8c2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'<s> My name is Sylvain.</s></s> What is your name?</s>'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 98
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in decode:\n",
        "  print(f\"{i}: {decode[i]}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JJS4zVyVzs-B",
        "outputId": "16b65163-be0d-475d-a834-c2e69f628c4e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "input_ids: [0, 2646, 9351, 83, 100973, 21845, 5, 2, 2, 4865, 83, 935, 9351, 32, 2]\n",
            "attention_mask: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
            "offset_mapping: [(0, 0), (0, 2), (2, 7), (7, 10), (10, 15), (15, 18), (18, 19), (0, 0), (0, 0), (0, 4), (4, 7), (7, 12), (12, 17), (17, 18), (0, 0)]\n",
            "start_positions: [4]\n",
            "end_positions: [5]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"My name is Sylvain.\"[11:18]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "1skR5Sn12xfb",
        "outputId": "c13fa78e-ab72-40f0-be95-1ec05f8f2e3f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Sylvain'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 83
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Demo model"
      ],
      "metadata": {
        "id": "B_QtTS9oDkZ9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModelForQuestionAnswering, TrainingArguments, Trainer\n",
        "from transformers import AutoTokenizer"
      ],
      "metadata": {
        "id": "aMbmkYOOO-xe"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model1 = AutoModelForQuestionAnswering.from_pretrained(\"/content/drive/MyDrive/CS221/DoAnCK/Model/Roberta\") \n",
        "tokenizer1 = AutoTokenizer.from_pretrained(\"/content/drive/MyDrive/CS221/DoAnCK/Model/Roberta\")\n",
        "\n",
        "#model2 = AutoModelForQuestionAnswering.from_pretrained(\"/content/drive/MyDrive/CS221/DoAnCK/Model/Minibert\") \n",
        "#tokenizer2 = AutoTokenizer.from_pretrained(\"/content/drive/MyDrive/CS221/DoAnCK/Model/Minibert\")\n",
        "\n",
        "#model3 = AutoModelForQuestionAnswering.from_pretrained(\"/content/drive/MyDrive/CS221/DoAnCK/Model/distilBERT_0-3500\") \n",
        "#tokenizer3 = AutoTokenizer.from_pretrained(\"/content/drive/MyDrive/CS221/DoAnCK/Model/distilBERT_0-3500\")\n",
        "\n",
        "#model4 = AutoModelForQuestionAnswering.from_pretrained(\"/content/drive/MyDrive/CS221/DoAnCK/Model/AlBERT\") \n",
        "#tokenizer4 = AutoTokenizer.from_pretrained(\"/content/drive/MyDrive/CS221/DoAnCK/Model/AlBERT\")"
      ],
      "metadata": {
        "id": "c_MMjqyhEHZp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def Demo(path, args):\n",
        "  model = AutoModelForQuestionAnswering.from_pretrained(path) \n",
        "  tokenizer = AutoTokenizer.from_pretrained(path)\n",
        "\n",
        "  #Load data\n",
        "  test_contexts, test_questions, test_answers = read_squad_val('/content/drive/MyDrive/CS221/DoAnCK/Dataset/Mailong25/train-v2.0.json')\n",
        "  add_end_idx(test_answers, test_contexts)\n",
        "  new_test_contexts=[]\n",
        "  new_test_questions=[]\n",
        "  new_test_answers=[]\n",
        "  for i in range(len(test_answers)):\n",
        "    if test_answers[i]['answer_start']!=test_answers[i]['answer_end']:\n",
        "      new_test_contexts.append(test_contexts[i])\n",
        "      new_test_questions.append(test_questions[i])\n",
        "      new_test_answers.append(test_answers[i])\n",
        "  (test_contexts, test_questions, test_answers)=(new_test_contexts, new_test_questions, new_test_answers)\n",
        "  test_encodings = tokenizer(test_contexts, test_questions, truncation=True, padding=True, return_offsets_mapping=True,)\n",
        "  add_token_positions(test_encodings, test_answers)\n",
        "  test_dataset = SquadDataset(test_encodings)\n",
        "\n",
        "  #Set trainer\n",
        "\n",
        "  trainer = Trainer(\n",
        "    model,\n",
        "    args,\n",
        "    #train_dataset=train_dataset,\n",
        "    eval_dataset=test_dataset,\n",
        "    #data_collator=data_collator,\n",
        "    tokenizer=tokenizer,\n",
        "    compute_metrics=compute_metrics)\n",
        "\n",
        "  #Predict\n",
        "  context = []\n",
        "  question = []\n",
        "  answer = []\n",
        "  for i in range(0, 100, 10):\n",
        "    context.append(test_contexts[i])\n",
        "    question.append(test_questions[i])\n",
        "    answer.append(Predict([test_contexts[i]], [test_questions[i]], trainer))\n",
        "    \n",
        "  return context, question, answer"
      ],
      "metadata": {
        "id": "6RXVpj0-GvPS"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "args = TrainingArguments(\n",
        "    f\"/content/drive/MyDrive/CS221/DoAnCK/Logs/test\",#Tên folder chứa log\n",
        "    evaluation_strategy = \"epoch\",#Đánh giá sau mỗi epoch\n",
        "    save_strategy = \"epoch\",\n",
        "    learning_rate=2e-5,\n",
        "    per_device_train_batch_size=8,\n",
        "    per_device_eval_batch_size=16,\n",
        "    num_train_epochs=10,\n",
        "    weight_decay=0.01\n",
        "    #push_to_hub=True,\n",
        ")"
      ],
      "metadata": {
        "id": "rOc1QDOzEHZq"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model1"
      ],
      "metadata": {
        "id": "jkWjAmPQUnmU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "a, b, c = Demo(\"/content/drive/MyDrive/CS221/DoAnCK/Model/Roberta\", args)\n",
        "for i in range(len(a)):\n",
        "  print(f\"Ex {i}: \\n\\tContext: {a[i]}\\n\\tQuestion: {b[i]}\\n\\tAnswer: {c[i]}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qhk3_WguPosa",
        "outputId": "4739f2da-5c31-49b6-e2d8-13b905d3c069"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ex 0: \n",
            "\tContext: Narendra Damodardas Modi ( tiếng Gujarat : નરેન્દ્ર દામોદરદાસ મોદી , [ nəreːnd̪rə d̪ɑːmoːd̪ərəd̪ɑːsə moːd̪iː ] ( nghe ) , tiếng Hindi : नरेन्द्र दामोदरदास मोदी , sinh ngày 17 tháng 9 năm 1950 ) là Thủ tướng Ấn Độ thứ 15 . Ông là thủ lĩnh của đảng Bharatiya Janata ( đảng Nhân dân ) , từng giữ chức Thủ tịch bộ trưởng Gujarat từ năm 2001 đến năm 2014 . Ông đại diện cho Varanasi tại Lok Sabha .\n",
            "\tQuestion: Ai là thủ tướng Ấn Độ hiện tại\n",
            "\tAnswer: Narendra Damodardas Modi\n",
            "Ex 1: \n",
            "\tContext: Chia sẻ với VnExpress sau khi được Forbes công nhận là tỷ phú USD với 1,3 tỷ USD tài sản , ông Trần Đình Long - Chủ tịch HĐQT Tập đoàn Hoà Phát , thú nhận đã lâu không làm việc để vì mục tiêu kiếm một con số cụ thể bao nhiêu tiền trong ngày .\n",
            "\tQuestion: Ai là chủ tịch tập đoàn Hòa Phát\n",
            "\tAnswer:  ông Trần Đình Long\n",
            "Ex 2: \n",
            "\tContext: Nhà Trắng ngày 29/4 cho biết , Tổng thống Mỹ Donald Trump đã mời Tổng thống Philippines Rodrigo Duterte tới thăm Mỹ .\n",
            "\tQuestion: Ai là tổng thống Philippines\n",
            "\tAnswer:  Rodrigo Duterte\n",
            "Ex 3: \n",
            "\tContext: Sáng ngày 25-2 , Bộ trưởng Bộ TT-TT Nguyễn Mạnh Hùng , Chủ tịch UBND TP Hà Nội Nguyễn Đức Chung , Thứ trưởng Bộ Ngoại giao Lê Hoài Trung sáng 25-2 đã chủ trì cuộc họp báo tại Trung tâm ...\n",
            "\tQuestion: Bộ trưởng bộ ngoại giao Việt Nam là ai\n",
            "\tAnswer:  Lê Hoài Trung\n",
            "Ex 4: \n",
            "\tContext: Khi ra mắt lần đầu vào năm 1993 , bộ phim Jurassic Park ( Công viên kỷ Jura ) của đạo diễn kỳ tài Steven Spielberg đã trở thành một trong những bom tấn kinh điển về công nghệ CGI ( công nghệ mô phỏng hình ảnh ) cũng như thổi bay mọi phòng vé thời bấy giờ . Tiếp theo là các phần phim The Lost World : Jurassic Park ( 1997 ) và Jurassic Park III ( 2001 ) .\n",
            "\tQuestion: Bộ phim Jurassic Park do ai làm đạo diễn?\n",
            "\tAnswer:  Steven Spielberg\n",
            "Ex 5: \n",
            "\tContext: ( VNF ) - Công ty Cổ phần Vinhomes ( HoSE : VHM ) vừa thông báo bà Nguyễn Diệu Linh , thành viên HĐQT kiêm Tổng giám đốc đã được bầu vào vị trí Phó Chủ tịch HĐQT của công ty .\n",
            "\tQuestion: tổng giám đốc công ty cổ phần Vinhomes\n",
            "\tAnswer: ,\n",
            "Ex 6: \n",
            "\tContext: Một đoạn clip ghi lại câu trả lời của phi hành gia Buzz Aldrin , người thứ 2 đặt chân lên Mặt trăng thừa nhận ông chưa từng đặt chân lên Mặt trăng , đã được đăng tải lên mạng .\n",
            "\tQuestion: Ai là người thứ hai đặt chân lên Mặt trăng?\n",
            "\tAnswer:  Buzz Aldrin ,\n",
            "Ex 7: \n",
            "\tContext: Ông Putin lần đầu tiên nắm quyền tổng thống Nga vào ngày 31/12/1999 , sau khi tổng thống đầu tiên của Nga , ông Boris Yeltsin bất ngờ tuyên bố thoái vị và trao quyền lại cho thủ tướng Vladimir Putin , khi đó vẫn là cái tên ít người biết đến . Ba tháng sau , ông đắc cử tổng thống lần đầu tiên .\n",
            "\tQuestion: Tổng thống Nga hiện tại là ai\n",
            "\tAnswer: Ông Putin lần đầu tiên nắm quyền tổng thống Nga vào ngày 31/12/1999 , sau khi tổng thống đầu tiên của Nga , ông Boris Yeltsin\n",
            "Ex 8: \n",
            "\tContext: Cùng với đó , Hội đồng quản trị FECON cũng đã bổ nhiệm ông Nguyễn Văn Thanh , Tổng giám đốc điều hành FECON chính thức đảm nhận vị trí Tổng giám đốc FECON từ ngày 8/11/2018 .\n",
            "\tQuestion: tổng giám đốc công ty Fecon\n",
            "\tAnswer: ,\n",
            "Ex 9: \n",
            "\tContext: “ Vài năm nay , mọi người nhìn thép rất xấu , nhưng thép vẫn được coi là bánh mì của công nghiệp và tại những nước công nghiệp hoá mới như chúng ta , nhu cầu thép vẫn còn tăng ” , đó là chia sẻ chân tình của ông Trần Đình Long , Chủ tịch HĐQT Tập đoàn Hoà Phát khi nói về những mối quan tâm của dư luận thời gian gần đây trước những biến động lớn trong ngành thép lẫn tương lai của ngành này tại Việt Nam .\n",
            "\tQuestion: chủ tịch tập đoàn Hòa Phát\n",
            "\tAnswer: ,\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model 2"
      ],
      "metadata": {
        "id": "dCm_hw8qUqyG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "a, b, c = Demo(\"/content/drive/MyDrive/CS221/DoAnCK/Model/Minibert\", args)\n",
        "for i in range(len(a)):\n",
        "  print(f\"Ex {i}: \\n\\tContext: {a[i]}\\n\\tQuestion: {b[i]}\\n\\tAnswer: {c[i]}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "E-vGlHUkUpSf",
        "outputId": "92559e43-fbf2-40e9-8d4e-a1821770961d"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loading configuration file /content/drive/MyDrive/CS221/DoAnCK/Model/Minibert/config.json\n",
            "Model config RobertaConfig {\n",
            "  \"_name_or_path\": \"/content/drive/MyDrive/CS221/DoAnCK/Model/Minibert\",\n",
            "  \"architectures\": [\n",
            "    \"RobertaForQuestionAnswering\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"bos_token_id\": 0,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"language\": \"english\",\n",
            "  \"layer_norm_eps\": 1e-05,\n",
            "  \"max_position_embeddings\": 514,\n",
            "  \"model_type\": \"roberta\",\n",
            "  \"name\": \"Roberta\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 6,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"torch_dtype\": \"float32\",\n",
            "  \"transformers_version\": \"4.26.0\",\n",
            "  \"type_vocab_size\": 1,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 50265\n",
            "}\n",
            "\n",
            "loading weights file /content/drive/MyDrive/CS221/DoAnCK/Model/Minibert/pytorch_model.bin\n",
            "All model checkpoint weights were used when initializing RobertaForQuestionAnswering.\n",
            "\n",
            "All the weights of RobertaForQuestionAnswering were initialized from the model checkpoint at /content/drive/MyDrive/CS221/DoAnCK/Model/Minibert.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use RobertaForQuestionAnswering for predictions without further training.\n",
            "loading file vocab.json\n",
            "loading file merges.txt\n",
            "loading file tokenizer.json\n",
            "loading file added_tokens.json\n",
            "loading file special_tokens_map.json\n",
            "loading file tokenizer_config.json\n",
            "***** Running Prediction *****\n",
            "  Num examples = 1\n",
            "  Batch size = 16\n",
            "The following columns in the test set don't have a corresponding argument in `RobertaForQuestionAnswering.forward` and have been ignored: overflow_to_sample_mapping, offset_mapping. If overflow_to_sample_mapping, offset_mapping are not expected by `RobertaForQuestionAnswering.forward`,  you can safely ignore this message.\n",
            "You're using a RobertaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "***** Running Prediction *****\n",
            "  Num examples = 1\n",
            "  Batch size = 16\n",
            "The following columns in the test set don't have a corresponding argument in `RobertaForQuestionAnswering.forward` and have been ignored: overflow_to_sample_mapping, offset_mapping. If overflow_to_sample_mapping, offset_mapping are not expected by `RobertaForQuestionAnswering.forward`,  you can safely ignore this message.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "***** Running Prediction *****\n",
            "  Num examples = 1\n",
            "  Batch size = 16\n",
            "The following columns in the test set don't have a corresponding argument in `RobertaForQuestionAnswering.forward` and have been ignored: overflow_to_sample_mapping, offset_mapping. If overflow_to_sample_mapping, offset_mapping are not expected by `RobertaForQuestionAnswering.forward`,  you can safely ignore this message.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "***** Running Prediction *****\n",
            "  Num examples = 1\n",
            "  Batch size = 16\n",
            "The following columns in the test set don't have a corresponding argument in `RobertaForQuestionAnswering.forward` and have been ignored: overflow_to_sample_mapping, offset_mapping. If overflow_to_sample_mapping, offset_mapping are not expected by `RobertaForQuestionAnswering.forward`,  you can safely ignore this message.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "***** Running Prediction *****\n",
            "  Num examples = 1\n",
            "  Batch size = 16\n",
            "The following columns in the test set don't have a corresponding argument in `RobertaForQuestionAnswering.forward` and have been ignored: overflow_to_sample_mapping, offset_mapping. If overflow_to_sample_mapping, offset_mapping are not expected by `RobertaForQuestionAnswering.forward`,  you can safely ignore this message.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "***** Running Prediction *****\n",
            "  Num examples = 1\n",
            "  Batch size = 16\n",
            "The following columns in the test set don't have a corresponding argument in `RobertaForQuestionAnswering.forward` and have been ignored: overflow_to_sample_mapping, offset_mapping. If overflow_to_sample_mapping, offset_mapping are not expected by `RobertaForQuestionAnswering.forward`,  you can safely ignore this message.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "***** Running Prediction *****\n",
            "  Num examples = 1\n",
            "  Batch size = 16\n",
            "The following columns in the test set don't have a corresponding argument in `RobertaForQuestionAnswering.forward` and have been ignored: overflow_to_sample_mapping, offset_mapping. If overflow_to_sample_mapping, offset_mapping are not expected by `RobertaForQuestionAnswering.forward`,  you can safely ignore this message.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "***** Running Prediction *****\n",
            "  Num examples = 1\n",
            "  Batch size = 16\n",
            "The following columns in the test set don't have a corresponding argument in `RobertaForQuestionAnswering.forward` and have been ignored: overflow_to_sample_mapping, offset_mapping. If overflow_to_sample_mapping, offset_mapping are not expected by `RobertaForQuestionAnswering.forward`,  you can safely ignore this message.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "***** Running Prediction *****\n",
            "  Num examples = 1\n",
            "  Batch size = 16\n",
            "The following columns in the test set don't have a corresponding argument in `RobertaForQuestionAnswering.forward` and have been ignored: overflow_to_sample_mapping, offset_mapping. If overflow_to_sample_mapping, offset_mapping are not expected by `RobertaForQuestionAnswering.forward`,  you can safely ignore this message.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "***** Running Prediction *****\n",
            "  Num examples = 1\n",
            "  Batch size = 16\n",
            "The following columns in the test set don't have a corresponding argument in `RobertaForQuestionAnswering.forward` and have been ignored: overflow_to_sample_mapping, offset_mapping. If overflow_to_sample_mapping, offset_mapping are not expected by `RobertaForQuestionAnswering.forward`,  you can safely ignore this message.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ex 0: \n",
            "\tContext: Narendra Damodardas Modi ( tiếng Gujarat : નરેન્દ્ર દામોદરદાસ મોદી , [ nəreːnd̪rə d̪ɑːmoːd̪ərəd̪ɑːsə moːd̪iː ] ( nghe ) , tiếng Hindi : नरेन्द्र दामोदरदास मोदी , sinh ngày 17 tháng 9 năm 1950 ) là Thủ tướng Ấn Độ thứ 15 . Ông là thủ lĩnh của đảng Bharatiya Janata ( đảng Nhân dân ) , từng giữ chức Thủ tịch bộ trưởng Gujarat từ năm 2001 đến năm 2014 . Ông đại diện cho Varanasi tại Lok Sabha .\n",
            "\tQuestion: Ai là thủ tướng Ấn Độ hiện tại\n",
            "\tAnswer: Narendra Damodardas Modi\n",
            "Ex 1: \n",
            "\tContext: Chia sẻ với VnExpress sau khi được Forbes công nhận là tỷ phú USD với 1,3 tỷ USD tài sản , ông Trần Đình Long - Chủ tịch HĐQT Tập đoàn Hoà Phát , thú nhận đã lâu không làm việc để vì mục tiêu kiếm một con số cụ thể bao nhiêu tiền trong ngày .\n",
            "\tQuestion: Ai là chủ tịch tập đoàn Hòa Phát\n",
            "\tAnswer: Chia sẻ với VnExpress\n",
            "Ex 2: \n",
            "\tContext: Nhà Trắng ngày 29/4 cho biết , Tổng thống Mỹ Donald Trump đã mời Tổng thống Philippines Rodrigo Duterte tới thăm Mỹ .\n",
            "\tQuestion: Ai là tổng thống Philippines\n",
            "\tAnswer: Donald Trump\n",
            "Ex 3: \n",
            "\tContext: Sáng ngày 25-2 , Bộ trưởng Bộ TT-TT Nguyễn Mạnh Hùng , Chủ tịch UBND TP Hà Nội Nguyễn Đức Chung , Thứ trưởng Bộ Ngoại giao Lê Hoài Trung sáng 25-2 đã chủ trì cuộc họp báo tại Trung tâm ...\n",
            "\tQuestion: Bộ trưởng bộ ngoại giao Việt Nam là ai\n",
            "\tAnswer: ,\n",
            "Ex 4: \n",
            "\tContext: Khi ra mắt lần đầu vào năm 1993 , bộ phim Jurassic Park ( Công viên kỷ Jura ) của đạo diễn kỳ tài Steven Spielberg đã trở thành một trong những bom tấn kinh điển về công nghệ CGI ( công nghệ mô phỏng hình ảnh ) cũng như thổi bay mọi phòng vé thời bấy giờ . Tiếp theo là các phần phim The Lost World : Jurassic Park ( 1997 ) và Jurassic Park III ( 2001 ) .\n",
            "\tQuestion: Bộ phim Jurassic Park do ai làm đạo diễn?\n",
            "\tAnswer: Công viên kỷ Jura )\n",
            "Ex 5: \n",
            "\tContext: ( VNF ) - Công ty Cổ phần Vinhomes ( HoSE : VHM ) vừa thông báo bà Nguyễn Diệu Linh , thành viên HĐQT kiêm Tổng giám đốc đã được bầu vào vị trí Phó Chủ tịch HĐQT của công ty .\n",
            "\tQuestion: tổng giám đốc công ty cổ phần Vinhomes\n",
            "\tAnswer: Tổng giám đốc\n",
            "Ex 6: \n",
            "\tContext: Một đoạn clip ghi lại câu trả lời của phi hành gia Buzz Aldrin , người thứ 2 đặt chân lên Mặt trăng thừa nhận ông chưa từng đặt chân lên Mặt trăng , đã được đăng tải lên mạng .\n",
            "\tQuestion: Ai là người thứ hai đặt chân lên Mặt trăng?\n",
            "\tAnswer: Buzz Aldrin ,\n",
            "Ex 7: \n",
            "\tContext: Ông Putin lần đầu tiên nắm quyền tổng thống Nga vào ngày 31/12/1999 , sau khi tổng thống đầu tiên của Nga , ông Boris Yeltsin bất ngờ tuyên bố thoái vị và trao quyền lại cho thủ tướng Vladimir Putin , khi đó vẫn là cái tên ít người biết đến . Ba tháng sau , ông đắc cử tổng thống lần đầu tiên .\n",
            "\tQuestion: Tổng thống Nga hiện tại là ai\n",
            "\tAnswer: Boris Yeltsin\n",
            "Ex 8: \n",
            "\tContext: Cùng với đó , Hội đồng quản trị FECON cũng đã bổ nhiệm ông Nguyễn Văn Thanh , Tổng giám đốc điều hành FECON chính thức đảm nhận vị trí Tổng giám đốc FECON từ ngày 8/11/2018 .\n",
            "\tQuestion: tổng giám đốc công ty Fecon\n",
            "\tAnswer: ,\n",
            "Ex 9: \n",
            "\tContext: “ Vài năm nay , mọi người nhìn thép rất xấu , nhưng thép vẫn được coi là bánh mì của công nghiệp và tại những nước công nghiệp hoá mới như chúng ta , nhu cầu thép vẫn còn tăng ” , đó là chia sẻ chân tình của ông Trần Đình Long , Chủ tịch HĐQT Tập đoàn Hoà Phát khi nói về những mối quan tâm của dư luận thời gian gần đây trước những biến động lớn trong ngành thép lẫn tương lai của ngành này tại Việt Nam .\n",
            "\tQuestion: chủ tịch tập đoàn Hòa Phát\n",
            "\tAnswer: ,\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model 3"
      ],
      "metadata": {
        "id": "k77a4owfUtre"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "a, b, c = Demo(\"/content/drive/MyDrive/CS221/DoAnCK/Model/distilBERT_0-3500\", args)\n",
        "for i in range(len(a)):\n",
        "  print(f\"Ex {i}: \\n\\tContext: {a[i]}\\n\\tQuestion: {b[i]}\\n\\tAnswer: {c[i]}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "jtSN35yjUtrf",
        "outputId": "b1912e1e-3a32-4ea2-a513-fd2eaeb66652"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loading configuration file /content/drive/MyDrive/CS221/DoAnCK/Model/distilBERT_0-3500/config.json\n",
            "Model config DistilBertConfig {\n",
            "  \"_name_or_path\": \"/content/drive/MyDrive/CS221/DoAnCK/Model/distilBERT_0-3500\",\n",
            "  \"activation\": \"gelu\",\n",
            "  \"architectures\": [\n",
            "    \"DistilBertForQuestionAnswering\"\n",
            "  ],\n",
            "  \"attention_dropout\": 0.1,\n",
            "  \"dim\": 768,\n",
            "  \"dropout\": 0.1,\n",
            "  \"eos_token_ids\": null,\n",
            "  \"hidden_dim\": 3072,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"distilbert\",\n",
            "  \"n_heads\": 12,\n",
            "  \"n_layers\": 6,\n",
            "  \"output_past\": true,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"qa_dropout\": 0.1,\n",
            "  \"seq_classif_dropout\": 0.2,\n",
            "  \"sinusoidal_pos_embds\": false,\n",
            "  \"tie_weights_\": true,\n",
            "  \"torch_dtype\": \"float32\",\n",
            "  \"transformers_version\": \"4.26.0\",\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n",
            "loading weights file /content/drive/MyDrive/CS221/DoAnCK/Model/distilBERT_0-3500/pytorch_model.bin\n",
            "All model checkpoint weights were used when initializing DistilBertForQuestionAnswering.\n",
            "\n",
            "All the weights of DistilBertForQuestionAnswering were initialized from the model checkpoint at /content/drive/MyDrive/CS221/DoAnCK/Model/distilBERT_0-3500.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use DistilBertForQuestionAnswering for predictions without further training.\n",
            "loading file vocab.txt\n",
            "loading file tokenizer.json\n",
            "loading file added_tokens.json\n",
            "loading file special_tokens_map.json\n",
            "loading file tokenizer_config.json\n",
            "***** Running Prediction *****\n",
            "  Num examples = 1\n",
            "  Batch size = 16\n",
            "The following columns in the test set don't have a corresponding argument in `DistilBertForQuestionAnswering.forward` and have been ignored: overflow_to_sample_mapping, offset_mapping. If overflow_to_sample_mapping, offset_mapping are not expected by `DistilBertForQuestionAnswering.forward`,  you can safely ignore this message.\n",
            "You're using a DistilBertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "***** Running Prediction *****\n",
            "  Num examples = 1\n",
            "  Batch size = 16\n",
            "The following columns in the test set don't have a corresponding argument in `DistilBertForQuestionAnswering.forward` and have been ignored: overflow_to_sample_mapping, offset_mapping. If overflow_to_sample_mapping, offset_mapping are not expected by `DistilBertForQuestionAnswering.forward`,  you can safely ignore this message.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "***** Running Prediction *****\n",
            "  Num examples = 1\n",
            "  Batch size = 16\n",
            "The following columns in the test set don't have a corresponding argument in `DistilBertForQuestionAnswering.forward` and have been ignored: overflow_to_sample_mapping, offset_mapping. If overflow_to_sample_mapping, offset_mapping are not expected by `DistilBertForQuestionAnswering.forward`,  you can safely ignore this message.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "***** Running Prediction *****\n",
            "  Num examples = 1\n",
            "  Batch size = 16\n",
            "The following columns in the test set don't have a corresponding argument in `DistilBertForQuestionAnswering.forward` and have been ignored: overflow_to_sample_mapping, offset_mapping. If overflow_to_sample_mapping, offset_mapping are not expected by `DistilBertForQuestionAnswering.forward`,  you can safely ignore this message.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "***** Running Prediction *****\n",
            "  Num examples = 1\n",
            "  Batch size = 16\n",
            "The following columns in the test set don't have a corresponding argument in `DistilBertForQuestionAnswering.forward` and have been ignored: overflow_to_sample_mapping, offset_mapping. If overflow_to_sample_mapping, offset_mapping are not expected by `DistilBertForQuestionAnswering.forward`,  you can safely ignore this message.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "***** Running Prediction *****\n",
            "  Num examples = 1\n",
            "  Batch size = 16\n",
            "The following columns in the test set don't have a corresponding argument in `DistilBertForQuestionAnswering.forward` and have been ignored: overflow_to_sample_mapping, offset_mapping. If overflow_to_sample_mapping, offset_mapping are not expected by `DistilBertForQuestionAnswering.forward`,  you can safely ignore this message.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "***** Running Prediction *****\n",
            "  Num examples = 1\n",
            "  Batch size = 16\n",
            "The following columns in the test set don't have a corresponding argument in `DistilBertForQuestionAnswering.forward` and have been ignored: overflow_to_sample_mapping, offset_mapping. If overflow_to_sample_mapping, offset_mapping are not expected by `DistilBertForQuestionAnswering.forward`,  you can safely ignore this message.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "***** Running Prediction *****\n",
            "  Num examples = 1\n",
            "  Batch size = 16\n",
            "The following columns in the test set don't have a corresponding argument in `DistilBertForQuestionAnswering.forward` and have been ignored: overflow_to_sample_mapping, offset_mapping. If overflow_to_sample_mapping, offset_mapping are not expected by `DistilBertForQuestionAnswering.forward`,  you can safely ignore this message.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "***** Running Prediction *****\n",
            "  Num examples = 1\n",
            "  Batch size = 16\n",
            "The following columns in the test set don't have a corresponding argument in `DistilBertForQuestionAnswering.forward` and have been ignored: overflow_to_sample_mapping, offset_mapping. If overflow_to_sample_mapping, offset_mapping are not expected by `DistilBertForQuestionAnswering.forward`,  you can safely ignore this message.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "***** Running Prediction *****\n",
            "  Num examples = 1\n",
            "  Batch size = 16\n",
            "The following columns in the test set don't have a corresponding argument in `DistilBertForQuestionAnswering.forward` and have been ignored: overflow_to_sample_mapping, offset_mapping. If overflow_to_sample_mapping, offset_mapping are not expected by `DistilBertForQuestionAnswering.forward`,  you can safely ignore this message.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ex 0: \n",
            "\tContext: Narendra Damodardas Modi ( tiếng Gujarat : નરેન્દ્ર દામોદરદાસ મોદી , [ nəreːnd̪rə d̪ɑːmoːd̪ərəd̪ɑːsə moːd̪iː ] ( nghe ) , tiếng Hindi : नरेन्द्र दामोदरदास मोदी , sinh ngày 17 tháng 9 năm 1950 ) là Thủ tướng Ấn Độ thứ 15 . Ông là thủ lĩnh của đảng Bharatiya Janata ( đảng Nhân dân ) , từng giữ chức Thủ tịch bộ trưởng Gujarat từ năm 2001 đến năm 2014 . Ông đại diện cho Varanasi tại Lok Sabha .\n",
            "\tQuestion: Ai là thủ tướng Ấn Độ hiện tại\n",
            "\tAnswer: Narendra Damodardas Modi\n",
            "Ex 1: \n",
            "\tContext: Chia sẻ với VnExpress sau khi được Forbes công nhận là tỷ phú USD với 1,3 tỷ USD tài sản , ông Trần Đình Long - Chủ tịch HĐQT Tập đoàn Hoà Phát , thú nhận đã lâu không làm việc để vì mục tiêu kiếm một con số cụ thể bao nhiêu tiền trong ngày .\n",
            "\tQuestion: Ai là chủ tịch tập đoàn Hòa Phát\n",
            "\tAnswer: Forbes\n",
            "Ex 2: \n",
            "\tContext: Nhà Trắng ngày 29/4 cho biết , Tổng thống Mỹ Donald Trump đã mời Tổng thống Philippines Rodrigo Duterte tới thăm Mỹ .\n",
            "\tQuestion: Ai là tổng thống Philippines\n",
            "\tAnswer: Donald Trump\n",
            "Ex 3: \n",
            "\tContext: Sáng ngày 25-2 , Bộ trưởng Bộ TT-TT Nguyễn Mạnh Hùng , Chủ tịch UBND TP Hà Nội Nguyễn Đức Chung , Thứ trưởng Bộ Ngoại giao Lê Hoài Trung sáng 25-2 đã chủ trì cuộc họp báo tại Trung tâm ...\n",
            "\tQuestion: Bộ trưởng bộ ngoại giao Việt Nam là ai\n",
            "\tAnswer: TT-TT Nguyễn Mạnh Hùng , Chủ tịch UBND TP Hà Nội Nguyễn Đức Chung , Thứ trưởng Bộ Ngoại giao Lê Hoài Trung sáng 25-2 đã chủ trì cuộc họp báo tại Trung tâm\n",
            "Ex 4: \n",
            "\tContext: Khi ra mắt lần đầu vào năm 1993 , bộ phim Jurassic Park ( Công viên kỷ Jura ) của đạo diễn kỳ tài Steven Spielberg đã trở thành một trong những bom tấn kinh điển về công nghệ CGI ( công nghệ mô phỏng hình ảnh ) cũng như thổi bay mọi phòng vé thời bấy giờ . Tiếp theo là các phần phim The Lost World : Jurassic Park ( 1997 ) và Jurassic Park III ( 2001 ) .\n",
            "\tQuestion: Bộ phim Jurassic Park do ai làm đạo diễn?\n",
            "\tAnswer: Steven Spielberg\n",
            "Ex 5: \n",
            "\tContext: ( VNF ) - Công ty Cổ phần Vinhomes ( HoSE : VHM ) vừa thông báo bà Nguyễn Diệu Linh , thành viên HĐQT kiêm Tổng giám đốc đã được bầu vào vị trí Phó Chủ tịch HĐQT của công ty .\n",
            "\tQuestion: tổng giám đốc công ty cổ phần Vinhomes\n",
            "\tAnswer: VHM )\n",
            "Ex 6: \n",
            "\tContext: Một đoạn clip ghi lại câu trả lời của phi hành gia Buzz Aldrin , người thứ 2 đặt chân lên Mặt trăng thừa nhận ông chưa từng đặt chân lên Mặt trăng , đã được đăng tải lên mạng .\n",
            "\tQuestion: Ai là người thứ hai đặt chân lên Mặt trăng?\n",
            "\tAnswer: Buzz Aldrin ,\n",
            "Ex 7: \n",
            "\tContext: Ông Putin lần đầu tiên nắm quyền tổng thống Nga vào ngày 31/12/1999 , sau khi tổng thống đầu tiên của Nga , ông Boris Yeltsin bất ngờ tuyên bố thoái vị và trao quyền lại cho thủ tướng Vladimir Putin , khi đó vẫn là cái tên ít người biết đến . Ba tháng sau , ông đắc cử tổng thống lần đầu tiên .\n",
            "\tQuestion: Tổng thống Nga hiện tại là ai\n",
            "\tAnswer: Boris Yeltsin\n",
            "Ex 8: \n",
            "\tContext: Cùng với đó , Hội đồng quản trị FECON cũng đã bổ nhiệm ông Nguyễn Văn Thanh , Tổng giám đốc điều hành FECON chính thức đảm nhận vị trí Tổng giám đốc FECON từ ngày 8/11/2018 .\n",
            "\tQuestion: tổng giám đốc công ty Fecon\n",
            "\tAnswer: Nguyễn Văn Thanh , Tổng giám đốc điều hành FECON chính thức đảm nhận vị trí\n",
            "Ex 9: \n",
            "\tContext: “ Vài năm nay , mọi người nhìn thép rất xấu , nhưng thép vẫn được coi là bánh mì của công nghiệp và tại những nước công nghiệp hoá mới như chúng ta , nhu cầu thép vẫn còn tăng ” , đó là chia sẻ chân tình của ông Trần Đình Long , Chủ tịch HĐQT Tập đoàn Hoà Phát khi nói về những mối quan tâm của dư luận thời gian gần đây trước những biến động lớn trong ngành thép lẫn tương lai của ngành này tại Việt Nam .\n",
            "\tQuestion: chủ tịch tập đoàn Hòa Phát\n",
            "\tAnswer: Chủ tịch HĐQT Tập đoàn Hoà Phát\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model 4"
      ],
      "metadata": {
        "id": "1GRug0TDUt10"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "a, b, c = Demo(\"/content/drive/MyDrive/CS221/DoAnCK/Model/AlBERT\", args)\n",
        "for i in range(len(a)):\n",
        "  print(f\"Ex {i}: \\n\\tContext: {a[i]}\\n\\tQuestion: {b[i]}\\n\\tAnswer: {c[i]}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "U8HuBDdWUt11",
        "outputId": "58d25c0f-3374-4ab2-830a-486b2617b9bd"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loading configuration file /content/drive/MyDrive/CS221/DoAnCK/Model/AlBERT/config.json\n",
            "Model config AlbertConfig {\n",
            "  \"_name_or_path\": \"/content/drive/MyDrive/CS221/DoAnCK/Model/AlBERT\",\n",
            "  \"architectures\": [\n",
            "    \"AlbertForQuestionAnswering\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0,\n",
            "  \"bos_token_id\": 2,\n",
            "  \"classifier_dropout_prob\": 0.1,\n",
            "  \"down_scale_factor\": 1,\n",
            "  \"embedding_size\": 128,\n",
            "  \"eos_token_id\": 3,\n",
            "  \"eos_token_ids\": null,\n",
            "  \"gap_size\": 0,\n",
            "  \"hidden_act\": \"gelu_new\",\n",
            "  \"hidden_dropout_prob\": 0,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"inner_group_num\": 1,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"albert\",\n",
            "  \"net_structure_type\": 0,\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_groups\": 1,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"num_memory_blocks\": 0,\n",
            "  \"output_past\": true,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"torch_dtype\": \"float32\",\n",
            "  \"transformers_version\": \"4.26.0\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"vocab_size\": 30000\n",
            "}\n",
            "\n",
            "loading weights file /content/drive/MyDrive/CS221/DoAnCK/Model/AlBERT/pytorch_model.bin\n",
            "All model checkpoint weights were used when initializing AlbertForQuestionAnswering.\n",
            "\n",
            "All the weights of AlbertForQuestionAnswering were initialized from the model checkpoint at /content/drive/MyDrive/CS221/DoAnCK/Model/AlBERT.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use AlbertForQuestionAnswering for predictions without further training.\n",
            "loading file spiece.model\n",
            "loading file tokenizer.json\n",
            "loading file added_tokens.json\n",
            "loading file special_tokens_map.json\n",
            "loading file tokenizer_config.json\n",
            "***** Running Prediction *****\n",
            "  Num examples = 1\n",
            "  Batch size = 16\n",
            "The following columns in the test set don't have a corresponding argument in `AlbertForQuestionAnswering.forward` and have been ignored: overflow_to_sample_mapping, offset_mapping. If overflow_to_sample_mapping, offset_mapping are not expected by `AlbertForQuestionAnswering.forward`,  you can safely ignore this message.\n",
            "You're using a AlbertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "***** Running Prediction *****\n",
            "  Num examples = 1\n",
            "  Batch size = 16\n",
            "The following columns in the test set don't have a corresponding argument in `AlbertForQuestionAnswering.forward` and have been ignored: overflow_to_sample_mapping, offset_mapping. If overflow_to_sample_mapping, offset_mapping are not expected by `AlbertForQuestionAnswering.forward`,  you can safely ignore this message.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "***** Running Prediction *****\n",
            "  Num examples = 1\n",
            "  Batch size = 16\n",
            "The following columns in the test set don't have a corresponding argument in `AlbertForQuestionAnswering.forward` and have been ignored: overflow_to_sample_mapping, offset_mapping. If overflow_to_sample_mapping, offset_mapping are not expected by `AlbertForQuestionAnswering.forward`,  you can safely ignore this message.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "***** Running Prediction *****\n",
            "  Num examples = 1\n",
            "  Batch size = 16\n",
            "The following columns in the test set don't have a corresponding argument in `AlbertForQuestionAnswering.forward` and have been ignored: overflow_to_sample_mapping, offset_mapping. If overflow_to_sample_mapping, offset_mapping are not expected by `AlbertForQuestionAnswering.forward`,  you can safely ignore this message.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "***** Running Prediction *****\n",
            "  Num examples = 1\n",
            "  Batch size = 16\n",
            "The following columns in the test set don't have a corresponding argument in `AlbertForQuestionAnswering.forward` and have been ignored: overflow_to_sample_mapping, offset_mapping. If overflow_to_sample_mapping, offset_mapping are not expected by `AlbertForQuestionAnswering.forward`,  you can safely ignore this message.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "***** Running Prediction *****\n",
            "  Num examples = 1\n",
            "  Batch size = 16\n",
            "The following columns in the test set don't have a corresponding argument in `AlbertForQuestionAnswering.forward` and have been ignored: overflow_to_sample_mapping, offset_mapping. If overflow_to_sample_mapping, offset_mapping are not expected by `AlbertForQuestionAnswering.forward`,  you can safely ignore this message.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "***** Running Prediction *****\n",
            "  Num examples = 1\n",
            "  Batch size = 16\n",
            "The following columns in the test set don't have a corresponding argument in `AlbertForQuestionAnswering.forward` and have been ignored: overflow_to_sample_mapping, offset_mapping. If overflow_to_sample_mapping, offset_mapping are not expected by `AlbertForQuestionAnswering.forward`,  you can safely ignore this message.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "***** Running Prediction *****\n",
            "  Num examples = 1\n",
            "  Batch size = 16\n",
            "The following columns in the test set don't have a corresponding argument in `AlbertForQuestionAnswering.forward` and have been ignored: overflow_to_sample_mapping, offset_mapping. If overflow_to_sample_mapping, offset_mapping are not expected by `AlbertForQuestionAnswering.forward`,  you can safely ignore this message.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "***** Running Prediction *****\n",
            "  Num examples = 1\n",
            "  Batch size = 16\n",
            "The following columns in the test set don't have a corresponding argument in `AlbertForQuestionAnswering.forward` and have been ignored: overflow_to_sample_mapping, offset_mapping. If overflow_to_sample_mapping, offset_mapping are not expected by `AlbertForQuestionAnswering.forward`,  you can safely ignore this message.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "***** Running Prediction *****\n",
            "  Num examples = 1\n",
            "  Batch size = 16\n",
            "The following columns in the test set don't have a corresponding argument in `AlbertForQuestionAnswering.forward` and have been ignored: overflow_to_sample_mapping, offset_mapping. If overflow_to_sample_mapping, offset_mapping are not expected by `AlbertForQuestionAnswering.forward`,  you can safely ignore this message.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ex 0: \n",
            "\tContext: Narendra Damodardas Modi ( tiếng Gujarat : નરેન્દ્ર દામોદરદાસ મોદી , [ nəreːnd̪rə d̪ɑːmoːd̪ərəd̪ɑːsə moːd̪iː ] ( nghe ) , tiếng Hindi : नरेन्द्र दामोदरदास मोदी , sinh ngày 17 tháng 9 năm 1950 ) là Thủ tướng Ấn Độ thứ 15 . Ông là thủ lĩnh của đảng Bharatiya Janata ( đảng Nhân dân ) , từng giữ chức Thủ tịch bộ trưởng Gujarat từ năm 2001 đến năm 2014 . Ông đại diện cho Varanasi tại Lok Sabha .\n",
            "\tQuestion: Ai là thủ tướng Ấn Độ hiện tại\n",
            "\tAnswer: Narendra Damodardas\n",
            "Ex 1: \n",
            "\tContext: Chia sẻ với VnExpress sau khi được Forbes công nhận là tỷ phú USD với 1,3 tỷ USD tài sản , ông Trần Đình Long - Chủ tịch HĐQT Tập đoàn Hoà Phát , thú nhận đã lâu không làm việc để vì mục tiêu kiếm một con số cụ thể bao nhiêu tiền trong ngày .\n",
            "\tQuestion: Ai là chủ tịch tập đoàn Hòa Phát\n",
            "\tAnswer:  Forbes\n",
            "Ex 2: \n",
            "\tContext: Nhà Trắng ngày 29/4 cho biết , Tổng thống Mỹ Donald Trump đã mời Tổng thống Philippines Rodrigo Duterte tới thăm Mỹ .\n",
            "\tQuestion: Ai là tổng thống Philippines\n",
            "\tAnswer:  Rodrigo Duterte\n",
            "Ex 3: \n",
            "\tContext: Sáng ngày 25-2 , Bộ trưởng Bộ TT-TT Nguyễn Mạnh Hùng , Chủ tịch UBND TP Hà Nội Nguyễn Đức Chung , Thứ trưởng Bộ Ngoại giao Lê Hoài Trung sáng 25-2 đã chủ trì cuộc họp báo tại Trung tâm ...\n",
            "\tQuestion: Bộ trưởng bộ ngoại giao Việt Nam là ai\n",
            "\tAnswer: ,\n",
            "Ex 4: \n",
            "\tContext: Khi ra mắt lần đầu vào năm 1993 , bộ phim Jurassic Park ( Công viên kỷ Jura ) của đạo diễn kỳ tài Steven Spielberg đã trở thành một trong những bom tấn kinh điển về công nghệ CGI ( công nghệ mô phỏng hình ảnh ) cũng như thổi bay mọi phòng vé thời bấy giờ . Tiếp theo là các phần phim The Lost World : Jurassic Park ( 1997 ) và Jurassic Park III ( 2001 ) .\n",
            "\tQuestion: Bộ phim Jurassic Park do ai làm đạo diễn?\n",
            "\tAnswer:  Steven Spielberg\n",
            "Ex 5: \n",
            "\tContext: ( VNF ) - Công ty Cổ phần Vinhomes ( HoSE : VHM ) vừa thông báo bà Nguyễn Diệu Linh , thành viên HĐQT kiêm Tổng giám đốc đã được bầu vào vị trí Phó Chủ tịch HĐQT của công ty .\n",
            "\tQuestion: tổng giám đốc công ty cổ phần Vinhomes\n",
            "\tAnswer: ( VNF ) - Công ty Cổ phần Vinhomes ( HoSE : VHM )\n",
            "Ex 6: \n",
            "\tContext: Một đoạn clip ghi lại câu trả lời của phi hành gia Buzz Aldrin , người thứ 2 đặt chân lên Mặt trăng thừa nhận ông chưa từng đặt chân lên Mặt trăng , đã được đăng tải lên mạng .\n",
            "\tQuestion: Ai là người thứ hai đặt chân lên Mặt trăng?\n",
            "\tAnswer: ,\n",
            "Ex 7: \n",
            "\tContext: Ông Putin lần đầu tiên nắm quyền tổng thống Nga vào ngày 31/12/1999 , sau khi tổng thống đầu tiên của Nga , ông Boris Yeltsin bất ngờ tuyên bố thoái vị và trao quyền lại cho thủ tướng Vladimir Putin , khi đó vẫn là cái tên ít người biết đến . Ba tháng sau , ông đắc cử tổng thống lần đầu tiên .\n",
            "\tQuestion: Tổng thống Nga hiện tại là ai\n",
            "\tAnswer:  Putin lần đầu tiên\n",
            "Ex 8: \n",
            "\tContext: Cùng với đó , Hội đồng quản trị FECON cũng đã bổ nhiệm ông Nguyễn Văn Thanh , Tổng giám đốc điều hành FECON chính thức đảm nhận vị trí Tổng giám đốc FECON từ ngày 8/11/2018 .\n",
            "\tQuestion: tổng giám đốc công ty Fecon\n",
            "\tAnswer:  FECON chính thức đảm nhận vị trí Tổng giám đốc FECON từ\n",
            "Ex 9: \n",
            "\tContext: “ Vài năm nay , mọi người nhìn thép rất xấu , nhưng thép vẫn được coi là bánh mì của công nghiệp và tại những nước công nghiệp hoá mới như chúng ta , nhu cầu thép vẫn còn tăng ” , đó là chia sẻ chân tình của ông Trần Đình Long , Chủ tịch HĐQT Tập đoàn Hoà Phát khi nói về những mối quan tâm của dư luận thời gian gần đây trước những biến động lớn trong ngành thép lẫn tương lai của ngành này tại Việt Nam .\n",
            "\tQuestion: chủ tịch tập đoàn Hòa Phát\n",
            "\tAnswer:  nói về những mối quan tâm của dư luận thời gian\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(10):\n",
        "  print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EHtl-KNkY_4S",
        "outputId": "9526c781-b6c7-418e-a252-985702b0d132"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n"
          ]
        }
      ]
    }
  ]
}