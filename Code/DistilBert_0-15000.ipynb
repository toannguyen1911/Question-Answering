{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1NMOC3RAgig1SJWkzI3HfCrS674rzNXE8","timestamp":1675324778671},{"file_id":"1IhAQCzm8_b9n8eon7jN28HHOjDANDtLt","timestamp":1675301948680}],"collapsed_sections":["LAP6Y877eGiV","j4PBa6RfgFVW"]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"1978dfdea0424945b2f57bde92739328":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_cc870905c2e54c4b89e6d3c4510fcdbe","IPY_MODEL_6277480ae41f42109abc884be4ecaf0e","IPY_MODEL_9b899f15246445ebb09f6ec76300b006"],"layout":"IPY_MODEL_3e0bb0cff7274f16b2a3f3bad0c5417b"}},"cc870905c2e54c4b89e6d3c4510fcdbe":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f3799c4f80e14421bbde10c615e46890","placeholder":"​","style":"IPY_MODEL_199eb065570e4387a1102a50af482559","value":"Downloading (…)okenizer_config.json: 100%"}},"6277480ae41f42109abc884be4ecaf0e":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_96774c2ff95441a189d1238eaaa60bc1","max":28,"min":0,"orientation":"horizontal","style":"IPY_MODEL_fb6ad4ccd8ed46a9ae688b333f564c27","value":28}},"9b899f15246445ebb09f6ec76300b006":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_8e9048cd640846f0909814e2ab7e4c0f","placeholder":"​","style":"IPY_MODEL_2b9fec2ea68c467d8d904e681d807018","value":" 28.0/28.0 [00:00&lt;00:00, 1.14kB/s]"}},"3e0bb0cff7274f16b2a3f3bad0c5417b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f3799c4f80e14421bbde10c615e46890":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"199eb065570e4387a1102a50af482559":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"96774c2ff95441a189d1238eaaa60bc1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fb6ad4ccd8ed46a9ae688b333f564c27":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"8e9048cd640846f0909814e2ab7e4c0f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2b9fec2ea68c467d8d904e681d807018":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"484639fa8942480aa753f7207baac80a":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_7f98314f0c344db9a25bd46802ba1060","IPY_MODEL_e916145c0d73415dafe6a213bc715ed3","IPY_MODEL_b92c34f836174f49b89f73d5ee060e59"],"layout":"IPY_MODEL_1079798d08b34ce4badb7405fed92ede"}},"7f98314f0c344db9a25bd46802ba1060":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_27d81d5673544d509a09a9ef0795decd","placeholder":"​","style":"IPY_MODEL_788d78855a7542a69f13353eac6b0881","value":"Downloading (…)lve/main/config.json: 100%"}},"e916145c0d73415dafe6a213bc715ed3":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_863e8f92c9e04841b66e82eff25bd521","max":483,"min":0,"orientation":"horizontal","style":"IPY_MODEL_669b6ad9f90545ba978decb20a8a8627","value":483}},"b92c34f836174f49b89f73d5ee060e59":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_2a12369983044fe595e0e0c3e08b38cf","placeholder":"​","style":"IPY_MODEL_b6a065432ead4a10a9aba4f575c0cda2","value":" 483/483 [00:00&lt;00:00, 23.3kB/s]"}},"1079798d08b34ce4badb7405fed92ede":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"27d81d5673544d509a09a9ef0795decd":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"788d78855a7542a69f13353eac6b0881":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"863e8f92c9e04841b66e82eff25bd521":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"669b6ad9f90545ba978decb20a8a8627":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"2a12369983044fe595e0e0c3e08b38cf":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b6a065432ead4a10a9aba4f575c0cda2":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"6870350ad484419f9cb77ddd03093121":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_223c4490f726445283ea0d99cdc9f8a3","IPY_MODEL_66db95bdc9af4074b771344171f931b6","IPY_MODEL_fdf5f4a2f0c54a588865d62a8801f478"],"layout":"IPY_MODEL_b4ae8aca0d3b476fb59a1b4e669960cb"}},"223c4490f726445283ea0d99cdc9f8a3":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_df89aefc1b954da09fba9bf29af475d0","placeholder":"​","style":"IPY_MODEL_88e0aa752e8445e1a62f3e2fe9e64e92","value":"Downloading (…)solve/main/vocab.txt: 100%"}},"66db95bdc9af4074b771344171f931b6":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_2226bef059e0417faa640901915f1277","max":231508,"min":0,"orientation":"horizontal","style":"IPY_MODEL_8bdae7de98be47b89887df45abe9b4f3","value":231508}},"fdf5f4a2f0c54a588865d62a8801f478":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_6e73c26140624ce39bd9467f6fb4e9f6","placeholder":"​","style":"IPY_MODEL_65956a54c45c4ed4a51dfb6a8a9229b3","value":" 232k/232k [00:00&lt;00:00, 261kB/s]"}},"b4ae8aca0d3b476fb59a1b4e669960cb":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"df89aefc1b954da09fba9bf29af475d0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"88e0aa752e8445e1a62f3e2fe9e64e92":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"2226bef059e0417faa640901915f1277":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8bdae7de98be47b89887df45abe9b4f3":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"6e73c26140624ce39bd9467f6fb4e9f6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"65956a54c45c4ed4a51dfb6a8a9229b3":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"37d6190813dd4dd0b5b891c1eff0f2ad":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_2de8600986f24dc2b5261649c51c2d41","IPY_MODEL_45809d6e826543b69e6d9ef6fc330400","IPY_MODEL_20e0b00b76084676854269f4f7576471"],"layout":"IPY_MODEL_76f0d71a5327429999239e9501b25ebd"}},"2de8600986f24dc2b5261649c51c2d41":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_0e12626d8d414c68a2f509b3e6f98568","placeholder":"​","style":"IPY_MODEL_ffe1bad788744c3dbe1c3ffba8d194a5","value":"Downloading (…)/main/tokenizer.json: 100%"}},"45809d6e826543b69e6d9ef6fc330400":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_d50c850602944eb29b1ab0bd0bb27be6","max":466062,"min":0,"orientation":"horizontal","style":"IPY_MODEL_5b795f7feedd4f15a89c3f70b0d2134b","value":466062}},"20e0b00b76084676854269f4f7576471":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e6701c08cedd432d80c2a6f6a547a653","placeholder":"​","style":"IPY_MODEL_82d1fefc73654ea480c32db1511ead1c","value":" 466k/466k [00:01&lt;00:00, 417kB/s]"}},"76f0d71a5327429999239e9501b25ebd":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0e12626d8d414c68a2f509b3e6f98568":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ffe1bad788744c3dbe1c3ffba8d194a5":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d50c850602944eb29b1ab0bd0bb27be6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5b795f7feedd4f15a89c3f70b0d2134b":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"e6701c08cedd432d80c2a6f6a547a653":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"82d1fefc73654ea480c32db1511ead1c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}},"accelerator":"GPU","gpuClass":"standard"},"cells":[{"cell_type":"markdown","source":["#Install lib"],"metadata":{"id":"LAP6Y877eGiV"}},{"cell_type":"code","execution_count":4,"metadata":{"id":"ShbRR5_AIN9-","colab":{"base_uri":"https://localhost:8080/"},"outputId":"903d9291-0931-409d-a633-d901817187fd","executionInfo":{"status":"ok","timestamp":1675324876026,"user_tz":-420,"elapsed":4767,"user":{"displayName":"Bự Turtle","userId":"10418066683906582777"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: datasets in /usr/local/lib/python3.8/dist-packages (2.9.0)\n","Requirement already satisfied: transformers in /usr/local/lib/python3.8/dist-packages (4.26.0)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.8/dist-packages (from datasets) (1.21.6)\n","Requirement already satisfied: multiprocess in /usr/local/lib/python3.8/dist-packages (from datasets) (0.70.14)\n","Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.8/dist-packages (from datasets) (2.25.1)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/dist-packages (from datasets) (6.0)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.8/dist-packages (from datasets) (1.3.5)\n","Requirement already satisfied: pyarrow>=6.0.0 in /usr/local/lib/python3.8/dist-packages (from datasets) (9.0.0)\n","Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.8/dist-packages (from datasets) (4.64.1)\n","Requirement already satisfied: aiohttp in /usr/local/lib/python3.8/dist-packages (from datasets) (3.8.3)\n","Requirement already satisfied: responses<0.19 in /usr/local/lib/python3.8/dist-packages (from datasets) (0.18.0)\n","Requirement already satisfied: xxhash in /usr/local/lib/python3.8/dist-packages (from datasets) (3.2.0)\n","Requirement already satisfied: fsspec[http]>=2021.11.1 in /usr/local/lib/python3.8/dist-packages (from datasets) (2022.11.0)\n","Requirement already satisfied: huggingface-hub<1.0.0,>=0.2.0 in /usr/local/lib/python3.8/dist-packages (from datasets) (0.12.0)\n","Requirement already satisfied: dill<0.3.7 in /usr/local/lib/python3.8/dist-packages (from datasets) (0.3.6)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from datasets) (21.3)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (2022.6.2)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from transformers) (3.9.0)\n","Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.8/dist-packages (from transformers) (0.13.2)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (6.0.4)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (1.3.3)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (1.3.1)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (22.2.0)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (1.8.2)\n","Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (2.1.1)\n","Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (4.0.2)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.8/dist-packages (from huggingface-hub<1.0.0,>=0.2.0->datasets) (4.4.0)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging->datasets) (3.0.9)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->datasets) (2022.12.7)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->datasets) (2.10)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->datasets) (1.26.14)\n","Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->datasets) (4.0.0)\n","Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.8/dist-packages (from pandas->datasets) (2.8.2)\n","Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.8/dist-packages (from pandas->datasets) (2022.7)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.8/dist-packages (from python-dateutil>=2.7.3->pandas->datasets) (1.15.0)\n"]}],"source":["!pip install datasets transformers"]},{"cell_type":"code","source":["!pip install transformers[sentencepiece]"],"metadata":{"id":"vJ7O0QdtvKh7","colab":{"base_uri":"https://localhost:8080/"},"outputId":"bebee357-3daf-4fa5-a5bc-430f95b45050","executionInfo":{"status":"ok","timestamp":1675324878861,"user_tz":-420,"elapsed":2842,"user":{"displayName":"Bự Turtle","userId":"10418066683906582777"}}},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: transformers[sentencepiece] in /usr/local/lib/python3.8/dist-packages (4.26.0)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.8/dist-packages (from transformers[sentencepiece]) (4.64.1)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from transformers[sentencepiece]) (3.9.0)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.8/dist-packages (from transformers[sentencepiece]) (1.21.6)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from transformers[sentencepiece]) (21.3)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.11.0 in /usr/local/lib/python3.8/dist-packages (from transformers[sentencepiece]) (0.12.0)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/dist-packages (from transformers[sentencepiece]) (6.0)\n","Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.8/dist-packages (from transformers[sentencepiece]) (0.13.2)\n","Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from transformers[sentencepiece]) (2.25.1)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.8/dist-packages (from transformers[sentencepiece]) (2022.6.2)\n","Requirement already satisfied: sentencepiece!=0.1.92,>=0.1.91 in /usr/local/lib/python3.8/dist-packages (from transformers[sentencepiece]) (0.1.97)\n","Requirement already satisfied: protobuf<=3.20.2 in /usr/local/lib/python3.8/dist-packages (from transformers[sentencepiece]) (3.19.6)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.8/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers[sentencepiece]) (4.4.0)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging>=20.0->transformers[sentencepiece]) (3.0.9)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->transformers[sentencepiece]) (2.10)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->transformers[sentencepiece]) (1.26.14)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->transformers[sentencepiece]) (2022.12.7)\n","Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->transformers[sentencepiece]) (4.0.0)\n"]}]},{"cell_type":"code","source":["#!apt install git-lfs"],"metadata":{"id":"1Koh8yXlITLC","executionInfo":{"status":"ok","timestamp":1675324878861,"user_tz":-420,"elapsed":5,"user":{"displayName":"Bự Turtle","userId":"10418066683906582777"}}},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":["#Enviroment"],"metadata":{"id":"nlrl0qCj7t8P"}},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2TbYPNbz7yHO","outputId":"7d5e38ba-ca79-43d0-8c34-b8755f18d181","executionInfo":{"status":"ok","timestamp":1675324909072,"user_tz":-420,"elapsed":30215,"user":{"displayName":"Bự Turtle","userId":"10418066683906582777"}}},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["# This flag is the difference between SQUAD v1 or 2 (if you're using another dataset, it indicates if impossible answers are allowed or not).\n","squad_v2 = True\n","#model_checkpoint = \"xlm-roberta-base\"\n","model_checkpoint = \"distilbert-base-uncased\"\n","batch_size = 16"],"metadata":{"id":"0A7s9p2BIgTT","executionInfo":{"status":"ok","timestamp":1675324946017,"user_tz":-420,"elapsed":652,"user":{"displayName":"Bự Turtle","userId":"10418066683906582777"}}},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":["#Preprocessing the training data"],"metadata":{"id":"zWJeRCn4dYkv"}},{"cell_type":"code","source":["import json\n","from pathlib import Path\n","import torch"],"metadata":{"id":"2pXKNpVo6XzJ","executionInfo":{"status":"ok","timestamp":1675324952475,"user_tz":-420,"elapsed":3975,"user":{"displayName":"Bự Turtle","userId":"10418066683906582777"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":["from transformers import AutoTokenizer\n","    \n","tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":257,"referenced_widgets":["1978dfdea0424945b2f57bde92739328","cc870905c2e54c4b89e6d3c4510fcdbe","6277480ae41f42109abc884be4ecaf0e","9b899f15246445ebb09f6ec76300b006","3e0bb0cff7274f16b2a3f3bad0c5417b","f3799c4f80e14421bbde10c615e46890","199eb065570e4387a1102a50af482559","96774c2ff95441a189d1238eaaa60bc1","fb6ad4ccd8ed46a9ae688b333f564c27","8e9048cd640846f0909814e2ab7e4c0f","2b9fec2ea68c467d8d904e681d807018","484639fa8942480aa753f7207baac80a","7f98314f0c344db9a25bd46802ba1060","e916145c0d73415dafe6a213bc715ed3","b92c34f836174f49b89f73d5ee060e59","1079798d08b34ce4badb7405fed92ede","27d81d5673544d509a09a9ef0795decd","788d78855a7542a69f13353eac6b0881","863e8f92c9e04841b66e82eff25bd521","669b6ad9f90545ba978decb20a8a8627","2a12369983044fe595e0e0c3e08b38cf","b6a065432ead4a10a9aba4f575c0cda2","6870350ad484419f9cb77ddd03093121","223c4490f726445283ea0d99cdc9f8a3","66db95bdc9af4074b771344171f931b6","fdf5f4a2f0c54a588865d62a8801f478","b4ae8aca0d3b476fb59a1b4e669960cb","df89aefc1b954da09fba9bf29af475d0","88e0aa752e8445e1a62f3e2fe9e64e92","2226bef059e0417faa640901915f1277","8bdae7de98be47b89887df45abe9b4f3","6e73c26140624ce39bd9467f6fb4e9f6","65956a54c45c4ed4a51dfb6a8a9229b3","37d6190813dd4dd0b5b891c1eff0f2ad","2de8600986f24dc2b5261649c51c2d41","45809d6e826543b69e6d9ef6fc330400","20e0b00b76084676854269f4f7576471","76f0d71a5327429999239e9501b25ebd","0e12626d8d414c68a2f509b3e6f98568","ffe1bad788744c3dbe1c3ffba8d194a5","d50c850602944eb29b1ab0bd0bb27be6","5b795f7feedd4f15a89c3f70b0d2134b","e6701c08cedd432d80c2a6f6a547a653","82d1fefc73654ea480c32db1511ead1c"]},"id":"-IZTRVm8JA25","outputId":"fd8dca5e-325d-4aeb-dead-efa626009a62","executionInfo":{"status":"ok","timestamp":1675324965395,"user_tz":-420,"elapsed":12922,"user":{"displayName":"Bự Turtle","userId":"10418066683906582777"}}},"execution_count":10,"outputs":[{"output_type":"display_data","data":{"text/plain":["Downloading (…)okenizer_config.json:   0%|          | 0.00/28.0 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1978dfdea0424945b2f57bde92739328"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading (…)lve/main/config.json:   0%|          | 0.00/483 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"484639fa8942480aa753f7207baac80a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading (…)solve/main/vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6870350ad484419f9cb77ddd03093121"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading (…)/main/tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"37d6190813dd4dd0b5b891c1eff0f2ad"}},"metadata":{}}]},{"cell_type":"code","source":["def read_squad_train(path,data_index,context_size):\n","  \"\"\"\n","  Read data format squad \n","  -> return contexts, questions, answers of sentenses\n","  \"\"\"\n","  path = Path(path)\n","  with open(path, 'rb') as f:\n","      squad_dict = json.load(f)\n","\n","  contexts = []\n","  questions = []\n","  answers = []\n","  size=0\n","  for group in squad_dict['data'][data_index-1:data_index]:\n","      for passage in group['paragraphs']:\n","        if size <= context_size:\n","          context = passage['context']\n","          for qa in passage['qas']:\n","              question = qa['question']\n","              for answer in qa['answers']:\n","                if answer['answer_start']>=0:\n","                  contexts.append(context)\n","                  questions.append(question)\n","                  answers.append(answer)\n","          size+=1\n","        else: break\n","\n","  return contexts, questions, answers\n","def read_squad_val(path):\n","  \"\"\"\n","  Read data format squad \n","  -> return contexts, questions, answers of sentenses\n","  \"\"\"\n","  path = Path(path)\n","  with open(path, 'rb') as f:\n","      squad_dict = json.load(f)\n","\n","  contexts = []\n","  questions = []\n","  answers = []\n","  for group in squad_dict['data']:\n","      for passage in group['paragraphs']:\n","          context = passage['context']\n","          for qa in passage['qas']:\n","              question = qa['question']\n","              for answer in qa['answers']:\n","                  contexts.append(context)\n","                  questions.append(question)\n","                  answers.append(answer)\n","\n","  return contexts, questions, answers\n","def add_token_positions(encodings, answers):\n","  \"\"\"\n","  Convert answer start- end from string to token\n","  \"\"\"\n","  start_positions = []\n","  end_positions = []\n","  for i in range(len(answers)):\n","    start_positions.append(encodings.char_to_token(i, answers[i]['answer_start']))\n","    end_positions.append(encodings.char_to_token(i, answers[i]['answer_end'] - 1))\n","    # if None, the answer passage has been truncated\n","    if start_positions[-1] is None:\n","        start_positions[-1] = tokenizer.model_max_length\n","    if end_positions[-1] is None:\n","        end_positions[-1] = tokenizer.model_max_length\n","  encodings.update({'start_positions': start_positions, 'end_positions': end_positions})\n","def add_end_idx(answers, contexts):\n","  \"\"\"\n","  Squad format chỉ có id start của câu trả lời\n","  -> Hàm này dùng để tạo id end của câu trả lời\n","  \"\"\"\n","  for answer, context in zip(answers, contexts):\n","    gold_text = answer['text']\n","    start_idx = answer['answer_start']\n","    end_idx = start_idx + len(gold_text)\n","\n","    # sometimes squad answers are off by a character or two – fix this\n","    if context[start_idx:end_idx] == gold_text:\n","        answer['answer_end'] = end_idx\n","    elif context[start_idx-1:end_idx-1] == gold_text:\n","        answer['answer_start'] = start_idx - 1\n","        answer['answer_end'] = end_idx - 1     # When the gold label is off by one character\n","    elif context[start_idx-2:end_idx-2] == gold_text:\n","        answer['answer_start'] = start_idx - 2\n","        answer['answer_end'] = end_idx - 2     # When the gold label is off by two characters\n","\n","\n","def read_squad_train2(path,context_index):\n","  \"\"\"\n","  Read data format squad \n","  -> return contexts, questions, answers of sentenses\n","  \"\"\"\n","  path = Path(path)\n","  with open(path, 'rb') as f:\n","      squad_dict = json.load(f)\n","\n","  contexts = []\n","  questions = []\n","  answers = []\n","  for group in squad_dict['data'][0:1]:\n","      for passage in group['paragraphs'][context_index[0]:context_index[1]+1]:\n","          context = passage['context']\n","          for qa in passage['qas']:\n","              question = qa['question']\n","              for answer in qa['answers']:\n","                if answer['answer_start']>=0:\n","                  contexts.append(context)\n","                  questions.append(question)\n","                  answers.append(answer)\n","  return contexts, questions, answers\n","train_contexts, train_questions, train_answers = read_squad_train2('/content/drive/MyDrive/DoAnCK/Dataset/squad_vi.json', [10000,15000])\n","val_contexts, val_questions, val_answers = read_squad_train2('/content/drive/MyDrive/DoAnCK/Dataset/squad_vi.json', [17000,18000])\n","#val_contexts, val_questions, val_answers = read_squad_train('/content/drive/MyDrive/CS221/DoAnCK/Dataset/squad_vi.json', 3000, 3500)\n","add_end_idx(train_answers, train_contexts)\n","add_end_idx(val_answers, val_contexts) \n","\n","#train\n","new_train_contexts=[]\n","new_train_questions=[]\n","new_train_answers=[]\n","for i in range(len(train_answers)):\n","  if train_answers[i]['answer_start']!=train_answers[i]['answer_end']:\n","    new_train_contexts.append(train_contexts[i])\n","    new_train_questions.append(train_questions[i])\n","    new_train_answers.append(train_answers[i])\n","(train_contexts, train_questions, train_answers)=(new_train_contexts, new_train_questions, new_train_answers)\n","(new_train_contexts, new_train_questions, new_train_answers)=(0,0,0)\n","new_val_contexts=[]\n","new_val_questions=[]\n","new_val_answers=[]\n","for i in range(len(val_answers)):\n","  if val_answers[i]['answer_start']!=val_answers[i]['answer_end']:\n","    new_val_contexts.append(val_contexts[i])\n","    new_val_questions.append(val_questions[i])\n","    new_val_answers.append(val_answers[i])\n","(val_contexts, val_questions, val_answers)=(new_val_contexts, new_val_questions, new_val_answers)\n","(new_val_contexts, new_val_questions, new_val_answers)=(0,0,0)\n","# #chia train val\n","# val_contexts, val_questions, val_answers = train_contexts[12000:], train_questions[12000:], train_answers[12000:]\n","# train_contexts, train_questions, train_answers = train_contexts[:12000], train_questions[:12000], train_answers[:12000]\n","\n","\n","train_encodings = tokenizer(train_contexts, train_questions, truncation=True, padding=True)\n","val_encodings = tokenizer(val_contexts, val_questions, truncation=True, padding=True)\n","\n","add_token_positions(train_encodings, train_answers)\n","add_token_positions(val_encodings, val_answers)"],"metadata":{"id":"DON7PU5kgZHM","executionInfo":{"status":"ok","timestamp":1675330595825,"user_tz":-420,"elapsed":18311,"user":{"displayName":"Bự Turtle","userId":"10418066683906582777"}}},"execution_count":24,"outputs":[]},{"cell_type":"code","source":["len(train_answers)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NHy3jzk1UGd-","executionInfo":{"status":"ok","timestamp":1675330600642,"user_tz":-420,"elapsed":1151,"user":{"displayName":"Bự Turtle","userId":"10418066683906582777"}},"outputId":"0bc47771-c3f7-4d2b-9008-42908c754dbf"},"execution_count":25,"outputs":[{"output_type":"execute_result","data":{"text/plain":["19861"]},"metadata":{},"execution_count":25}]},{"cell_type":"markdown","source":["Tải data lên pytorch"],"metadata":{"id":"yKVZEDsGJBaH"}},{"cell_type":"code","source":["class SquadDataset(torch.utils.data.Dataset):\n","    def __init__(self, encodings):\n","        self.encodings = encodings\n","\n","    def __getitem__(self, idx):\n","        return {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n","\n","    def __len__(self):\n","        return len(self.encodings.input_ids)"],"metadata":{"id":"juoHW4ZpJn7V","executionInfo":{"status":"ok","timestamp":1675330610605,"user_tz":-420,"elapsed":2032,"user":{"displayName":"Bự Turtle","userId":"10418066683906582777"}}},"execution_count":26,"outputs":[]},{"cell_type":"code","source":["train_dataset = SquadDataset(train_encodings)\n","val_dataset = SquadDataset(val_encodings)"],"metadata":{"id":"3wGUVFH-24U8","executionInfo":{"status":"ok","timestamp":1675330611291,"user_tz":-420,"elapsed":3,"user":{"displayName":"Bự Turtle","userId":"10418066683906582777"}}},"execution_count":27,"outputs":[]},{"cell_type":"markdown","source":["#Load pretrain"],"metadata":{"id":"XcSlcJmuKoip"}},{"cell_type":"code","source":["from transformers import AutoModelForQuestionAnswering, TrainingArguments, Trainer\n","\n","model = AutoModelForQuestionAnswering.from_pretrained(model_checkpoint)\n","model.load_state_dict(torch.load('/content/drive/MyDrive/LOG/sublog3/checkpoint-10292/pytorch_model.bin'))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OzIv0rIXKpxm","outputId":"b58f349c-c94d-445f-860e-85de963cda68","executionInfo":{"status":"ok","timestamp":1675325161720,"user_tz":-420,"elapsed":11830,"user":{"displayName":"Bự Turtle","userId":"10418066683906582777"}}},"execution_count":15,"outputs":[{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForQuestionAnswering: ['vocab_transform.weight', 'vocab_transform.bias', 'vocab_projector.bias', 'vocab_projector.weight', 'vocab_layer_norm.weight', 'vocab_layer_norm.bias']\n","- This IS expected if you are initializing DistilBertForQuestionAnswering from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing DistilBertForQuestionAnswering from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of DistilBertForQuestionAnswering were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"execute_result","data":{"text/plain":["<All keys matched successfully>"]},"metadata":{},"execution_count":15}]},{"cell_type":"code","source":[],"metadata":{"id":"yWhLOQqYfYgD"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#Train"],"metadata":{"id":"vMlPE-C7l1kQ"}},{"cell_type":"code","source":["from torch.utils.data import DataLoader\n","from transformers import AdamW"],"metadata":{"id":"DGxpf8C53jYT","executionInfo":{"status":"ok","timestamp":1675325161722,"user_tz":-420,"elapsed":44,"user":{"displayName":"Bự Turtle","userId":"10418066683906582777"}}},"execution_count":16,"outputs":[]},{"cell_type":"code","source":["val_count = len(val_dataset)"],"metadata":{"id":"5p4f1kqpYPV1","executionInfo":{"status":"ok","timestamp":1675325169437,"user_tz":-420,"elapsed":680,"user":{"displayName":"Bự Turtle","userId":"10418066683906582777"}}},"execution_count":18,"outputs":[]},{"cell_type":"code","source":["epochs = 10\n","batch_size=16\n","train_count = len(train_dataset)\n","val_count = len(val_dataset)\n","PATH = \"//content/drive/MyDrive/LOG/best_model.model\""],"metadata":{"id":"ZSkUTlj23qUH","executionInfo":{"status":"ok","timestamp":1675325174271,"user_tz":-420,"elapsed":746,"user":{"displayName":"Bự Turtle","userId":"10418066683906582777"}}},"execution_count":19,"outputs":[]},{"cell_type":"markdown","source":["###Train with trainer"],"metadata":{"id":"fN-QiKEf5ngP"}},{"cell_type":"markdown","source":["###10 epoch"],"metadata":{"id":"S5O0Qz2EKTD6"}},{"cell_type":"code","source":["import numpy as np"],"metadata":{"id":"YB2HLKlLRieW","executionInfo":{"status":"ok","timestamp":1675325237514,"user_tz":-420,"elapsed":685,"user":{"displayName":"Bự Turtle","userId":"10418066683906582777"}}},"execution_count":20,"outputs":[]},{"cell_type":"code","source":["args = TrainingArguments(\n","    f\"/content/drive/MyDrive/LOG/sublog2\",#Tên folder chứa log\n","    evaluation_strategy = \"epoch\",#Đánh giá sau mỗi epoch\n","    learning_rate=5e-5,\n","    per_device_train_batch_size=batch_size,\n","    per_device_eval_batch_size=16,\n","    num_train_epochs=10,\n","    weight_decay=0.01,\n","    #push_to_hub=True,\n",")"],"metadata":{"id":"Qh5bWNzHKYOL","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1675311994797,"user_tz":-420,"elapsed":399,"user":{"displayName":"Phước Trần Hồ Thiên","userId":"02774547961789878242"}},"outputId":"38079222-4adf-4d32-8618-6c4fe4421bb9"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["PyTorch: setting up devices\n","The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n"]}]},{"cell_type":"code","source":["def f1_score(start_pred,end_pred,start_true,end_true):\n","  a=np.arange(int(start_pred),int(end_pred+1), step=1)\n","  b=np.arange(int(start_true),int(end_true+1), step=1)\n","  true_count = len(np.intersect1d(a,b))\n","  if ((int(end_true)-int(start_true)) == 0):\n","    recall = 0\n","  else:\n","    recall = true_count/(int(end_true)-int(start_true))\n","  if ((int(end_pred)-int(start_pred)) == 0):\n","    precision = 0\n","  else:\n","    precision= true_count/(int(end_pred)-int(start_pred))\n","  if (precision + recall == 0):\n","    return 0\n","  f1=2*(precision*recall)/(precision+recall)\n","  return f1"],"metadata":{"id":"VSGbLruKKYOL","executionInfo":{"status":"ok","timestamp":1675325241906,"user_tz":-420,"elapsed":1,"user":{"displayName":"Bự Turtle","userId":"10418066683906582777"}}},"execution_count":21,"outputs":[]},{"cell_type":"code","source":["def compute_metrics(eval_pred):    \n","    logits, labels = eval_pred\n","    predictions = np.argmax(logits, axis=-1)\n","    count = 0\n","    for i in range(len(predictions[0])):\n","      if (predictions[0][i] == labels[0][i] and predictions[1][i] == labels[1][i]):\n","        count += 1\n","    f1 = 0\n","    for i in range(len(predictions[0])):\n","      f1 += f1_score(predictions[0][i], predictions[1][i], labels[0][i], labels[1][i])\n","\n","    return {'exact_match': round(count*100/len(predictions[0]), 3), 'f1_score': round(f1/len(predictions[0]),3)} #metric.compute(predictions=predictions, references=labels)"],"metadata":{"id":"NnKZcCABKYOL","executionInfo":{"status":"ok","timestamp":1675325243893,"user_tz":-420,"elapsed":3,"user":{"displayName":"Bự Turtle","userId":"10418066683906582777"}}},"execution_count":22,"outputs":[]},{"cell_type":"code","source":["trainer = Trainer(\n","    model,\n","    args,\n","    train_dataset=train_dataset,\n","    eval_dataset=val_dataset,\n","    #data_collator=data_collator,\n","    tokenizer=tokenizer,\n","    compute_metrics=compute_metrics\n",")"],"metadata":{"id":"FUNMR9oVKYOL"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#0-10000\n"],"metadata":{"id":"j4PBa6RfgFVW"}},{"cell_type":"code","source":["args = TrainingArguments(\n","    f\"/content/drive/MyDrive/LOG/sublog3\",#Tên folder chứa log\n","    evaluation_strategy = \"epoch\",#Đánh giá sau mỗi epoch\n","    learning_rate=5e-5,\n","    per_device_train_batch_size=batch_size,\n","    per_device_eval_batch_size=16,\n","    num_train_epochs=10,\n","    weight_decay=0.01,\n","    save_strategy = \"epoch\",\n","    #push_to_hub=True,\n",")\n","trainer = Trainer(\n","    model,\n","    args,\n","    train_dataset=train_dataset,\n","    eval_dataset=val_dataset,\n","    #data_collator=data_collator,\n","    tokenizer=tokenizer,\n","    compute_metrics=compute_metrics\n",")\n","trainer.train()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"U-MRiANaYBpj","outputId":"ad402c63-ee24-43d0-d2e2-87db96f40bf6"},"execution_count":null,"outputs":[{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["PyTorch: setting up devices\n","The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n","***** Running training *****\n","  Num examples = 41166\n","  Num Epochs = 10\n","  Instantaneous batch size per device = 16\n","  Total train batch size (w. parallel, distributed & accumulation) = 16\n","  Gradient Accumulation steps = 1\n","  Total optimization steps = 25730\n","  Number of trainable parameters = 66364418\n"]},{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='5977' max='25730' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [ 5977/25730 1:22:44 < 4:33:32, 1.20 it/s, Epoch 2.32/10]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Exact Match</th>\n","      <th>F1 Score</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>2.415900</td>\n","      <td>2.505397</td>\n","      <td>28.284000</td>\n","      <td>0.463000</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>1.864500</td>\n","      <td>2.454407</td>\n","      <td>30.599000</td>\n","      <td>0.503000</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["***** Running Evaluation *****\n","  Num examples = 3974\n","  Batch size = 16\n","Saving model checkpoint to /content/drive/MyDrive/LOG/sublog3/checkpoint-2573\n","Configuration saved in /content/drive/MyDrive/LOG/sublog3/checkpoint-2573/config.json\n","Model weights saved in /content/drive/MyDrive/LOG/sublog3/checkpoint-2573/pytorch_model.bin\n","tokenizer config file saved in /content/drive/MyDrive/LOG/sublog3/checkpoint-2573/tokenizer_config.json\n","Special tokens file saved in /content/drive/MyDrive/LOG/sublog3/checkpoint-2573/special_tokens_map.json\n","***** Running Evaluation *****\n","  Num examples = 3974\n","  Batch size = 16\n","Saving model checkpoint to /content/drive/MyDrive/LOG/sublog3/checkpoint-5146\n","Configuration saved in /content/drive/MyDrive/LOG/sublog3/checkpoint-5146/config.json\n","Model weights saved in /content/drive/MyDrive/LOG/sublog3/checkpoint-5146/pytorch_model.bin\n","tokenizer config file saved in /content/drive/MyDrive/LOG/sublog3/checkpoint-5146/tokenizer_config.json\n","Special tokens file saved in /content/drive/MyDrive/LOG/sublog3/checkpoint-5146/special_tokens_map.json\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='13208' max='25730' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [13208/25730 3:03:31 < 2:54:01, 1.20 it/s, Epoch 5.13/10]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Exact Match</th>\n","      <th>F1 Score</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>2.415900</td>\n","      <td>2.505397</td>\n","      <td>28.284000</td>\n","      <td>0.463000</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>1.864500</td>\n","      <td>2.454407</td>\n","      <td>30.599000</td>\n","      <td>0.503000</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>1.514800</td>\n","      <td>2.444758</td>\n","      <td>31.152000</td>\n","      <td>0.522000</td>\n","    </tr>\n","    <tr>\n","      <td>4</td>\n","      <td>1.189400</td>\n","      <td>2.676967</td>\n","      <td>31.480000</td>\n","      <td>0.528000</td>\n","    </tr>\n","    <tr>\n","      <td>5</td>\n","      <td>0.885300</td>\n","      <td>2.908550</td>\n","      <td>30.649000</td>\n","      <td>0.521000</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["***** Running Evaluation *****\n","  Num examples = 3974\n","  Batch size = 16\n","Saving model checkpoint to /content/drive/MyDrive/LOG/sublog3/checkpoint-7719\n","Configuration saved in /content/drive/MyDrive/LOG/sublog3/checkpoint-7719/config.json\n","Model weights saved in /content/drive/MyDrive/LOG/sublog3/checkpoint-7719/pytorch_model.bin\n","tokenizer config file saved in /content/drive/MyDrive/LOG/sublog3/checkpoint-7719/tokenizer_config.json\n","Special tokens file saved in /content/drive/MyDrive/LOG/sublog3/checkpoint-7719/special_tokens_map.json\n","***** Running Evaluation *****\n","  Num examples = 3974\n","  Batch size = 16\n","Saving model checkpoint to /content/drive/MyDrive/LOG/sublog3/checkpoint-10292\n","Configuration saved in /content/drive/MyDrive/LOG/sublog3/checkpoint-10292/config.json\n","Model weights saved in /content/drive/MyDrive/LOG/sublog3/checkpoint-10292/pytorch_model.bin\n","tokenizer config file saved in /content/drive/MyDrive/LOG/sublog3/checkpoint-10292/tokenizer_config.json\n","Special tokens file saved in /content/drive/MyDrive/LOG/sublog3/checkpoint-10292/special_tokens_map.json\n","***** Running Evaluation *****\n","  Num examples = 3974\n","  Batch size = 16\n","Saving model checkpoint to /content/drive/MyDrive/LOG/sublog3/checkpoint-12865\n","Configuration saved in /content/drive/MyDrive/LOG/sublog3/checkpoint-12865/config.json\n","Model weights saved in /content/drive/MyDrive/LOG/sublog3/checkpoint-12865/pytorch_model.bin\n","tokenizer config file saved in /content/drive/MyDrive/LOG/sublog3/checkpoint-12865/tokenizer_config.json\n","Special tokens file saved in /content/drive/MyDrive/LOG/sublog3/checkpoint-12865/special_tokens_map.json\n"]}]},{"cell_type":"code","source":["args = TrainingArguments(\n","    f\"/content/drive/MyDrive/LOG//content/drive/MyDrive/LOG/sublog5\",#Tên folder chứa log\n","    evaluation_strategy = \"epoch\",#Đánh giá sau mỗi epoch\n","    learning_rate=5e-5,\n","    per_device_train_batch_size=batch_size,\n","    per_device_eval_batch_size=16,\n","    num_train_epochs=5,\n","    weight_decay=0.01,\n","    save_strategy = \"epoch\",\n","    #push_to_hub=True,\n",")\n","trainer = Trainer(\n","    model,\n","    args,\n","    train_dataset=train_dataset,\n","    eval_dataset=val_dataset,\n","    #data_collator=data_collator,\n","    tokenizer=tokenizer,\n","    compute_metrics=compute_metrics\n",")\n","trainer.train()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":993},"id":"41pA9zcTKb1k","executionInfo":{"status":"error","timestamp":1675330515248,"user_tz":-420,"elapsed":5262262,"user":{"displayName":"Bự Turtle","userId":"10418066683906582777"}},"outputId":"e0b2318a-c244-4964-ef0f-cea7d0c5cd8f"},"execution_count":23,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.8/dist-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n","***** Running training *****\n","  Num examples = 41166\n","  Num Epochs = 5\n","  Instantaneous batch size per device = 16\n","  Total train batch size (w. parallel, distributed & accumulation) = 16\n","  Gradient Accumulation steps = 1\n","  Total optimization steps = 12865\n","  Number of trainable parameters = 66364418\n","You're using a DistilBertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='6482' max='12865' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [ 6482/12865 1:27:38 < 1:26:19, 1.23 it/s, Epoch 2.52/5]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Exact Match</th>\n","      <th>F1 Score</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>0.814100</td>\n","      <td>3.321112</td>\n","      <td>29.567000</td>\n","      <td>0.493000</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>0.516000</td>\n","      <td>3.559578</td>\n","      <td>29.391000</td>\n","      <td>0.506000</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["***** Running Evaluation *****\n","  Num examples = 3974\n","  Batch size = 16\n","Saving model checkpoint to /content/drive/MyDrive/LOG/sublog4/checkpoint-2573\n","Configuration saved in /content/drive/MyDrive/LOG/sublog4/checkpoint-2573/config.json\n","Model weights saved in /content/drive/MyDrive/LOG/sublog4/checkpoint-2573/pytorch_model.bin\n","tokenizer config file saved in /content/drive/MyDrive/LOG/sublog4/checkpoint-2573/tokenizer_config.json\n","Special tokens file saved in /content/drive/MyDrive/LOG/sublog4/checkpoint-2573/special_tokens_map.json\n","***** Running Evaluation *****\n","  Num examples = 3974\n","  Batch size = 16\n","Saving model checkpoint to /content/drive/MyDrive/LOG/sublog4/checkpoint-5146\n","Configuration saved in /content/drive/MyDrive/LOG/sublog4/checkpoint-5146/config.json\n","Model weights saved in /content/drive/MyDrive/LOG/sublog4/checkpoint-5146/pytorch_model.bin\n","tokenizer config file saved in /content/drive/MyDrive/LOG/sublog4/checkpoint-5146/tokenizer_config.json\n","Special tokens file saved in /content/drive/MyDrive/LOG/sublog4/checkpoint-5146/special_tokens_map.json\n"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-23-3442dfea208f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0mcompute_metrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcompute_metrics\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m )\n\u001b[0;32m---> 21\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   1541\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inner_training_loop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train_batch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_find_batch_size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1542\u001b[0m         )\n\u001b[0;32m-> 1543\u001b[0;31m         return inner_training_loop(\n\u001b[0m\u001b[1;32m   1544\u001b[0m             \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1545\u001b[0m             \u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36m_inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   1789\u001b[0m                         \u001b[0mtr_loss_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1790\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1791\u001b[0;31m                     \u001b[0mtr_loss_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1792\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1793\u001b[0m                 if (\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mtraining_step\u001b[0;34m(self, model, inputs)\u001b[0m\n\u001b[1;32m   2555\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeepspeed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2556\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2557\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2558\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2559\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    486\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    487\u001b[0m             )\n\u001b[0;32m--> 488\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    489\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    490\u001b[0m         )\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    195\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    196\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 197\u001b[0;31m     Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    198\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m         allow_unreachable=True, accumulate_grad=True)  # Calls into the C++ engine to run the backward pass\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"markdown","source":["#10000-15000"],"metadata":{"id":"TTQOl5McgNu5"}},{"cell_type":"code","source":["from transformers import AutoModelForQuestionAnswering, TrainingArguments, Trainer\n","\n","model = AutoModelForQuestionAnswering.from_pretrained(model_checkpoint)\n","model.load_state_dict(torch.load('/content/drive/MyDrive/LOG/content/drive/MyDrive/LOG/sublog5/checkpoint-3726/pytorch_model.bin'))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"naqCF3sGfaQj","executionInfo":{"status":"ok","timestamp":1675330705773,"user_tz":-420,"elapsed":7659,"user":{"displayName":"Bự Turtle","userId":"10418066683906582777"}},"outputId":"efc8fdd0-f15f-431b-c3d5-5bed74fc1455"},"execution_count":28,"outputs":[{"output_type":"stream","name":"stderr","text":["loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--distilbert-base-uncased/snapshots/1c4513b2eedbda136f57676a34eea67aba266e5c/config.json\n","Model config DistilBertConfig {\n","  \"_name_or_path\": \"distilbert-base-uncased\",\n","  \"activation\": \"gelu\",\n","  \"architectures\": [\n","    \"DistilBertForMaskedLM\"\n","  ],\n","  \"attention_dropout\": 0.1,\n","  \"dim\": 768,\n","  \"dropout\": 0.1,\n","  \"hidden_dim\": 3072,\n","  \"initializer_range\": 0.02,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"distilbert\",\n","  \"n_heads\": 12,\n","  \"n_layers\": 6,\n","  \"pad_token_id\": 0,\n","  \"qa_dropout\": 0.1,\n","  \"seq_classif_dropout\": 0.2,\n","  \"sinusoidal_pos_embds\": false,\n","  \"tie_weights_\": true,\n","  \"transformers_version\": \"4.26.0\",\n","  \"vocab_size\": 30522\n","}\n","\n","loading weights file pytorch_model.bin from cache at /root/.cache/huggingface/hub/models--distilbert-base-uncased/snapshots/1c4513b2eedbda136f57676a34eea67aba266e5c/pytorch_model.bin\n","Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForQuestionAnswering: ['vocab_transform.weight', 'vocab_transform.bias', 'vocab_projector.bias', 'vocab_projector.weight', 'vocab_layer_norm.weight', 'vocab_layer_norm.bias']\n","- This IS expected if you are initializing DistilBertForQuestionAnswering from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing DistilBertForQuestionAnswering from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of DistilBertForQuestionAnswering were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"execute_result","data":{"text/plain":["<All keys matched successfully>"]},"metadata":{},"execution_count":28}]},{"cell_type":"code","source":["args = TrainingArguments(\n","    f\"/content/drive/MyDrive/LOG/content/drive/MyDrive/LOG/sublog5\",#Tên folder chứa log\n","    evaluation_strategy = \"epoch\",#Đánh giá sau mỗi epoch\n","    learning_rate=5e-5,\n","    per_device_train_batch_size=batch_size,\n","    per_device_eval_batch_size=16,\n","    num_train_epochs=10,\n","    weight_decay=0.01,\n","    save_strategy = \"epoch\",\n","    #push_to_hub=True,\n",")\n","trainer = Trainer(\n","    model,\n","    args,\n","    train_dataset=train_dataset,\n","    eval_dataset=val_dataset,\n","    #data_collator=data_collator,\n","    tokenizer=tokenizer,\n","    compute_metrics=compute_metrics\n",")\n","trainer.train()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"Hr6vNBf4finD","executionInfo":{"status":"ok","timestamp":1675341258324,"user_tz":-420,"elapsed":10511040,"user":{"displayName":"Bự Turtle","userId":"10418066683906582777"}},"outputId":"f3555ac5-18e9-471c-b455-d26487e54e15"},"execution_count":29,"outputs":[{"output_type":"stream","name":"stderr","text":["PyTorch: setting up devices\n","The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n","/usr/local/lib/python3.8/dist-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n","***** Running training *****\n","  Num examples = 19861\n","  Num Epochs = 10\n","  Instantaneous batch size per device = 16\n","  Total train batch size (w. parallel, distributed & accumulation) = 16\n","  Gradient Accumulation steps = 1\n","  Total optimization steps = 12420\n","  Number of trainable parameters = 66364418\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='12420' max='12420' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [12420/12420 2:55:09, Epoch 10/10]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Exact Match</th>\n","      <th>F1 Score</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>2.389000</td>\n","      <td>2.190277</td>\n","      <td>32.612000</td>\n","      <td>0.539000</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>1.833300</td>\n","      <td>2.231283</td>\n","      <td>32.788000</td>\n","      <td>0.543000</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>1.422200</td>\n","      <td>2.413545</td>\n","      <td>32.964000</td>\n","      <td>0.553000</td>\n","    </tr>\n","    <tr>\n","      <td>4</td>\n","      <td>1.006200</td>\n","      <td>2.693565</td>\n","      <td>32.813000</td>\n","      <td>0.547000</td>\n","    </tr>\n","    <tr>\n","      <td>5</td>\n","      <td>0.753200</td>\n","      <td>3.050770</td>\n","      <td>32.134000</td>\n","      <td>0.538000</td>\n","    </tr>\n","    <tr>\n","      <td>6</td>\n","      <td>0.521200</td>\n","      <td>3.398000</td>\n","      <td>31.731000</td>\n","      <td>0.535000</td>\n","    </tr>\n","    <tr>\n","      <td>7</td>\n","      <td>0.381800</td>\n","      <td>3.784125</td>\n","      <td>31.681000</td>\n","      <td>0.535000</td>\n","    </tr>\n","    <tr>\n","      <td>8</td>\n","      <td>0.246800</td>\n","      <td>4.068014</td>\n","      <td>31.782000</td>\n","      <td>0.540000</td>\n","    </tr>\n","    <tr>\n","      <td>9</td>\n","      <td>0.192300</td>\n","      <td>4.363337</td>\n","      <td>32.260000</td>\n","      <td>0.541000</td>\n","    </tr>\n","    <tr>\n","      <td>10</td>\n","      <td>0.129900</td>\n","      <td>4.653668</td>\n","      <td>31.706000</td>\n","      <td>0.538000</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["***** Running Evaluation *****\n","  Num examples = 3974\n","  Batch size = 16\n","Saving model checkpoint to /content/drive/MyDrive/LOG/content/drive/MyDrive/LOG/sublog5/checkpoint-1242\n","Configuration saved in /content/drive/MyDrive/LOG/content/drive/MyDrive/LOG/sublog5/checkpoint-1242/config.json\n","Model weights saved in /content/drive/MyDrive/LOG/content/drive/MyDrive/LOG/sublog5/checkpoint-1242/pytorch_model.bin\n","tokenizer config file saved in /content/drive/MyDrive/LOG/content/drive/MyDrive/LOG/sublog5/checkpoint-1242/tokenizer_config.json\n","Special tokens file saved in /content/drive/MyDrive/LOG/content/drive/MyDrive/LOG/sublog5/checkpoint-1242/special_tokens_map.json\n","***** Running Evaluation *****\n","  Num examples = 3974\n","  Batch size = 16\n","Saving model checkpoint to /content/drive/MyDrive/LOG/content/drive/MyDrive/LOG/sublog5/checkpoint-2484\n","Configuration saved in /content/drive/MyDrive/LOG/content/drive/MyDrive/LOG/sublog5/checkpoint-2484/config.json\n","Model weights saved in /content/drive/MyDrive/LOG/content/drive/MyDrive/LOG/sublog5/checkpoint-2484/pytorch_model.bin\n","tokenizer config file saved in /content/drive/MyDrive/LOG/content/drive/MyDrive/LOG/sublog5/checkpoint-2484/tokenizer_config.json\n","Special tokens file saved in /content/drive/MyDrive/LOG/content/drive/MyDrive/LOG/sublog5/checkpoint-2484/special_tokens_map.json\n","***** Running Evaluation *****\n","  Num examples = 3974\n","  Batch size = 16\n","Saving model checkpoint to /content/drive/MyDrive/LOG/content/drive/MyDrive/LOG/sublog5/checkpoint-3726\n","Configuration saved in /content/drive/MyDrive/LOG/content/drive/MyDrive/LOG/sublog5/checkpoint-3726/config.json\n","Model weights saved in /content/drive/MyDrive/LOG/content/drive/MyDrive/LOG/sublog5/checkpoint-3726/pytorch_model.bin\n","tokenizer config file saved in /content/drive/MyDrive/LOG/content/drive/MyDrive/LOG/sublog5/checkpoint-3726/tokenizer_config.json\n","Special tokens file saved in /content/drive/MyDrive/LOG/content/drive/MyDrive/LOG/sublog5/checkpoint-3726/special_tokens_map.json\n","***** Running Evaluation *****\n","  Num examples = 3974\n","  Batch size = 16\n","Saving model checkpoint to /content/drive/MyDrive/LOG/content/drive/MyDrive/LOG/sublog5/checkpoint-4968\n","Configuration saved in /content/drive/MyDrive/LOG/content/drive/MyDrive/LOG/sublog5/checkpoint-4968/config.json\n","Model weights saved in /content/drive/MyDrive/LOG/content/drive/MyDrive/LOG/sublog5/checkpoint-4968/pytorch_model.bin\n","tokenizer config file saved in /content/drive/MyDrive/LOG/content/drive/MyDrive/LOG/sublog5/checkpoint-4968/tokenizer_config.json\n","Special tokens file saved in /content/drive/MyDrive/LOG/content/drive/MyDrive/LOG/sublog5/checkpoint-4968/special_tokens_map.json\n","***** Running Evaluation *****\n","  Num examples = 3974\n","  Batch size = 16\n","Saving model checkpoint to /content/drive/MyDrive/LOG/content/drive/MyDrive/LOG/sublog5/checkpoint-6210\n","Configuration saved in /content/drive/MyDrive/LOG/content/drive/MyDrive/LOG/sublog5/checkpoint-6210/config.json\n","Model weights saved in /content/drive/MyDrive/LOG/content/drive/MyDrive/LOG/sublog5/checkpoint-6210/pytorch_model.bin\n","tokenizer config file saved in /content/drive/MyDrive/LOG/content/drive/MyDrive/LOG/sublog5/checkpoint-6210/tokenizer_config.json\n","Special tokens file saved in /content/drive/MyDrive/LOG/content/drive/MyDrive/LOG/sublog5/checkpoint-6210/special_tokens_map.json\n","***** Running Evaluation *****\n","  Num examples = 3974\n","  Batch size = 16\n","Saving model checkpoint to /content/drive/MyDrive/LOG/content/drive/MyDrive/LOG/sublog5/checkpoint-7452\n","Configuration saved in /content/drive/MyDrive/LOG/content/drive/MyDrive/LOG/sublog5/checkpoint-7452/config.json\n","Model weights saved in /content/drive/MyDrive/LOG/content/drive/MyDrive/LOG/sublog5/checkpoint-7452/pytorch_model.bin\n","tokenizer config file saved in /content/drive/MyDrive/LOG/content/drive/MyDrive/LOG/sublog5/checkpoint-7452/tokenizer_config.json\n","Special tokens file saved in /content/drive/MyDrive/LOG/content/drive/MyDrive/LOG/sublog5/checkpoint-7452/special_tokens_map.json\n","***** Running Evaluation *****\n","  Num examples = 3974\n","  Batch size = 16\n","Saving model checkpoint to /content/drive/MyDrive/LOG/content/drive/MyDrive/LOG/sublog5/checkpoint-8694\n","Configuration saved in /content/drive/MyDrive/LOG/content/drive/MyDrive/LOG/sublog5/checkpoint-8694/config.json\n","Model weights saved in /content/drive/MyDrive/LOG/content/drive/MyDrive/LOG/sublog5/checkpoint-8694/pytorch_model.bin\n","tokenizer config file saved in /content/drive/MyDrive/LOG/content/drive/MyDrive/LOG/sublog5/checkpoint-8694/tokenizer_config.json\n","Special tokens file saved in /content/drive/MyDrive/LOG/content/drive/MyDrive/LOG/sublog5/checkpoint-8694/special_tokens_map.json\n","***** Running Evaluation *****\n","  Num examples = 3974\n","  Batch size = 16\n","Saving model checkpoint to /content/drive/MyDrive/LOG/content/drive/MyDrive/LOG/sublog5/checkpoint-9936\n","Configuration saved in /content/drive/MyDrive/LOG/content/drive/MyDrive/LOG/sublog5/checkpoint-9936/config.json\n","Model weights saved in /content/drive/MyDrive/LOG/content/drive/MyDrive/LOG/sublog5/checkpoint-9936/pytorch_model.bin\n","tokenizer config file saved in /content/drive/MyDrive/LOG/content/drive/MyDrive/LOG/sublog5/checkpoint-9936/tokenizer_config.json\n","Special tokens file saved in /content/drive/MyDrive/LOG/content/drive/MyDrive/LOG/sublog5/checkpoint-9936/special_tokens_map.json\n","***** Running Evaluation *****\n","  Num examples = 3974\n","  Batch size = 16\n","Saving model checkpoint to /content/drive/MyDrive/LOG/content/drive/MyDrive/LOG/sublog5/checkpoint-11178\n","Configuration saved in /content/drive/MyDrive/LOG/content/drive/MyDrive/LOG/sublog5/checkpoint-11178/config.json\n","Model weights saved in /content/drive/MyDrive/LOG/content/drive/MyDrive/LOG/sublog5/checkpoint-11178/pytorch_model.bin\n","tokenizer config file saved in /content/drive/MyDrive/LOG/content/drive/MyDrive/LOG/sublog5/checkpoint-11178/tokenizer_config.json\n","Special tokens file saved in /content/drive/MyDrive/LOG/content/drive/MyDrive/LOG/sublog5/checkpoint-11178/special_tokens_map.json\n","***** Running Evaluation *****\n","  Num examples = 3974\n","  Batch size = 16\n","Saving model checkpoint to /content/drive/MyDrive/LOG/content/drive/MyDrive/LOG/sublog5/checkpoint-12420\n","Configuration saved in /content/drive/MyDrive/LOG/content/drive/MyDrive/LOG/sublog5/checkpoint-12420/config.json\n","Model weights saved in /content/drive/MyDrive/LOG/content/drive/MyDrive/LOG/sublog5/checkpoint-12420/pytorch_model.bin\n","tokenizer config file saved in /content/drive/MyDrive/LOG/content/drive/MyDrive/LOG/sublog5/checkpoint-12420/tokenizer_config.json\n","Special tokens file saved in /content/drive/MyDrive/LOG/content/drive/MyDrive/LOG/sublog5/checkpoint-12420/special_tokens_map.json\n","\n","\n","Training completed. Do not forget to share your model on huggingface.co/models =)\n","\n","\n"]},{"output_type":"execute_result","data":{"text/plain":["TrainOutput(global_step=12420, training_loss=0.8826650794577483, metrics={'train_runtime': 10509.9002, 'train_samples_per_second': 18.897, 'train_steps_per_second': 1.182, 'total_flos': 2.594901219735552e+16, 'train_loss': 0.8826650794577483, 'epoch': 10.0})"]},"metadata":{},"execution_count":29}]},{"cell_type":"code","source":["model2 = AutoModelForQuestionAnswering.from_pretrained(model_checkpoint)\n","model2.load_state_dict(torch.load('/content/drive/MyDrive/LOG/content/drive/MyDrive/LOG/sublog5/checkpoint-3726/pytorch_model.bin'))"],"metadata":{"id":"9jDl0cwwIGJu"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["args = TrainingArguments(\n","    f\"/content/drive/MyDrive/LOG/content/drive/MyDrive/LOG/sublog5\",#Tên folder chứa log\n","    evaluation_strategy = \"epoch\",#Đánh giá sau mỗi epoch\n","    learning_rate=5e-5,\n","    per_device_train_batch_size=batch_size,\n","    per_device_eval_batch_size=16,\n","    num_train_epochs=10,\n","    weight_decay=0.01,\n","    save_strategy = \"epoch\",\n","    #push_to_hub=True,\n",")\n","trainer = Trainer(\n","    model2,\n","    args,\n","    train_dataset=train_dataset,\n","    eval_dataset=val_dataset,\n","    #data_collator=data_collator,\n","    tokenizer=tokenizer,\n","    compute_metrics=compute_metrics\n",")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"aMt-geRmIgB4","executionInfo":{"status":"ok","timestamp":1675341491896,"user_tz":-420,"elapsed":739,"user":{"displayName":"Bự Turtle","userId":"10418066683906582777"}},"outputId":"635d16bc-2d88-40ea-ef59-2f7eccb32da2"},"execution_count":32,"outputs":[{"output_type":"stream","name":"stderr","text":["PyTorch: setting up devices\n","The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n"]}]},{"cell_type":"code","source":["trainer.evaluate()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":201},"id":"JXuehNKgInQU","executionInfo":{"status":"ok","timestamp":1675341573809,"user_tz":-420,"elapsed":68078,"user":{"displayName":"Bự Turtle","userId":"10418066683906582777"}},"outputId":"dea27a64-0579-4f72-f055-865d927a0092"},"execution_count":33,"outputs":[{"output_type":"stream","name":"stderr","text":["***** Running Evaluation *****\n","  Num examples = 3974\n","  Batch size = 16\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='249' max='249' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [249/249 01:06]\n","    </div>\n","    "]},"metadata":{}},{"output_type":"execute_result","data":{"text/plain":["{'eval_loss': 2.4135451316833496,\n"," 'eval_exact_match': 32.964,\n"," 'eval_f1_score': 0.553,\n"," 'eval_runtime': 67.319,\n"," 'eval_samples_per_second': 59.032,\n"," 'eval_steps_per_second': 3.699}"]},"metadata":{},"execution_count":33}]},{"cell_type":"markdown","source":["Evaluation"],"metadata":{"id":"RLHW604nx1HN"}}]}