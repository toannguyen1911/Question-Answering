{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "LAP6Y877eGiV",
        "nJkoYfLK7wco",
        "zWJeRCn4dYkv"
      ],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "b339d51906be4030838c636e427200c1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_88005b023a354a45abd01d22e541e2f4",
              "IPY_MODEL_8fc8300f6ea840088e2acd54d2bd0d90",
              "IPY_MODEL_c1bfaabfa8674b09bb309932adacf074"
            ],
            "layout": "IPY_MODEL_f57a0bee031b4b959d037aae06c81fa7"
          }
        },
        "88005b023a354a45abd01d22e541e2f4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4e8790ffd9aa42eda28a95230edc37c8",
            "placeholder": "​",
            "style": "IPY_MODEL_bb7fcce2d00940ff8f50df59ea56c713",
            "value": "Downloading (…)okenizer_config.json: 100%"
          }
        },
        "8fc8300f6ea840088e2acd54d2bd0d90": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d7f909bcc0464c4f987643ee1af4bf67",
            "max": 79,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_49713488c7374f51a1501797afd66efa",
            "value": 79
          }
        },
        "c1bfaabfa8674b09bb309932adacf074": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8dfd0d7537a64fe7ab9d689b32adcd46",
            "placeholder": "​",
            "style": "IPY_MODEL_ee1225b1c8514262ac39bda98d28b9b1",
            "value": " 79.0/79.0 [00:00&lt;00:00, 2.69kB/s]"
          }
        },
        "f57a0bee031b4b959d037aae06c81fa7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4e8790ffd9aa42eda28a95230edc37c8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bb7fcce2d00940ff8f50df59ea56c713": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d7f909bcc0464c4f987643ee1af4bf67": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "49713488c7374f51a1501797afd66efa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8dfd0d7537a64fe7ab9d689b32adcd46": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ee1225b1c8514262ac39bda98d28b9b1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "75d8f324b5d64bc5a3218ea117b34709": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c9706b8f93fc451a9ac0f6c85c1a23d2",
              "IPY_MODEL_7dea6ce79d4444bdad4a1701e6d8c8f9",
              "IPY_MODEL_bef8ae1a0bf94265b21f8f820931454a"
            ],
            "layout": "IPY_MODEL_cc411788015144fea20edbc5244c83ca"
          }
        },
        "c9706b8f93fc451a9ac0f6c85c1a23d2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_380aa11642244941b48cf58d2003a04a",
            "placeholder": "​",
            "style": "IPY_MODEL_e3f972ca2e9e47df8e54dcb168263781",
            "value": "Downloading (…)lve/main/config.json: 100%"
          }
        },
        "7dea6ce79d4444bdad4a1701e6d8c8f9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0ab3e535fc194f2aad82551c5d97e2e0",
            "max": 605,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4dc9beffd22344a5b8312c6a13104f88",
            "value": 605
          }
        },
        "bef8ae1a0bf94265b21f8f820931454a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bdda6de86b254990b8304656a7f9675b",
            "placeholder": "​",
            "style": "IPY_MODEL_f182b8b84b104396900ffff93a617beb",
            "value": " 605/605 [00:00&lt;00:00, 23.1kB/s]"
          }
        },
        "cc411788015144fea20edbc5244c83ca": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "380aa11642244941b48cf58d2003a04a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e3f972ca2e9e47df8e54dcb168263781": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0ab3e535fc194f2aad82551c5d97e2e0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4dc9beffd22344a5b8312c6a13104f88": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "bdda6de86b254990b8304656a7f9675b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f182b8b84b104396900ffff93a617beb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9c44d19b37bc494395a0daec78572a73": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b7b37b1b6cb24ed8a375a1dd5dfc1808",
              "IPY_MODEL_c0b47017a43b4368be83003d06112495",
              "IPY_MODEL_2b46c7845c02429e87360f67ba97f562"
            ],
            "layout": "IPY_MODEL_056c500058b843de9e4505e7ed3da9bb"
          }
        },
        "b7b37b1b6cb24ed8a375a1dd5dfc1808": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c7f8c25f80684716a1f296f268551619",
            "placeholder": "​",
            "style": "IPY_MODEL_7b98863b2dc24778aec603f616123d9c",
            "value": "Downloading (…)ncepiece.bpe.model&quot;;: 100%"
          }
        },
        "c0b47017a43b4368be83003d06112495": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e8555cd47fcd469597698e7b1c0a66ac",
            "max": 5069051,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_2c995b09a3614c6f9c8e33966679fdfc",
            "value": 5069051
          }
        },
        "2b46c7845c02429e87360f67ba97f562": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ddda6da5d3d34877b6f561d357f36000",
            "placeholder": "​",
            "style": "IPY_MODEL_1cdeb1e6c59a4893bfb19db07a58d166",
            "value": " 5.07M/5.07M [00:00&lt;00:00, 17.2MB/s]"
          }
        },
        "056c500058b843de9e4505e7ed3da9bb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c7f8c25f80684716a1f296f268551619": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7b98863b2dc24778aec603f616123d9c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e8555cd47fcd469597698e7b1c0a66ac": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2c995b09a3614c6f9c8e33966679fdfc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ddda6da5d3d34877b6f561d357f36000": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1cdeb1e6c59a4893bfb19db07a58d166": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cd9ea8a7a8fa47f0a309938f6103c9c4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0ac11243a2c64b13b6633d1a6ceb1d75",
              "IPY_MODEL_b742e8a52a4f4d1c9af215e42179e3e4",
              "IPY_MODEL_b0594c22104a4ca7b03cfaf55f7fb39e"
            ],
            "layout": "IPY_MODEL_a609dae7e448437bb6b0758ba778beb2"
          }
        },
        "0ac11243a2c64b13b6633d1a6ceb1d75": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_acba33dfb9b44e598ad97ee1b715f2d3",
            "placeholder": "​",
            "style": "IPY_MODEL_16b4ceceed684438ab719ac23fe825af",
            "value": "Downloading (…)cial_tokens_map.json: 100%"
          }
        },
        "b742e8a52a4f4d1c9af215e42179e3e4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d82fc94cf17f45f0ba7966929e122eaa",
            "max": 150,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e23a0dde83fe4a18bfdd45e00ee1e8e7",
            "value": 150
          }
        },
        "b0594c22104a4ca7b03cfaf55f7fb39e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0caeba8a572e44249bd9e126dd15f183",
            "placeholder": "​",
            "style": "IPY_MODEL_14996a7a03884e859d509484cd08439d",
            "value": " 150/150 [00:00&lt;00:00, 1.92kB/s]"
          }
        },
        "a609dae7e448437bb6b0758ba778beb2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "acba33dfb9b44e598ad97ee1b715f2d3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "16b4ceceed684438ab719ac23fe825af": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d82fc94cf17f45f0ba7966929e122eaa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e23a0dde83fe4a18bfdd45e00ee1e8e7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0caeba8a572e44249bd9e126dd15f183": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "14996a7a03884e859d509484cd08439d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e13837beb131498eb5cfafe4698404c6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_37c82f7385e44894b0ede292f602e029",
              "IPY_MODEL_3d6e90f59e9245c8bb0a38ef3405b338",
              "IPY_MODEL_14010470f02d44d99d17dd3057c61f94"
            ],
            "layout": "IPY_MODEL_50ce3a0d5ab74c349f319e98837fb714"
          }
        },
        "37c82f7385e44894b0ede292f602e029": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_991acbf870d74970ac4cb633b4efe40f",
            "placeholder": "​",
            "style": "IPY_MODEL_c7da2b35cd4344a2ace2f2a7580c55bc",
            "value": "Downloading (…)&quot;pytorch_model.bin&quot;;: 100%"
          }
        },
        "3d6e90f59e9245c8bb0a38ef3405b338": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_00476ea9f7674594999a5127db6a78f2",
            "max": 1109905791,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e229d591e1d341de9e499cac1a076392",
            "value": 1109905791
          }
        },
        "14010470f02d44d99d17dd3057c61f94": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5fc17690aa474f689fa6cea59157a751",
            "placeholder": "​",
            "style": "IPY_MODEL_e26faabb6d7c465caed87e9134c3d1ba",
            "value": " 1.11G/1.11G [00:21&lt;00:00, 59.0MB/s]"
          }
        },
        "50ce3a0d5ab74c349f319e98837fb714": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "991acbf870d74970ac4cb633b4efe40f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c7da2b35cd4344a2ace2f2a7580c55bc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "00476ea9f7674594999a5127db6a78f2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e229d591e1d341de9e499cac1a076392": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5fc17690aa474f689fa6cea59157a751": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e26faabb6d7c465caed87e9134c3d1ba": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Install lib"
      ],
      "metadata": {
        "id": "LAP6Y877eGiV"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ShbRR5_AIN9-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6449d1a8-8339-41f7-ccb3-767642a3c419"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting datasets\n",
            "  Downloading datasets-2.9.0-py3-none-any.whl (462 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m462.8/462.8 KB\u001b[0m \u001b[31m36.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting transformers\n",
            "  Downloading transformers-4.26.0-py3-none-any.whl (6.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m92.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting responses<0.19\n",
            "  Downloading responses-0.18.0-py3-none-any.whl (38 kB)\n",
            "Requirement already satisfied: pyarrow>=6.0.0 in /usr/local/lib/python3.8/dist-packages (from datasets) (9.0.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/dist-packages (from datasets) (6.0)\n",
            "Requirement already satisfied: fsspec[http]>=2021.11.1 in /usr/local/lib/python3.8/dist-packages (from datasets) (2022.11.0)\n",
            "Collecting xxhash\n",
            "  Downloading xxhash-3.2.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (213 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m213.0/213.0 KB\u001b[0m \u001b[31m24.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.8/dist-packages (from datasets) (1.21.6)\n",
            "Collecting huggingface-hub<1.0.0,>=0.2.0\n",
            "  Downloading huggingface_hub-0.12.0-py3-none-any.whl (190 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m190.3/190.3 KB\u001b[0m \u001b[31m24.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting multiprocess\n",
            "  Downloading multiprocess-0.70.14-py38-none-any.whl (132 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m132.0/132.0 KB\u001b[0m \u001b[31m16.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from datasets) (21.3)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.8/dist-packages (from datasets) (2.25.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.8/dist-packages (from datasets) (1.3.5)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.8/dist-packages (from datasets) (4.64.1)\n",
            "Requirement already satisfied: dill<0.3.7 in /usr/local/lib/python3.8/dist-packages (from datasets) (0.3.6)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.8/dist-packages (from datasets) (3.8.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (2022.6.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from transformers) (3.9.0)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1\n",
            "  Downloading tokenizers-0.13.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.6/7.6 MB\u001b[0m \u001b[31m70.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (1.8.2)\n",
            "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (2.1.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (6.0.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (22.2.0)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (4.0.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (1.3.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.8/dist-packages (from huggingface-hub<1.0.0,>=0.2.0->datasets) (4.4.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging->datasets) (3.0.9)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->datasets) (2.10)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->datasets) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->datasets) (2022.12.7)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->datasets) (4.0.0)\n",
            "Collecting urllib3<1.27,>=1.21.1\n",
            "  Downloading urllib3-1.26.14-py2.py3-none-any.whl (140 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m140.6/140.6 KB\u001b[0m \u001b[31m19.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.8/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.8/dist-packages (from pandas->datasets) (2022.7)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.8/dist-packages (from python-dateutil>=2.7.3->pandas->datasets) (1.15.0)\n",
            "Installing collected packages: tokenizers, xxhash, urllib3, multiprocess, responses, huggingface-hub, transformers, datasets\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 1.24.3\n",
            "    Uninstalling urllib3-1.24.3:\n",
            "      Successfully uninstalled urllib3-1.24.3\n",
            "Successfully installed datasets-2.9.0 huggingface-hub-0.12.0 multiprocess-0.70.14 responses-0.18.0 tokenizers-0.13.2 transformers-4.26.0 urllib3-1.26.14 xxhash-3.2.0\n"
          ]
        }
      ],
      "source": [
        "!pip install datasets transformers"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers[sentencepiece]"
      ],
      "metadata": {
        "id": "vJ7O0QdtvKh7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ba164d2c-33f2-41ed-8434-e0f83b7da498"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: transformers[sentencepiece] in /usr/local/lib/python3.8/dist-packages (4.26.0)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.8/dist-packages (from transformers[sentencepiece]) (0.13.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from transformers[sentencepiece]) (3.9.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from transformers[sentencepiece]) (2.25.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.8/dist-packages (from transformers[sentencepiece]) (1.21.6)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from transformers[sentencepiece]) (21.3)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/dist-packages (from transformers[sentencepiece]) (6.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.8/dist-packages (from transformers[sentencepiece]) (2022.6.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.8/dist-packages (from transformers[sentencepiece]) (4.64.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.11.0 in /usr/local/lib/python3.8/dist-packages (from transformers[sentencepiece]) (0.12.0)\n",
            "Requirement already satisfied: protobuf<=3.20.2 in /usr/local/lib/python3.8/dist-packages (from transformers[sentencepiece]) (3.19.6)\n",
            "Collecting sentencepiece!=0.1.92,>=0.1.91\n",
            "  Downloading sentencepiece-0.1.97-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m51.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.8/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers[sentencepiece]) (4.4.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging>=20.0->transformers[sentencepiece]) (3.0.9)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->transformers[sentencepiece]) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->transformers[sentencepiece]) (2022.12.7)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->transformers[sentencepiece]) (1.26.14)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->transformers[sentencepiece]) (4.0.0)\n",
            "Installing collected packages: sentencepiece\n",
            "Successfully installed sentencepiece-0.1.97\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#!apt install git-lfs"
      ],
      "metadata": {
        "id": "1Koh8yXlITLC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Enviroment"
      ],
      "metadata": {
        "id": "nlrl0qCj7t8P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2TbYPNbz7yHO",
        "outputId": "00ac33b6-cf4a-4181-efcf-f0569283b370"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# This flag is the difference between SQUAD v1 or 2 (if you're using another dataset, it indicates if impossible answers are allowed or not).\n",
        "squad_v2 = True\n",
        "#model_checkpoint = \"xlm-roberta-base\"\n",
        "model_checkpoint = \"deepset/xlm-roberta-base-squad2\"\n",
        "batch_size = 16"
      ],
      "metadata": {
        "id": "0A7s9p2BIgTT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Preprocessing the training data"
      ],
      "metadata": {
        "id": "zWJeRCn4dYkv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "from pathlib import Path\n",
        "import torch"
      ],
      "metadata": {
        "id": "2pXKNpVo6XzJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer\n",
        "    \n",
        "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 145,
          "referenced_widgets": [
            "b339d51906be4030838c636e427200c1",
            "88005b023a354a45abd01d22e541e2f4",
            "8fc8300f6ea840088e2acd54d2bd0d90",
            "c1bfaabfa8674b09bb309932adacf074",
            "f57a0bee031b4b959d037aae06c81fa7",
            "4e8790ffd9aa42eda28a95230edc37c8",
            "bb7fcce2d00940ff8f50df59ea56c713",
            "d7f909bcc0464c4f987643ee1af4bf67",
            "49713488c7374f51a1501797afd66efa",
            "8dfd0d7537a64fe7ab9d689b32adcd46",
            "ee1225b1c8514262ac39bda98d28b9b1",
            "75d8f324b5d64bc5a3218ea117b34709",
            "c9706b8f93fc451a9ac0f6c85c1a23d2",
            "7dea6ce79d4444bdad4a1701e6d8c8f9",
            "bef8ae1a0bf94265b21f8f820931454a",
            "cc411788015144fea20edbc5244c83ca",
            "380aa11642244941b48cf58d2003a04a",
            "e3f972ca2e9e47df8e54dcb168263781",
            "0ab3e535fc194f2aad82551c5d97e2e0",
            "4dc9beffd22344a5b8312c6a13104f88",
            "bdda6de86b254990b8304656a7f9675b",
            "f182b8b84b104396900ffff93a617beb",
            "9c44d19b37bc494395a0daec78572a73",
            "b7b37b1b6cb24ed8a375a1dd5dfc1808",
            "c0b47017a43b4368be83003d06112495",
            "2b46c7845c02429e87360f67ba97f562",
            "056c500058b843de9e4505e7ed3da9bb",
            "c7f8c25f80684716a1f296f268551619",
            "7b98863b2dc24778aec603f616123d9c",
            "e8555cd47fcd469597698e7b1c0a66ac",
            "2c995b09a3614c6f9c8e33966679fdfc",
            "ddda6da5d3d34877b6f561d357f36000",
            "1cdeb1e6c59a4893bfb19db07a58d166",
            "cd9ea8a7a8fa47f0a309938f6103c9c4",
            "0ac11243a2c64b13b6633d1a6ceb1d75",
            "b742e8a52a4f4d1c9af215e42179e3e4",
            "b0594c22104a4ca7b03cfaf55f7fb39e",
            "a609dae7e448437bb6b0758ba778beb2",
            "acba33dfb9b44e598ad97ee1b715f2d3",
            "16b4ceceed684438ab719ac23fe825af",
            "d82fc94cf17f45f0ba7966929e122eaa",
            "e23a0dde83fe4a18bfdd45e00ee1e8e7",
            "0caeba8a572e44249bd9e126dd15f183",
            "14996a7a03884e859d509484cd08439d"
          ]
        },
        "id": "-IZTRVm8JA25",
        "outputId": "f5acbf2f-6a99-4a18-d0df-70ad04c7300f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)okenizer_config.json:   0%|          | 0.00/79.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b339d51906be4030838c636e427200c1"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)lve/main/config.json:   0%|          | 0.00/605 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "75d8f324b5d64bc5a3218ea117b34709"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)ncepiece.bpe.model\";:   0%|          | 0.00/5.07M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9c44d19b37bc494395a0daec78572a73"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)cial_tokens_map.json:   0%|          | 0.00/150 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "cd9ea8a7a8fa47f0a309938f6103c9c4"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def read_squad_train(path,data_index,context_size):\n",
        "  \"\"\"\n",
        "  Read data format squad \n",
        "  -> return contexts, questions, answers of sentenses\n",
        "  \"\"\"\n",
        "  path = Path(path)\n",
        "  with open(path, 'rb') as f:\n",
        "      squad_dict = json.load(f)\n",
        "\n",
        "  contexts = []\n",
        "  questions = []\n",
        "  answers = []\n",
        "  size=0\n",
        "  for group in squad_dict['data'][data_index-1:data_index]:\n",
        "      for passage in group['paragraphs']:\n",
        "        if size <= context_size:\n",
        "          context = passage['context']\n",
        "          for qa in passage['qas']:\n",
        "              question = qa['question']\n",
        "              for answer in qa['answers']:\n",
        "                if answer['answer_start']>=0:\n",
        "                  contexts.append(context)\n",
        "                  questions.append(question)\n",
        "                  answers.append(answer)\n",
        "          size+=1\n",
        "        else: break\n",
        "\n",
        "  return contexts, questions, answers\n",
        "def read_squad_val(path):\n",
        "  \"\"\"\n",
        "  Read data format squad \n",
        "  -> return contexts, questions, answers of sentenses\n",
        "  \"\"\"\n",
        "  path = Path(path)\n",
        "  with open(path, 'rb') as f:\n",
        "      squad_dict = json.load(f)\n",
        "\n",
        "  contexts = []\n",
        "  questions = []\n",
        "  answers = []\n",
        "  for group in squad_dict['data']:\n",
        "      for passage in group['paragraphs']:\n",
        "          context = passage['context']\n",
        "          for qa in passage['qas']:\n",
        "              question = qa['question']\n",
        "              for answer in qa['answers']:\n",
        "                  contexts.append(context)\n",
        "                  questions.append(question)\n",
        "                  answers.append(answer)\n",
        "\n",
        "  return contexts, questions, answers\n",
        "def add_token_positions(encodings, answers):\n",
        "  \"\"\"\n",
        "  Convert answer start- end from string to token\n",
        "  \"\"\"\n",
        "  start_positions = []\n",
        "  end_positions = []\n",
        "  for i in range(len(answers)):\n",
        "    start_positions.append(encodings.char_to_token(i, answers[i]['answer_start']))\n",
        "    end_positions.append(encodings.char_to_token(i, answers[i]['answer_end'] - 1))\n",
        "    # if None, the answer passage has been truncated\n",
        "    if start_positions[-1] is None:\n",
        "        start_positions[-1] = tokenizer.model_max_length\n",
        "    if end_positions[-1] is None:\n",
        "        end_positions[-1] = tokenizer.model_max_length\n",
        "  encodings.update({'start_positions': start_positions, 'end_positions': end_positions})\n",
        "def add_end_idx(answers, contexts):\n",
        "  \"\"\"\n",
        "  Squad format chỉ có id start của câu trả lời\n",
        "  -> Hàm này dùng để tạo id end của câu trả lời\n",
        "  \"\"\"\n",
        "  for answer, context in zip(answers, contexts):\n",
        "    gold_text = answer['text']\n",
        "    start_idx = answer['answer_start']\n",
        "    end_idx = start_idx + len(gold_text)\n",
        "\n",
        "    # sometimes squad answers are off by a character or two – fix this\n",
        "    if context[start_idx:end_idx] == gold_text:\n",
        "        answer['answer_end'] = end_idx\n",
        "    elif context[start_idx-1:end_idx-1] == gold_text:\n",
        "        answer['answer_start'] = start_idx - 1\n",
        "        answer['answer_end'] = end_idx - 1     # When the gold label is off by one character\n",
        "    elif context[start_idx-2:end_idx-2] == gold_text:\n",
        "        answer['answer_start'] = start_idx - 2\n",
        "        answer['answer_end'] = end_idx - 2     # When the gold label is off by two characters"
      ],
      "metadata": {
        "id": "DON7PU5kgZHM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_contexts, train_questions, train_answers = read_squad_train('/content/drive/MyDrive/CS221/DoAnCK/Dataset/squad_vi.json', 1,3500)\n",
        "#val_contexts, val_questions, val_answers = read_squad_train('/content/drive/MyDrive/CS221/DoAnCK/Dataset/squad_vi.json', 3000, 3500)\n",
        "add_end_idx(train_answers, train_contexts)\n",
        "#add_end_idx(val_answers, val_contexts) \n",
        "\n",
        "#train\n",
        "new_train_contexts=[]\n",
        "new_train_questions=[]\n",
        "new_train_answers=[]\n",
        "for i in range(len(train_answers)):\n",
        "  if train_answers[i]['answer_start']!=train_answers[i]['answer_end']:\n",
        "    new_train_contexts.append(train_contexts[i])\n",
        "    new_train_questions.append(train_questions[i])\n",
        "    new_train_answers.append(train_answers[i])\n",
        "(train_contexts, train_questions, train_answers)=(new_train_contexts, new_train_questions, new_train_answers)\n",
        "(new_train_contexts, new_train_questions, new_train_answers)=(0,0,0)\n",
        "\n",
        "#chia train val\n",
        "val_contexts, val_questions, val_answers = train_contexts[12000:], train_questions[12000:], train_answers[12000:]\n",
        "train_contexts, train_questions, train_answers = train_contexts[:12000], train_questions[:12000], train_answers[:12000]\n",
        "\n",
        "\n",
        "train_encodings = tokenizer(train_contexts, train_questions, truncation=True, padding=True)\n",
        "val_encodings = tokenizer(val_contexts, val_questions, truncation=True, padding=True)\n",
        "\n",
        "add_token_positions(train_encodings, train_answers)\n",
        "add_token_positions(val_encodings, val_answers)\n"
      ],
      "metadata": {
        "id": "KABrDBg5j4q_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class SquadDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, encodings):\n",
        "        self.encodings = encodings\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.encodings.input_ids)"
      ],
      "metadata": {
        "id": "juoHW4ZpJn7V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = SquadDataset(train_encodings)\n",
        "val_dataset = SquadDataset(val_encodings)"
      ],
      "metadata": {
        "id": "3wGUVFH-24U8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Load pretrain"
      ],
      "metadata": {
        "id": "XcSlcJmuKoip"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModelForQuestionAnswering, TrainingArguments, Trainer\n",
        "\n",
        "model = AutoModelForQuestionAnswering.from_pretrained(model_checkpoint)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "referenced_widgets": [
            "e13837beb131498eb5cfafe4698404c6",
            "37c82f7385e44894b0ede292f602e029",
            "3d6e90f59e9245c8bb0a38ef3405b338",
            "14010470f02d44d99d17dd3057c61f94",
            "50ce3a0d5ab74c349f319e98837fb714",
            "991acbf870d74970ac4cb633b4efe40f",
            "c7da2b35cd4344a2ace2f2a7580c55bc",
            "00476ea9f7674594999a5127db6a78f2",
            "e229d591e1d341de9e499cac1a076392",
            "5fc17690aa474f689fa6cea59157a751",
            "e26faabb6d7c465caed87e9134c3d1ba"
          ]
        },
        "id": "OzIv0rIXKpxm",
        "outputId": "b65e4a33-e64f-4cad-efcb-1e25d65212b9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)\"pytorch_model.bin\";:   0%|          | 0.00/1.11G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e13837beb131498eb5cfafe4698404c6"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RLgu-uEd5cm0",
        "outputId": "fafe639c-6692-4d7e-c3e8-f28e61d00ee7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "XLMRobertaForQuestionAnswering(\n",
              "  (roberta): XLMRobertaModel(\n",
              "    (embeddings): XLMRobertaEmbeddings(\n",
              "      (word_embeddings): Embedding(250002, 768, padding_idx=1)\n",
              "      (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
              "      (token_type_embeddings): Embedding(1, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): XLMRobertaEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): XLMRobertaLayer(\n",
              "          (attention): XLMRobertaAttention(\n",
              "            (self): XLMRobertaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): XLMRobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): XLMRobertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): XLMRobertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): XLMRobertaLayer(\n",
              "          (attention): XLMRobertaAttention(\n",
              "            (self): XLMRobertaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): XLMRobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): XLMRobertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): XLMRobertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): XLMRobertaLayer(\n",
              "          (attention): XLMRobertaAttention(\n",
              "            (self): XLMRobertaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): XLMRobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): XLMRobertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): XLMRobertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): XLMRobertaLayer(\n",
              "          (attention): XLMRobertaAttention(\n",
              "            (self): XLMRobertaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): XLMRobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): XLMRobertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): XLMRobertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): XLMRobertaLayer(\n",
              "          (attention): XLMRobertaAttention(\n",
              "            (self): XLMRobertaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): XLMRobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): XLMRobertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): XLMRobertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): XLMRobertaLayer(\n",
              "          (attention): XLMRobertaAttention(\n",
              "            (self): XLMRobertaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): XLMRobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): XLMRobertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): XLMRobertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): XLMRobertaLayer(\n",
              "          (attention): XLMRobertaAttention(\n",
              "            (self): XLMRobertaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): XLMRobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): XLMRobertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): XLMRobertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): XLMRobertaLayer(\n",
              "          (attention): XLMRobertaAttention(\n",
              "            (self): XLMRobertaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): XLMRobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): XLMRobertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): XLMRobertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): XLMRobertaLayer(\n",
              "          (attention): XLMRobertaAttention(\n",
              "            (self): XLMRobertaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): XLMRobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): XLMRobertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): XLMRobertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): XLMRobertaLayer(\n",
              "          (attention): XLMRobertaAttention(\n",
              "            (self): XLMRobertaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): XLMRobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): XLMRobertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): XLMRobertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): XLMRobertaLayer(\n",
              "          (attention): XLMRobertaAttention(\n",
              "            (self): XLMRobertaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): XLMRobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): XLMRobertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): XLMRobertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): XLMRobertaLayer(\n",
              "          (attention): XLMRobertaAttention(\n",
              "            (self): XLMRobertaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): XLMRobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): XLMRobertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): XLMRobertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (qa_outputs): Linear(in_features=768, out_features=2, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Train"
      ],
      "metadata": {
        "id": "vMlPE-C7l1kQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader\n",
        "from transformers import AdamW\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "DGxpf8C53jYT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 10\n",
        "batch_size=8\n",
        "train_count = len(train_dataset)\n",
        "val_count = len(val_dataset)\n",
        "PATH = \"/content/drive/MyDrive/CS221/DoAnCK/Model/best_model.model\""
      ],
      "metadata": {
        "id": "ZSkUTlj23qUH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Train with pytorch (Train thử với data mẫu gồm 1000 bộ câu hỏi)"
      ],
      "metadata": {
        "id": "IKcswr6P3hdJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
        "model.to(device)\n",
        "train_loader = DataLoader(train_dataset, batch_size = batch_size, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size = batch_size, shuffle=True)\n",
        "\n",
        "optim = AdamW(model.parameters(), lr=5e-5)\n",
        "\n",
        "for epoch in range(epochs):\n",
        "  print(\"Epoch \" + str(epoch) + \":\")\n",
        "  train_loss, val_loss = 0.0, 0.0\n",
        "  train_correct, val_correct = 0, 0\n",
        "\n",
        "  #train\n",
        "  model.train()\n",
        "  for batch in train_loader:\n",
        "    optim.zero_grad()\n",
        "    input_ids = batch['input_ids'].to(device)\n",
        "    attention_mask = batch['attention_mask'].to(device)\n",
        "    start_positions = batch['start_positions'].to(device)\n",
        "    end_positions = batch['end_positions'].to(device)\n",
        "    outputs = model(input_ids, attention_mask=attention_mask, start_positions=start_positions, end_positions=end_positions)\n",
        "    loss = outputs[0]\n",
        "    loss.backward()\n",
        "    optim.step()\n",
        "    train_loss += loss\n",
        "    start, end = outputs.start_logits.argmax(dim=-1), outputs.end_logits.argmax(dim=-1)\n",
        "\n",
        "    #print(f'start: {start_positions}, end: {end_positions} \\nstart_pre: {start}, end_pre: {end}')\n",
        "    for i in range(len(start)):\n",
        "      if (start_positions[i] == start[i] and end_positions[i] == end[i]):\n",
        "        train_correct += 1\n",
        "\n",
        "  #Val\n",
        "  #torch.cuda.empty_cache()\n",
        "  # del outputs\n",
        "  # model.eval()\n",
        "  # for batch in val_loader:\n",
        "  #   input_ids = batch['input_ids'].to(device)\n",
        "  #   attention_mask = batch['attention_mask'].to(device)\n",
        "  #   start_positions = batch['start_positions'].to(device)\n",
        "  #   end_positions = batch['end_positions'].to(device)\n",
        "  #   outputs = model(input_ids, attention_mask=attention_mask, start_positions=start_positions, end_positions=end_positions)\n",
        "  #   loss = outputs[0]\n",
        "  #   val_loss += loss\n",
        "\n",
        "  #   start, end = outputs.start_logits.argmax(dim=-1), outputs.end_logits.argmax(dim=-1)\n",
        "  #   for i in range(len(start)):\n",
        "  #     if (start_positions[i] == start[i] and end_positions[i] == end[i]):\n",
        "  #       val_correct += 1\n",
        "\n",
        "  print(f'\\ttrain_loss: {train_loss/train_count}, train_EM: {round(train_correct/train_count, 3)}')#\\n\\tval_loss: {val_loss/val_count}, val_EM: {round(val_correct/val_count, 3)}')\n",
        "  torch.save(model.state_dict(), PATH)\n",
        "\n",
        "model.eval()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ka2LlbO_3fV6",
        "outputId": "a68f136c-2d37-4cd7-d16e-f756f86fc74b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0:\n",
            "\ttrain_loss: 0.06970500946044922, train_EM: 0.782\n",
            "Epoch 1:\n",
            "\ttrain_loss: 0.025197690352797508, train_EM: 0.91\n",
            "Epoch 2:\n",
            "\ttrain_loss: 0.010780108161270618, train_EM: 0.951\n",
            "Epoch 3:\n",
            "\ttrain_loss: 0.010792060755193233, train_EM: 0.961\n",
            "Epoch 4:\n",
            "\ttrain_loss: 0.004178685136139393, train_EM: 0.988\n",
            "Epoch 5:\n",
            "\ttrain_loss: 0.012848387472331524, train_EM: 0.956\n",
            "Epoch 6:\n",
            "\ttrain_loss: 0.008505364879965782, train_EM: 0.961\n",
            "Epoch 7:\n",
            "\ttrain_loss: 0.011643161065876484, train_EM: 0.956\n",
            "Epoch 8:\n",
            "\ttrain_loss: 0.00583803141489625, train_EM: 0.975\n",
            "Epoch 9:\n",
            "\ttrain_loss: 0.012150724418461323, train_EM: 0.962\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "XLMRobertaForQuestionAnswering(\n",
              "  (roberta): XLMRobertaModel(\n",
              "    (embeddings): XLMRobertaEmbeddings(\n",
              "      (word_embeddings): Embedding(250002, 768, padding_idx=1)\n",
              "      (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
              "      (token_type_embeddings): Embedding(1, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): XLMRobertaEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): XLMRobertaLayer(\n",
              "          (attention): XLMRobertaAttention(\n",
              "            (self): XLMRobertaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): XLMRobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): XLMRobertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): XLMRobertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): XLMRobertaLayer(\n",
              "          (attention): XLMRobertaAttention(\n",
              "            (self): XLMRobertaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): XLMRobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): XLMRobertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): XLMRobertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): XLMRobertaLayer(\n",
              "          (attention): XLMRobertaAttention(\n",
              "            (self): XLMRobertaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): XLMRobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): XLMRobertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): XLMRobertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): XLMRobertaLayer(\n",
              "          (attention): XLMRobertaAttention(\n",
              "            (self): XLMRobertaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): XLMRobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): XLMRobertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): XLMRobertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): XLMRobertaLayer(\n",
              "          (attention): XLMRobertaAttention(\n",
              "            (self): XLMRobertaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): XLMRobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): XLMRobertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): XLMRobertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): XLMRobertaLayer(\n",
              "          (attention): XLMRobertaAttention(\n",
              "            (self): XLMRobertaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): XLMRobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): XLMRobertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): XLMRobertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): XLMRobertaLayer(\n",
              "          (attention): XLMRobertaAttention(\n",
              "            (self): XLMRobertaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): XLMRobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): XLMRobertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): XLMRobertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): XLMRobertaLayer(\n",
              "          (attention): XLMRobertaAttention(\n",
              "            (self): XLMRobertaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): XLMRobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): XLMRobertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): XLMRobertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): XLMRobertaLayer(\n",
              "          (attention): XLMRobertaAttention(\n",
              "            (self): XLMRobertaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): XLMRobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): XLMRobertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): XLMRobertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): XLMRobertaLayer(\n",
              "          (attention): XLMRobertaAttention(\n",
              "            (self): XLMRobertaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): XLMRobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): XLMRobertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): XLMRobertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): XLMRobertaLayer(\n",
              "          (attention): XLMRobertaAttention(\n",
              "            (self): XLMRobertaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): XLMRobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): XLMRobertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): XLMRobertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): XLMRobertaLayer(\n",
              "          (attention): XLMRobertaAttention(\n",
              "            (self): XLMRobertaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): XLMRobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): XLMRobertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): XLMRobertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (qa_outputs): Linear(in_features=768, out_features=2, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Train with trainer (Chính thức)"
      ],
      "metadata": {
        "id": "fN-QiKEf5ngP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "args = TrainingArguments(\n",
        "    f\"/content/drive/MyDrive/CS221/DoAnCK/Logs/Roberta-ViSquad\",#Tên folder chứa log\n",
        "    evaluation_strategy = \"epoch\",#Đánh giá sau mỗi epoch\n",
        "    learning_rate=2e-5,\n",
        "    per_device_train_batch_size=batch_size,\n",
        "    per_device_eval_batch_size=16,\n",
        "    num_train_epochs=10,\n",
        "    weight_decay=0.01,\n",
        "    #push_to_hub=True,\n",
        ")"
      ],
      "metadata": {
        "id": "Qh5bWNzHKYOL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def f1_score(start_pred,end_pred,start_true,end_true):\n",
        "  a=np.arange(int(start_pred),int(end_pred+1), step=1)\n",
        "  b=np.arange(int(start_true),int(end_true+1), step=1)\n",
        "  true_count = len(np.intersect1d(a,b))\n",
        "  if ((int(end_true)-int(start_true)) == 0):\n",
        "    recall = 0\n",
        "  else:\n",
        "    recall = true_count/(int(end_true)-int(start_true))\n",
        "  if ((int(end_pred)-int(start_pred)) == 0):\n",
        "    precision = 0\n",
        "  else:\n",
        "    precision= true_count/(int(end_pred)-int(start_pred))\n",
        "  if (precision + recall == 0):\n",
        "    return 0\n",
        "  f1=2*(precision*recall)/(precision+recall)\n",
        "  return f1"
      ],
      "metadata": {
        "id": "VSGbLruKKYOL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_metrics(eval_pred):    \n",
        "    logits, labels = eval_pred\n",
        "    predictions = np.argmax(logits, axis=-1)\n",
        "    count = 0\n",
        "    for i in range(len(predictions[0])):\n",
        "      if (predictions[0][i] == labels[0][i] and predictions[1][i] == labels[1][i]):\n",
        "        count += 1\n",
        "    f1 = 0\n",
        "    for i in range(len(predictions[0])):\n",
        "      f1 += f1_score(predictions[0][i], predictions[1][i], labels[0][i], labels[1][i])\n",
        "\n",
        "    return {'exact_match': round(count/len(predictions[0]), 3), 'f1_score': round(f1/len(predictions[0]),3)} #metric.compute(predictions=predictions, references=labels)"
      ],
      "metadata": {
        "id": "NnKZcCABKYOL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer = Trainer(\n",
        "    model,\n",
        "    args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=val_dataset,\n",
        "    #data_collator=data_collator,\n",
        "    tokenizer=tokenizer,\n",
        "    compute_metrics=compute_metrics\n",
        ")"
      ],
      "metadata": {
        "id": "FUNMR9oVKYOL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.train()\n",
        "trainer.save_model(\"/content/drive/MyDrive/CS221/DoAnCK/Model/Roberta-ViSquad\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "e7c5b211-27dc-4943-b9a4-65d0300f9383",
        "id": "jWnUln7dKYOM"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n",
            "***** Running training *****\n",
            "  Num examples = 12000\n",
            "  Num Epochs = 10\n",
            "  Instantaneous batch size per device = 8\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
            "  Gradient Accumulation steps = 1\n",
            "  Total optimization steps = 15000\n",
            "  Number of trainable parameters = 277454594\n",
            "You're using a XLMRobertaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='15000' max='15000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [15000/15000 3:55:11, Epoch 10/10]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Exact Match</th>\n",
              "      <th>F1 Score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>1.479900</td>\n",
              "      <td>1.359919</td>\n",
              "      <td>52.696000</td>\n",
              "      <td>0.800000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>1.099000</td>\n",
              "      <td>1.337566</td>\n",
              "      <td>54.340000</td>\n",
              "      <td>0.834000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.805500</td>\n",
              "      <td>1.565913</td>\n",
              "      <td>54.751000</td>\n",
              "      <td>0.822000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.606600</td>\n",
              "      <td>1.708217</td>\n",
              "      <td>54.545000</td>\n",
              "      <td>0.815000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.461000</td>\n",
              "      <td>1.777834</td>\n",
              "      <td>54.751000</td>\n",
              "      <td>0.833000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.361900</td>\n",
              "      <td>2.020115</td>\n",
              "      <td>54.340000</td>\n",
              "      <td>0.822000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>0.284300</td>\n",
              "      <td>2.531387</td>\n",
              "      <td>55.932000</td>\n",
              "      <td>0.838000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>0.220700</td>\n",
              "      <td>2.673394</td>\n",
              "      <td>55.829000</td>\n",
              "      <td>0.837000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>0.163000</td>\n",
              "      <td>3.208999</td>\n",
              "      <td>55.419000</td>\n",
              "      <td>0.830000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>0.149000</td>\n",
              "      <td>3.267859</td>\n",
              "      <td>55.470000</td>\n",
              "      <td>0.831000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Saving model checkpoint to /content/drive/MyDrive/CS221/DoAnCK/Logs/Roberta-ViSquad/checkpoint-500\n",
            "Configuration saved in /content/drive/MyDrive/CS221/DoAnCK/Logs/Roberta-ViSquad/checkpoint-500/config.json\n",
            "Model weights saved in /content/drive/MyDrive/CS221/DoAnCK/Logs/Roberta-ViSquad/checkpoint-500/pytorch_model.bin\n",
            "tokenizer config file saved in /content/drive/MyDrive/CS221/DoAnCK/Logs/Roberta-ViSquad/checkpoint-500/tokenizer_config.json\n",
            "Special tokens file saved in /content/drive/MyDrive/CS221/DoAnCK/Logs/Roberta-ViSquad/checkpoint-500/special_tokens_map.json\n",
            "Saving model checkpoint to /content/drive/MyDrive/CS221/DoAnCK/Logs/Roberta-ViSquad/checkpoint-1000\n",
            "Configuration saved in /content/drive/MyDrive/CS221/DoAnCK/Logs/Roberta-ViSquad/checkpoint-1000/config.json\n",
            "Model weights saved in /content/drive/MyDrive/CS221/DoAnCK/Logs/Roberta-ViSquad/checkpoint-1000/pytorch_model.bin\n",
            "tokenizer config file saved in /content/drive/MyDrive/CS221/DoAnCK/Logs/Roberta-ViSquad/checkpoint-1000/tokenizer_config.json\n",
            "Special tokens file saved in /content/drive/MyDrive/CS221/DoAnCK/Logs/Roberta-ViSquad/checkpoint-1000/special_tokens_map.json\n",
            "Saving model checkpoint to /content/drive/MyDrive/CS221/DoAnCK/Logs/Roberta-ViSquad/checkpoint-1500\n",
            "Configuration saved in /content/drive/MyDrive/CS221/DoAnCK/Logs/Roberta-ViSquad/checkpoint-1500/config.json\n",
            "Model weights saved in /content/drive/MyDrive/CS221/DoAnCK/Logs/Roberta-ViSquad/checkpoint-1500/pytorch_model.bin\n",
            "tokenizer config file saved in /content/drive/MyDrive/CS221/DoAnCK/Logs/Roberta-ViSquad/checkpoint-1500/tokenizer_config.json\n",
            "Special tokens file saved in /content/drive/MyDrive/CS221/DoAnCK/Logs/Roberta-ViSquad/checkpoint-1500/special_tokens_map.json\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1947\n",
            "  Batch size = 16\n",
            "Saving model checkpoint to /content/drive/MyDrive/CS221/DoAnCK/Logs/Roberta-ViSquad/checkpoint-2000\n",
            "Configuration saved in /content/drive/MyDrive/CS221/DoAnCK/Logs/Roberta-ViSquad/checkpoint-2000/config.json\n",
            "Model weights saved in /content/drive/MyDrive/CS221/DoAnCK/Logs/Roberta-ViSquad/checkpoint-2000/pytorch_model.bin\n",
            "tokenizer config file saved in /content/drive/MyDrive/CS221/DoAnCK/Logs/Roberta-ViSquad/checkpoint-2000/tokenizer_config.json\n",
            "Special tokens file saved in /content/drive/MyDrive/CS221/DoAnCK/Logs/Roberta-ViSquad/checkpoint-2000/special_tokens_map.json\n",
            "Saving model checkpoint to /content/drive/MyDrive/CS221/DoAnCK/Logs/Roberta-ViSquad/checkpoint-2500\n",
            "Configuration saved in /content/drive/MyDrive/CS221/DoAnCK/Logs/Roberta-ViSquad/checkpoint-2500/config.json\n",
            "Model weights saved in /content/drive/MyDrive/CS221/DoAnCK/Logs/Roberta-ViSquad/checkpoint-2500/pytorch_model.bin\n",
            "tokenizer config file saved in /content/drive/MyDrive/CS221/DoAnCK/Logs/Roberta-ViSquad/checkpoint-2500/tokenizer_config.json\n",
            "Special tokens file saved in /content/drive/MyDrive/CS221/DoAnCK/Logs/Roberta-ViSquad/checkpoint-2500/special_tokens_map.json\n",
            "Saving model checkpoint to /content/drive/MyDrive/CS221/DoAnCK/Logs/Roberta-ViSquad/checkpoint-3000\n",
            "Configuration saved in /content/drive/MyDrive/CS221/DoAnCK/Logs/Roberta-ViSquad/checkpoint-3000/config.json\n",
            "Model weights saved in /content/drive/MyDrive/CS221/DoAnCK/Logs/Roberta-ViSquad/checkpoint-3000/pytorch_model.bin\n",
            "tokenizer config file saved in /content/drive/MyDrive/CS221/DoAnCK/Logs/Roberta-ViSquad/checkpoint-3000/tokenizer_config.json\n",
            "Special tokens file saved in /content/drive/MyDrive/CS221/DoAnCK/Logs/Roberta-ViSquad/checkpoint-3000/special_tokens_map.json\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1947\n",
            "  Batch size = 16\n",
            "Saving model checkpoint to /content/drive/MyDrive/CS221/DoAnCK/Logs/Roberta-ViSquad/checkpoint-3500\n",
            "Configuration saved in /content/drive/MyDrive/CS221/DoAnCK/Logs/Roberta-ViSquad/checkpoint-3500/config.json\n",
            "Model weights saved in /content/drive/MyDrive/CS221/DoAnCK/Logs/Roberta-ViSquad/checkpoint-3500/pytorch_model.bin\n",
            "tokenizer config file saved in /content/drive/MyDrive/CS221/DoAnCK/Logs/Roberta-ViSquad/checkpoint-3500/tokenizer_config.json\n",
            "Special tokens file saved in /content/drive/MyDrive/CS221/DoAnCK/Logs/Roberta-ViSquad/checkpoint-3500/special_tokens_map.json\n",
            "Saving model checkpoint to /content/drive/MyDrive/CS221/DoAnCK/Logs/Roberta-ViSquad/checkpoint-4000\n",
            "Configuration saved in /content/drive/MyDrive/CS221/DoAnCK/Logs/Roberta-ViSquad/checkpoint-4000/config.json\n",
            "Model weights saved in /content/drive/MyDrive/CS221/DoAnCK/Logs/Roberta-ViSquad/checkpoint-4000/pytorch_model.bin\n",
            "tokenizer config file saved in /content/drive/MyDrive/CS221/DoAnCK/Logs/Roberta-ViSquad/checkpoint-4000/tokenizer_config.json\n",
            "Special tokens file saved in /content/drive/MyDrive/CS221/DoAnCK/Logs/Roberta-ViSquad/checkpoint-4000/special_tokens_map.json\n",
            "Saving model checkpoint to /content/drive/MyDrive/CS221/DoAnCK/Logs/Roberta-ViSquad/checkpoint-4500\n",
            "Configuration saved in /content/drive/MyDrive/CS221/DoAnCK/Logs/Roberta-ViSquad/checkpoint-4500/config.json\n",
            "Model weights saved in /content/drive/MyDrive/CS221/DoAnCK/Logs/Roberta-ViSquad/checkpoint-4500/pytorch_model.bin\n",
            "tokenizer config file saved in /content/drive/MyDrive/CS221/DoAnCK/Logs/Roberta-ViSquad/checkpoint-4500/tokenizer_config.json\n",
            "Special tokens file saved in /content/drive/MyDrive/CS221/DoAnCK/Logs/Roberta-ViSquad/checkpoint-4500/special_tokens_map.json\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1947\n",
            "  Batch size = 16\n",
            "Saving model checkpoint to /content/drive/MyDrive/CS221/DoAnCK/Logs/Roberta-ViSquad/checkpoint-5000\n",
            "Configuration saved in /content/drive/MyDrive/CS221/DoAnCK/Logs/Roberta-ViSquad/checkpoint-5000/config.json\n",
            "Model weights saved in /content/drive/MyDrive/CS221/DoAnCK/Logs/Roberta-ViSquad/checkpoint-5000/pytorch_model.bin\n",
            "tokenizer config file saved in /content/drive/MyDrive/CS221/DoAnCK/Logs/Roberta-ViSquad/checkpoint-5000/tokenizer_config.json\n",
            "Special tokens file saved in /content/drive/MyDrive/CS221/DoAnCK/Logs/Roberta-ViSquad/checkpoint-5000/special_tokens_map.json\n",
            "Saving model checkpoint to /content/drive/MyDrive/CS221/DoAnCK/Logs/Roberta-ViSquad/checkpoint-5500\n",
            "Configuration saved in /content/drive/MyDrive/CS221/DoAnCK/Logs/Roberta-ViSquad/checkpoint-5500/config.json\n",
            "Model weights saved in /content/drive/MyDrive/CS221/DoAnCK/Logs/Roberta-ViSquad/checkpoint-5500/pytorch_model.bin\n",
            "tokenizer config file saved in /content/drive/MyDrive/CS221/DoAnCK/Logs/Roberta-ViSquad/checkpoint-5500/tokenizer_config.json\n",
            "Special tokens file saved in /content/drive/MyDrive/CS221/DoAnCK/Logs/Roberta-ViSquad/checkpoint-5500/special_tokens_map.json\n",
            "Saving model checkpoint to /content/drive/MyDrive/CS221/DoAnCK/Logs/Roberta-ViSquad/checkpoint-6000\n",
            "Configuration saved in /content/drive/MyDrive/CS221/DoAnCK/Logs/Roberta-ViSquad/checkpoint-6000/config.json\n",
            "Model weights saved in /content/drive/MyDrive/CS221/DoAnCK/Logs/Roberta-ViSquad/checkpoint-6000/pytorch_model.bin\n",
            "tokenizer config file saved in /content/drive/MyDrive/CS221/DoAnCK/Logs/Roberta-ViSquad/checkpoint-6000/tokenizer_config.json\n",
            "Special tokens file saved in /content/drive/MyDrive/CS221/DoAnCK/Logs/Roberta-ViSquad/checkpoint-6000/special_tokens_map.json\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1947\n",
            "  Batch size = 16\n",
            "Saving model checkpoint to /content/drive/MyDrive/CS221/DoAnCK/Logs/Roberta-ViSquad/checkpoint-6500\n",
            "Configuration saved in /content/drive/MyDrive/CS221/DoAnCK/Logs/Roberta-ViSquad/checkpoint-6500/config.json\n",
            "Model weights saved in /content/drive/MyDrive/CS221/DoAnCK/Logs/Roberta-ViSquad/checkpoint-6500/pytorch_model.bin\n",
            "tokenizer config file saved in /content/drive/MyDrive/CS221/DoAnCK/Logs/Roberta-ViSquad/checkpoint-6500/tokenizer_config.json\n",
            "Special tokens file saved in /content/drive/MyDrive/CS221/DoAnCK/Logs/Roberta-ViSquad/checkpoint-6500/special_tokens_map.json\n",
            "Saving model checkpoint to /content/drive/MyDrive/CS221/DoAnCK/Logs/Roberta-ViSquad/checkpoint-7000\n",
            "Configuration saved in /content/drive/MyDrive/CS221/DoAnCK/Logs/Roberta-ViSquad/checkpoint-7000/config.json\n",
            "Model weights saved in /content/drive/MyDrive/CS221/DoAnCK/Logs/Roberta-ViSquad/checkpoint-7000/pytorch_model.bin\n",
            "tokenizer config file saved in /content/drive/MyDrive/CS221/DoAnCK/Logs/Roberta-ViSquad/checkpoint-7000/tokenizer_config.json\n",
            "Special tokens file saved in /content/drive/MyDrive/CS221/DoAnCK/Logs/Roberta-ViSquad/checkpoint-7000/special_tokens_map.json\n",
            "Saving model checkpoint to /content/drive/MyDrive/CS221/DoAnCK/Logs/Roberta-ViSquad/checkpoint-7500\n",
            "Configuration saved in /content/drive/MyDrive/CS221/DoAnCK/Logs/Roberta-ViSquad/checkpoint-7500/config.json\n",
            "Model weights saved in /content/drive/MyDrive/CS221/DoAnCK/Logs/Roberta-ViSquad/checkpoint-7500/pytorch_model.bin\n",
            "tokenizer config file saved in /content/drive/MyDrive/CS221/DoAnCK/Logs/Roberta-ViSquad/checkpoint-7500/tokenizer_config.json\n",
            "Special tokens file saved in /content/drive/MyDrive/CS221/DoAnCK/Logs/Roberta-ViSquad/checkpoint-7500/special_tokens_map.json\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1947\n",
            "  Batch size = 16\n",
            "Saving model checkpoint to /content/drive/MyDrive/CS221/DoAnCK/Logs/Roberta-ViSquad/checkpoint-8000\n",
            "Configuration saved in /content/drive/MyDrive/CS221/DoAnCK/Logs/Roberta-ViSquad/checkpoint-8000/config.json\n",
            "Model weights saved in /content/drive/MyDrive/CS221/DoAnCK/Logs/Roberta-ViSquad/checkpoint-8000/pytorch_model.bin\n",
            "tokenizer config file saved in /content/drive/MyDrive/CS221/DoAnCK/Logs/Roberta-ViSquad/checkpoint-8000/tokenizer_config.json\n",
            "Special tokens file saved in /content/drive/MyDrive/CS221/DoAnCK/Logs/Roberta-ViSquad/checkpoint-8000/special_tokens_map.json\n",
            "Saving model checkpoint to /content/drive/MyDrive/CS221/DoAnCK/Logs/Roberta-ViSquad/checkpoint-8500\n",
            "Configuration saved in /content/drive/MyDrive/CS221/DoAnCK/Logs/Roberta-ViSquad/checkpoint-8500/config.json\n",
            "Model weights saved in /content/drive/MyDrive/CS221/DoAnCK/Logs/Roberta-ViSquad/checkpoint-8500/pytorch_model.bin\n",
            "tokenizer config file saved in /content/drive/MyDrive/CS221/DoAnCK/Logs/Roberta-ViSquad/checkpoint-8500/tokenizer_config.json\n",
            "Special tokens file saved in /content/drive/MyDrive/CS221/DoAnCK/Logs/Roberta-ViSquad/checkpoint-8500/special_tokens_map.json\n",
            "Saving model checkpoint to /content/drive/MyDrive/CS221/DoAnCK/Logs/Roberta-ViSquad/checkpoint-9000\n",
            "Configuration saved in /content/drive/MyDrive/CS221/DoAnCK/Logs/Roberta-ViSquad/checkpoint-9000/config.json\n",
            "Model weights saved in /content/drive/MyDrive/CS221/DoAnCK/Logs/Roberta-ViSquad/checkpoint-9000/pytorch_model.bin\n",
            "tokenizer config file saved in /content/drive/MyDrive/CS221/DoAnCK/Logs/Roberta-ViSquad/checkpoint-9000/tokenizer_config.json\n",
            "Special tokens file saved in /content/drive/MyDrive/CS221/DoAnCK/Logs/Roberta-ViSquad/checkpoint-9000/special_tokens_map.json\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1947\n",
            "  Batch size = 16\n",
            "Saving model checkpoint to /content/drive/MyDrive/CS221/DoAnCK/Logs/Roberta-ViSquad/checkpoint-9500\n",
            "Configuration saved in /content/drive/MyDrive/CS221/DoAnCK/Logs/Roberta-ViSquad/checkpoint-9500/config.json\n",
            "Model weights saved in /content/drive/MyDrive/CS221/DoAnCK/Logs/Roberta-ViSquad/checkpoint-9500/pytorch_model.bin\n",
            "tokenizer config file saved in /content/drive/MyDrive/CS221/DoAnCK/Logs/Roberta-ViSquad/checkpoint-9500/tokenizer_config.json\n",
            "Special tokens file saved in /content/drive/MyDrive/CS221/DoAnCK/Logs/Roberta-ViSquad/checkpoint-9500/special_tokens_map.json\n",
            "Saving model checkpoint to /content/drive/MyDrive/CS221/DoAnCK/Logs/Roberta-ViSquad/checkpoint-10000\n",
            "Configuration saved in /content/drive/MyDrive/CS221/DoAnCK/Logs/Roberta-ViSquad/checkpoint-10000/config.json\n",
            "Model weights saved in /content/drive/MyDrive/CS221/DoAnCK/Logs/Roberta-ViSquad/checkpoint-10000/pytorch_model.bin\n",
            "tokenizer config file saved in /content/drive/MyDrive/CS221/DoAnCK/Logs/Roberta-ViSquad/checkpoint-10000/tokenizer_config.json\n",
            "Special tokens file saved in /content/drive/MyDrive/CS221/DoAnCK/Logs/Roberta-ViSquad/checkpoint-10000/special_tokens_map.json\n",
            "Saving model checkpoint to /content/drive/MyDrive/CS221/DoAnCK/Logs/Roberta-ViSquad/checkpoint-10500\n",
            "Configuration saved in /content/drive/MyDrive/CS221/DoAnCK/Logs/Roberta-ViSquad/checkpoint-10500/config.json\n",
            "Model weights saved in /content/drive/MyDrive/CS221/DoAnCK/Logs/Roberta-ViSquad/checkpoint-10500/pytorch_model.bin\n",
            "tokenizer config file saved in /content/drive/MyDrive/CS221/DoAnCK/Logs/Roberta-ViSquad/checkpoint-10500/tokenizer_config.json\n",
            "Special tokens file saved in /content/drive/MyDrive/CS221/DoAnCK/Logs/Roberta-ViSquad/checkpoint-10500/special_tokens_map.json\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1947\n",
            "  Batch size = 16\n",
            "Saving model checkpoint to /content/drive/MyDrive/CS221/DoAnCK/Logs/Roberta-ViSquad/checkpoint-11000\n",
            "Configuration saved in /content/drive/MyDrive/CS221/DoAnCK/Logs/Roberta-ViSquad/checkpoint-11000/config.json\n",
            "Model weights saved in /content/drive/MyDrive/CS221/DoAnCK/Logs/Roberta-ViSquad/checkpoint-11000/pytorch_model.bin\n",
            "tokenizer config file saved in /content/drive/MyDrive/CS221/DoAnCK/Logs/Roberta-ViSquad/checkpoint-11000/tokenizer_config.json\n",
            "Special tokens file saved in /content/drive/MyDrive/CS221/DoAnCK/Logs/Roberta-ViSquad/checkpoint-11000/special_tokens_map.json\n",
            "Saving model checkpoint to /content/drive/MyDrive/CS221/DoAnCK/Logs/Roberta-ViSquad/checkpoint-11500\n",
            "Configuration saved in /content/drive/MyDrive/CS221/DoAnCK/Logs/Roberta-ViSquad/checkpoint-11500/config.json\n",
            "Model weights saved in /content/drive/MyDrive/CS221/DoAnCK/Logs/Roberta-ViSquad/checkpoint-11500/pytorch_model.bin\n",
            "tokenizer config file saved in /content/drive/MyDrive/CS221/DoAnCK/Logs/Roberta-ViSquad/checkpoint-11500/tokenizer_config.json\n",
            "Special tokens file saved in /content/drive/MyDrive/CS221/DoAnCK/Logs/Roberta-ViSquad/checkpoint-11500/special_tokens_map.json\n",
            "Saving model checkpoint to /content/drive/MyDrive/CS221/DoAnCK/Logs/Roberta-ViSquad/checkpoint-12000\n",
            "Configuration saved in /content/drive/MyDrive/CS221/DoAnCK/Logs/Roberta-ViSquad/checkpoint-12000/config.json\n",
            "Model weights saved in /content/drive/MyDrive/CS221/DoAnCK/Logs/Roberta-ViSquad/checkpoint-12000/pytorch_model.bin\n",
            "tokenizer config file saved in /content/drive/MyDrive/CS221/DoAnCK/Logs/Roberta-ViSquad/checkpoint-12000/tokenizer_config.json\n",
            "Special tokens file saved in /content/drive/MyDrive/CS221/DoAnCK/Logs/Roberta-ViSquad/checkpoint-12000/special_tokens_map.json\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1947\n",
            "  Batch size = 16\n",
            "Saving model checkpoint to /content/drive/MyDrive/CS221/DoAnCK/Logs/Roberta-ViSquad/checkpoint-12500\n",
            "Configuration saved in /content/drive/MyDrive/CS221/DoAnCK/Logs/Roberta-ViSquad/checkpoint-12500/config.json\n",
            "Model weights saved in /content/drive/MyDrive/CS221/DoAnCK/Logs/Roberta-ViSquad/checkpoint-12500/pytorch_model.bin\n",
            "tokenizer config file saved in /content/drive/MyDrive/CS221/DoAnCK/Logs/Roberta-ViSquad/checkpoint-12500/tokenizer_config.json\n",
            "Special tokens file saved in /content/drive/MyDrive/CS221/DoAnCK/Logs/Roberta-ViSquad/checkpoint-12500/special_tokens_map.json\n",
            "Saving model checkpoint to /content/drive/MyDrive/CS221/DoAnCK/Logs/Roberta-ViSquad/checkpoint-13000\n",
            "Configuration saved in /content/drive/MyDrive/CS221/DoAnCK/Logs/Roberta-ViSquad/checkpoint-13000/config.json\n",
            "Model weights saved in /content/drive/MyDrive/CS221/DoAnCK/Logs/Roberta-ViSquad/checkpoint-13000/pytorch_model.bin\n",
            "tokenizer config file saved in /content/drive/MyDrive/CS221/DoAnCK/Logs/Roberta-ViSquad/checkpoint-13000/tokenizer_config.json\n",
            "Special tokens file saved in /content/drive/MyDrive/CS221/DoAnCK/Logs/Roberta-ViSquad/checkpoint-13000/special_tokens_map.json\n",
            "Saving model checkpoint to /content/drive/MyDrive/CS221/DoAnCK/Logs/Roberta-ViSquad/checkpoint-13500\n",
            "Configuration saved in /content/drive/MyDrive/CS221/DoAnCK/Logs/Roberta-ViSquad/checkpoint-13500/config.json\n",
            "Model weights saved in /content/drive/MyDrive/CS221/DoAnCK/Logs/Roberta-ViSquad/checkpoint-13500/pytorch_model.bin\n",
            "tokenizer config file saved in /content/drive/MyDrive/CS221/DoAnCK/Logs/Roberta-ViSquad/checkpoint-13500/tokenizer_config.json\n",
            "Special tokens file saved in /content/drive/MyDrive/CS221/DoAnCK/Logs/Roberta-ViSquad/checkpoint-13500/special_tokens_map.json\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1947\n",
            "  Batch size = 16\n",
            "Saving model checkpoint to /content/drive/MyDrive/CS221/DoAnCK/Logs/Roberta-ViSquad/checkpoint-14000\n",
            "Configuration saved in /content/drive/MyDrive/CS221/DoAnCK/Logs/Roberta-ViSquad/checkpoint-14000/config.json\n",
            "Model weights saved in /content/drive/MyDrive/CS221/DoAnCK/Logs/Roberta-ViSquad/checkpoint-14000/pytorch_model.bin\n",
            "tokenizer config file saved in /content/drive/MyDrive/CS221/DoAnCK/Logs/Roberta-ViSquad/checkpoint-14000/tokenizer_config.json\n",
            "Special tokens file saved in /content/drive/MyDrive/CS221/DoAnCK/Logs/Roberta-ViSquad/checkpoint-14000/special_tokens_map.json\n",
            "Saving model checkpoint to /content/drive/MyDrive/CS221/DoAnCK/Logs/Roberta-ViSquad/checkpoint-14500\n",
            "Configuration saved in /content/drive/MyDrive/CS221/DoAnCK/Logs/Roberta-ViSquad/checkpoint-14500/config.json\n",
            "Model weights saved in /content/drive/MyDrive/CS221/DoAnCK/Logs/Roberta-ViSquad/checkpoint-14500/pytorch_model.bin\n",
            "tokenizer config file saved in /content/drive/MyDrive/CS221/DoAnCK/Logs/Roberta-ViSquad/checkpoint-14500/tokenizer_config.json\n",
            "Special tokens file saved in /content/drive/MyDrive/CS221/DoAnCK/Logs/Roberta-ViSquad/checkpoint-14500/special_tokens_map.json\n",
            "Saving model checkpoint to /content/drive/MyDrive/CS221/DoAnCK/Logs/Roberta-ViSquad/checkpoint-15000\n",
            "Configuration saved in /content/drive/MyDrive/CS221/DoAnCK/Logs/Roberta-ViSquad/checkpoint-15000/config.json\n",
            "Model weights saved in /content/drive/MyDrive/CS221/DoAnCK/Logs/Roberta-ViSquad/checkpoint-15000/pytorch_model.bin\n",
            "tokenizer config file saved in /content/drive/MyDrive/CS221/DoAnCK/Logs/Roberta-ViSquad/checkpoint-15000/tokenizer_config.json\n",
            "Special tokens file saved in /content/drive/MyDrive/CS221/DoAnCK/Logs/Roberta-ViSquad/checkpoint-15000/special_tokens_map.json\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1947\n",
            "  Batch size = 16\n",
            "\n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n",
            "Saving model checkpoint to /content/drive/MyDrive/CS221/DoAnCK/Model/Roberta-ViSquad\n",
            "Configuration saved in /content/drive/MyDrive/CS221/DoAnCK/Model/Roberta-ViSquad/config.json\n",
            "Model weights saved in /content/drive/MyDrive/CS221/DoAnCK/Model/Roberta-ViSquad/pytorch_model.bin\n",
            "tokenizer config file saved in /content/drive/MyDrive/CS221/DoAnCK/Model/Roberta-ViSquad/tokenizer_config.json\n",
            "Special tokens file saved in /content/drive/MyDrive/CS221/DoAnCK/Model/Roberta-ViSquad/special_tokens_map.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "DLrpnVO9KYOM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Evaluation"
      ],
      "metadata": {
        "id": "RLHW604nx1HN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Test"
      ],
      "metadata": {
        "id": "i1CcM3ZOJaf-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModelForQuestionAnswering, TrainingArguments, Trainer\n",
        "from transformers import AutoTokenizer\n",
        "\n",
        "model = AutoModelForQuestionAnswering.from_pretrained(\"/content/drive/MyDrive/CS221/DoAnCK/Logs/MiniBert-ViSquad/checkpoint-15000\") \n",
        "tokenizer = AutoTokenizer.from_pretrained(\"/content/drive/MyDrive/CS221/DoAnCK/Logs/MiniBert-ViSquad/checkpoint-15000\")"
      ],
      "metadata": {
        "id": "lOMW8Fi-JZs1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_contexts, test_questions, test_answers = read_squad_val('/content/drive/MyDrive/CS221/DoAnCK/Dataset/Mailong25/train-v2.0.json')\n",
        "add_end_idx(test_answers, test_contexts)\n",
        "new_test_contexts=[]\n",
        "new_test_questions=[]\n",
        "new_test_answers=[]\n",
        "for i in range(len(test_answers)):\n",
        "  if test_answers[i]['answer_start']!=test_answers[i]['answer_end']:\n",
        "    new_test_contexts.append(test_contexts[i])\n",
        "    new_test_questions.append(test_questions[i])\n",
        "    new_test_answers.append(test_answers[i])\n",
        "(test_contexts, test_questions, test_answers)=(new_test_contexts, new_test_questions, new_test_answers)\n",
        "test_encodings = tokenizer(test_contexts, test_questions, truncation=True, padding=True, return_offsets_mapping=True,)\n",
        "add_token_positions(test_encodings, test_answers)\n",
        "test_dataset = SquadDataset(test_encodings)"
      ],
      "metadata": {
        "id": "pc0lAnaygxIv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "args = TrainingArguments(\n",
        "    f\"/content/drive/MyDrive/CS221/DoAnCK/Logs/Roberta-ViSquad-test\",#Tên folder chứa log\n",
        "    evaluation_strategy = \"epoch\",#Đánh giá sau mỗi epoch\n",
        "    save_strategy = \"epoch\",\n",
        "    learning_rate=2e-5,\n",
        "    per_device_train_batch_size=batch_size,\n",
        "    per_device_eval_batch_size=16,\n",
        "    num_train_epochs=10,\n",
        "    weight_decay=0.01\n",
        "    #push_to_hub=True,\n",
        ")"
      ],
      "metadata": {
        "id": "vn0BOog3KyDU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d7f08172-2ef2-466d-fea3-b7b837b33cbf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "PyTorch: setting up devices\n",
            "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainer = Trainer(\n",
        "    model,\n",
        "    args,\n",
        "    #train_dataset=train_dataset,\n",
        "    eval_dataset=test_dataset,\n",
        "    #data_collator=data_collator,\n",
        "    tokenizer=tokenizer,\n",
        "    compute_metrics=compute_metrics\n",
        ")\n",
        "trainer.evaluate()"
      ],
      "metadata": {
        "id": "5nUbH5LPcDjk",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 231
        },
        "outputId": "b298a1f5-2faf-4a14-eccc-80a55d434e68"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "***** Running Evaluation *****\n",
            "  Num examples = 985\n",
            "  Batch size = 16\n",
            "The following columns in the evaluation set don't have a corresponding argument in `XLMRobertaForQuestionAnswering.forward` and have been ignored: offset_mapping. If offset_mapping are not expected by `XLMRobertaForQuestionAnswering.forward`,  you can safely ignore this message.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='62' max='62' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [62/62 00:17]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'eval_loss': 3.434296131134033,\n",
              " 'eval_exact_match': 0.534,\n",
              " 'eval_f1_score': 1.028,\n",
              " 'eval_runtime': 17.6028,\n",
              " 'eval_samples_per_second': 55.957,\n",
              " 'eval_steps_per_second': 3.522}"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Predict"
      ],
      "metadata": {
        "id": "gVjsbfooPe6i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def Predict(contexts, questions, trainer):\n",
        "  test_encodings = trainer.tokenizer(contexts, questions, truncation=True, padding=True, return_overflowing_tokens=True, return_offsets_mapping=True,)\n",
        "  test_dataset = SquadDataset(test_encodings)\n",
        "  \n",
        "  result = trainer.predict(test_dataset, )\n",
        "  predictions = np.argmax(result.predictions, axis =-1)\n",
        "  metrics = result.metrics\n",
        "  \n",
        "  answers = []\n",
        "  for i in range(len(contexts)):\n",
        "    start = test_encodings['offset_mapping'][0][predictions[0][0]][0]\n",
        "    end = test_encodings['offset_mapping'][0][predictions[1][0]][1]\n",
        "    answers.append(contexts[i][start: end])\n",
        "  return answers[0]"
      ],
      "metadata": {
        "id": "yAHmD-40TmJj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "a = Predict(['Nam sinh ra và lớn lên ở Thủ Đức. Nam học công nghệ thông tin'], [\"Nam học gì\"], trainer)\n",
        "a"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        },
        "id": "G2JfahLWTbVM",
        "outputId": "b087a44e-c5e0-4278-8f1e-1c4e094fee10"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "***** Running Prediction *****\n",
            "  Num examples = 1\n",
            "  Batch size = 16\n",
            "The following columns in the test set don't have a corresponding argument in `XLMRobertaForQuestionAnswering.forward` and have been ignored: overflow_to_sample_mapping, offset_mapping. If overflow_to_sample_mapping, offset_mapping are not expected by `XLMRobertaForQuestionAnswering.forward`,  you can safely ignore this message.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' công nghệ thông tin'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(0, 100, 10):\n",
        "  print(\"Context:\", test_contexts[i])\n",
        "  print(\"Question:\", test_questions[i])\n",
        "  print(\"Trả lời:\", Predict([test_contexts[i]], [test_questions[i]], trainer))\n",
        "  print(\"\\n==========\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "JcwJHQjiVQuZ",
        "outputId": "e51d150b-e22d-4b77-9e02-3978ff1cc38c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "***** Running Prediction *****\n",
            "  Num examples = 1\n",
            "  Batch size = 16\n",
            "The following columns in the test set don't have a corresponding argument in `XLMRobertaForQuestionAnswering.forward` and have been ignored: overflow_to_sample_mapping, offset_mapping. If overflow_to_sample_mapping, offset_mapping are not expected by `XLMRobertaForQuestionAnswering.forward`,  you can safely ignore this message.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Context: Narendra Damodardas Modi ( tiếng Gujarat : નરેન્દ્ર દામોદરદાસ મોદી , [ nəreːnd̪rə d̪ɑːmoːd̪ərəd̪ɑːsə moːd̪iː ] ( nghe ) , tiếng Hindi : नरेन्द्र दामोदरदास मोदी , sinh ngày 17 tháng 9 năm 1950 ) là Thủ tướng Ấn Độ thứ 15 . Ông là thủ lĩnh của đảng Bharatiya Janata ( đảng Nhân dân ) , từng giữ chức Thủ tịch bộ trưởng Gujarat từ năm 2001 đến năm 2014 . Ông đại diện cho Varanasi tại Lok Sabha .\n",
            "Question: Ai là thủ tướng Ấn Độ hiện tại\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "***** Running Prediction *****\n",
            "  Num examples = 1\n",
            "  Batch size = 16\n",
            "The following columns in the test set don't have a corresponding argument in `XLMRobertaForQuestionAnswering.forward` and have been ignored: overflow_to_sample_mapping, offset_mapping. If overflow_to_sample_mapping, offset_mapping are not expected by `XLMRobertaForQuestionAnswering.forward`,  you can safely ignore this message.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trả lời: Narendra Damodardas Modi\n",
            "\n",
            "==========\n",
            "Context: Chia sẻ với VnExpress sau khi được Forbes công nhận là tỷ phú USD với 1,3 tỷ USD tài sản , ông Trần Đình Long - Chủ tịch HĐQT Tập đoàn Hoà Phát , thú nhận đã lâu không làm việc để vì mục tiêu kiếm một con số cụ thể bao nhiêu tiền trong ngày .\n",
            "Question: Ai là chủ tịch tập đoàn Hòa Phát\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "***** Running Prediction *****\n",
            "  Num examples = 1\n",
            "  Batch size = 16\n",
            "The following columns in the test set don't have a corresponding argument in `XLMRobertaForQuestionAnswering.forward` and have been ignored: overflow_to_sample_mapping, offset_mapping. If overflow_to_sample_mapping, offset_mapping are not expected by `XLMRobertaForQuestionAnswering.forward`,  you can safely ignore this message.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trả lời:  ông Trần Đình Long\n",
            "\n",
            "==========\n",
            "Context: Nhà Trắng ngày 29/4 cho biết , Tổng thống Mỹ Donald Trump đã mời Tổng thống Philippines Rodrigo Duterte tới thăm Mỹ .\n",
            "Question: Ai là tổng thống Philippines\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "***** Running Prediction *****\n",
            "  Num examples = 1\n",
            "  Batch size = 16\n",
            "The following columns in the test set don't have a corresponding argument in `XLMRobertaForQuestionAnswering.forward` and have been ignored: overflow_to_sample_mapping, offset_mapping. If overflow_to_sample_mapping, offset_mapping are not expected by `XLMRobertaForQuestionAnswering.forward`,  you can safely ignore this message.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trả lời:  Rodrigo Duterte\n",
            "\n",
            "==========\n",
            "Context: Sáng ngày 25-2 , Bộ trưởng Bộ TT-TT Nguyễn Mạnh Hùng , Chủ tịch UBND TP Hà Nội Nguyễn Đức Chung , Thứ trưởng Bộ Ngoại giao Lê Hoài Trung sáng 25-2 đã chủ trì cuộc họp báo tại Trung tâm ...\n",
            "Question: Bộ trưởng bộ ngoại giao Việt Nam là ai\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "***** Running Prediction *****\n",
            "  Num examples = 1\n",
            "  Batch size = 16\n",
            "The following columns in the test set don't have a corresponding argument in `XLMRobertaForQuestionAnswering.forward` and have been ignored: overflow_to_sample_mapping, offset_mapping. If overflow_to_sample_mapping, offset_mapping are not expected by `XLMRobertaForQuestionAnswering.forward`,  you can safely ignore this message.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trả lời:  Lê Hoài Trung\n",
            "\n",
            "==========\n",
            "Context: Khi ra mắt lần đầu vào năm 1993 , bộ phim Jurassic Park ( Công viên kỷ Jura ) của đạo diễn kỳ tài Steven Spielberg đã trở thành một trong những bom tấn kinh điển về công nghệ CGI ( công nghệ mô phỏng hình ảnh ) cũng như thổi bay mọi phòng vé thời bấy giờ . Tiếp theo là các phần phim The Lost World : Jurassic Park ( 1997 ) và Jurassic Park III ( 2001 ) .\n",
            "Question: Bộ phim Jurassic Park do ai làm đạo diễn?\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "***** Running Prediction *****\n",
            "  Num examples = 1\n",
            "  Batch size = 16\n",
            "The following columns in the test set don't have a corresponding argument in `XLMRobertaForQuestionAnswering.forward` and have been ignored: overflow_to_sample_mapping, offset_mapping. If overflow_to_sample_mapping, offset_mapping are not expected by `XLMRobertaForQuestionAnswering.forward`,  you can safely ignore this message.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trả lời:  Steven Spielberg\n",
            "\n",
            "==========\n",
            "Context: ( VNF ) - Công ty Cổ phần Vinhomes ( HoSE : VHM ) vừa thông báo bà Nguyễn Diệu Linh , thành viên HĐQT kiêm Tổng giám đốc đã được bầu vào vị trí Phó Chủ tịch HĐQT của công ty .\n",
            "Question: tổng giám đốc công ty cổ phần Vinhomes\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "***** Running Prediction *****\n",
            "  Num examples = 1\n",
            "  Batch size = 16\n",
            "The following columns in the test set don't have a corresponding argument in `XLMRobertaForQuestionAnswering.forward` and have been ignored: overflow_to_sample_mapping, offset_mapping. If overflow_to_sample_mapping, offset_mapping are not expected by `XLMRobertaForQuestionAnswering.forward`,  you can safely ignore this message.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trả lời: ,\n",
            "\n",
            "==========\n",
            "Context: Một đoạn clip ghi lại câu trả lời của phi hành gia Buzz Aldrin , người thứ 2 đặt chân lên Mặt trăng thừa nhận ông chưa từng đặt chân lên Mặt trăng , đã được đăng tải lên mạng .\n",
            "Question: Ai là người thứ hai đặt chân lên Mặt trăng?\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "***** Running Prediction *****\n",
            "  Num examples = 1\n",
            "  Batch size = 16\n",
            "The following columns in the test set don't have a corresponding argument in `XLMRobertaForQuestionAnswering.forward` and have been ignored: overflow_to_sample_mapping, offset_mapping. If overflow_to_sample_mapping, offset_mapping are not expected by `XLMRobertaForQuestionAnswering.forward`,  you can safely ignore this message.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trả lời:  Buzz Aldrin ,\n",
            "\n",
            "==========\n",
            "Context: Ông Putin lần đầu tiên nắm quyền tổng thống Nga vào ngày 31/12/1999 , sau khi tổng thống đầu tiên của Nga , ông Boris Yeltsin bất ngờ tuyên bố thoái vị và trao quyền lại cho thủ tướng Vladimir Putin , khi đó vẫn là cái tên ít người biết đến . Ba tháng sau , ông đắc cử tổng thống lần đầu tiên .\n",
            "Question: Tổng thống Nga hiện tại là ai\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "***** Running Prediction *****\n",
            "  Num examples = 1\n",
            "  Batch size = 16\n",
            "The following columns in the test set don't have a corresponding argument in `XLMRobertaForQuestionAnswering.forward` and have been ignored: overflow_to_sample_mapping, offset_mapping. If overflow_to_sample_mapping, offset_mapping are not expected by `XLMRobertaForQuestionAnswering.forward`,  you can safely ignore this message.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trả lời: Ông Putin lần đầu tiên nắm quyền tổng thống Nga vào ngày 31/12/1999 , sau khi tổng thống đầu tiên của Nga , ông Boris Yeltsin\n",
            "\n",
            "==========\n",
            "Context: Cùng với đó , Hội đồng quản trị FECON cũng đã bổ nhiệm ông Nguyễn Văn Thanh , Tổng giám đốc điều hành FECON chính thức đảm nhận vị trí Tổng giám đốc FECON từ ngày 8/11/2018 .\n",
            "Question: tổng giám đốc công ty Fecon\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "***** Running Prediction *****\n",
            "  Num examples = 1\n",
            "  Batch size = 16\n",
            "The following columns in the test set don't have a corresponding argument in `XLMRobertaForQuestionAnswering.forward` and have been ignored: overflow_to_sample_mapping, offset_mapping. If overflow_to_sample_mapping, offset_mapping are not expected by `XLMRobertaForQuestionAnswering.forward`,  you can safely ignore this message.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trả lời: ,\n",
            "\n",
            "==========\n",
            "Context: “ Vài năm nay , mọi người nhìn thép rất xấu , nhưng thép vẫn được coi là bánh mì của công nghiệp và tại những nước công nghiệp hoá mới như chúng ta , nhu cầu thép vẫn còn tăng ” , đó là chia sẻ chân tình của ông Trần Đình Long , Chủ tịch HĐQT Tập đoàn Hoà Phát khi nói về những mối quan tâm của dư luận thời gian gần đây trước những biến động lớn trong ngành thép lẫn tương lai của ngành này tại Việt Nam .\n",
            "Question: chủ tịch tập đoàn Hòa Phát\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trả lời: ,\n",
            "\n",
            "==========\n"
          ]
        }
      ]
    }
  ]
}